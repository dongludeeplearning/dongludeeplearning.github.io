<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SignAvatar: Sign Language 3D Motion Reconstruction and Generation.">
  <meta name="keywords" content="SignAvatar, SMPLX, 3D Mesh">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SignAvatar: Sign Language 3D Motion Reconstruction and Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SignAvatar: Sign Language 3D Motion Reconstruction and Generations </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href=" ">Lu Dong</a>,</span>
            <span class="author-block">
              <a href=" ">Lipisha Chaudhary</a>,</span>
            <span class="author-block">
              <a href=" ">Fei Xu</a>,
            </span>
            <span class="author-block">
              <a href="https://wangxiaoshawn.github.io/">Xiao Wang</a>,
            </span>
            <span class="author-block">
              <a href=" ">Mason Lary</a>,
            </span>
            <span class="author-block">
              <a href=" ">Ifeoma Nwogu</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University at Buffalo,SUNY</span>

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10581934"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2405.07974"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="./files/FG_poster.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Poster</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/dongludeeplearning/SignAvatar"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href=" "
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./files/pubs/SignAvatarbg.png" alt="SignAvatar Teaser" style="width:90%; height:auto; margin-left:3%">
      <h2 class="subtitle has-text-centered" style="font-size:16px">
        <span class="dnerf">SignAvatar </span>  excels at two tasks: reconstructing 3D sign language motions from videos and generating them from semantics (images,
        text). The top row displays a sign language video for "drink" - note some motion blur here. The middle row shows the 3D avatar
        reconstruction by SignAvatar, and the bottom row demonstrates its ability to generate a 3D signing avatar from the word "drink".
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p style="text-align:justify;">  Achieving expressive 3D motion reconstruction and automatic generation for isolated sign words can be challenging, 
            due to the lack of real-world 3D sign-word data, the complex nuances of signing motions, and the cross-modal understanding of sign language semantics. 
            To address these challenges, we introduce SignAvatar, a framework capable of both word-level sign language reconstruction and generation. 
            SignAvatar employs a transformer-based conditional variational autoencoder architecture, effectively establishing relationships across different semantic modalities. 
            Additionally, this approach incorporates a curriculum learning strategy to enhance the modelâ€™s robustness and generalization, resulting in more realistic motions. 
            Furthermore, we contribute the ASL3DWord dataset, composed of 3D joint rotation data for the body, hands, and face, for unique sign words. 
            We demonstrate the effectiveness of SignAvatar through extensive experiments, showcasing its superior reconstruction and automatic generation capabilities.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <section class="main-idea">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img src="./files/pubs/SignAvatar_overview.png" alt="SignAvatar" style="width:90%; height:auto; margin-left:5%">
          <h2 class="subtitle has-text-centered">
            <span class="dnerf"> SignAvatar Overview</span> 
          </h2>
        </div>
      </div>
    </section>



  <section class="main-idea">
    <div class="container is-max-desktop">
      <div class="main-body">
        <img src="./files/pubs/SignAvatar_p2.png" alt="SignAvatar" style="width:90%; height:auto; margin-left:5%">
        <h2 class="subtitle has-text-centered" style="font-size:16px">
          <span class="dnerf"> SignAvatar Pipeline</span> The upper row represents the reconstruction process, absorbing knowledge and analyzing their relationships, while the lower row
          indicates the generation process, which outputs knowledge. Unlike the rigid mapping of sign language production, the input text or images
          in sign language generation showcase greater semantic flexibility.
        </h2>
      </div>
    </div>
  </section>

  <section class="main-idea">
    <div class="container is-max-desktop">
      <div class="main-body">
        <img src="./files/pubs/SignAvatar_book.png" alt="SignAvatar" style="width:100%; height:auto">
        <h2 class="subtitle has-text-centered" style="font-size:16px">
          <span class="dnerf"> SignAvatar </span> can accept images as input. Given an image on the left, and using the text-image embedding of CLIP, SignAvatar can
          recognize the corresponding semantics - "book", and generate the corresponding 3D signing motion. The upper row is the front view and
          the lower row is the side view.
        </h2>
      </div>
    </div>
  </section>
    
<!-- </section> -->



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{dong2024signavatar,
  title     = {Signavatar: Sign language 3d motion reconstruction and generation},
  author    = {Dong, Lu and Chaudhary, Lipisha and Xu, Fei and Wang, Xiao and Lary, Mason and Nwogu, Ifeoma},
  booktitle = {2024 IEEE 18th International Conference on Automatic Face and Gesture Recognition (FG)},
  year      = {2024},
  organization = {IEEE}
}</code></pre>
  </div>
</section>

Website template modified from <a href="https://nerfies.github.io/" target="_blank">NeRFies</a>.
</body>
</html>
