	<html>

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">	
	<title>Lu Dong</title>
	<meta content="LuDong, Lu Dong UB, lu dong ub, ludong,  https://dongludeeplearning.github.io/" name="keywords">
	<link rel="stylesheet" href="./index_files/jemdoc.css" type="text/css">
	<script async="" src="http://www.google-analytics.com/analytics.js"></script>
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
		ga('create', 'UA-66888300-1', 'auto');
		ga('send', 'pageview');
	</script>
	<script type="text/javascript" src="./index_files/jquery-1.12.4.min.js"></script>
	<style>
	a {color: #2471a3; text-decoration: none;}
	a:hover {color: #5499c7;}
	a.btn {background-color: #2471a3; color: #fff; font-size: 12px; margin-top: 4px; display: inline-block; padding: 0 4px; border-radius: 2px; line-height: 1.5em;}
	a.btn:hover {background-color: #174e74;}
	a.btn.btn-red {background-color: #d63a3a;}
	a.btn.btn-red:hover {background-color: #a02727;}
	a.btn.btn-orange {background-color: #e2700c;}
	a.btn.btn-orange:hover {background-color: #c46009;}
	a.btn.btn-dark {background-color: #345;}
	a.btn.btn-dark:hover {background-color: #234;}
	p {line-height: 1.5em;}
	.nobreak {white-space: nowrap;}
	.noselect {-webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none;}
	.bold {font-weight: bold;}
	.italic {font-style: italic;}
	.bulletpoints {line-height: 1.5em;}
	.row {box-sizing: border-box;}
	.row-media {display: block; float: left; width: 280px; height: 150px; background-position: center; background-size: contain; background-repeat: no-repeat; border-radius: 6px; border: 1px solid #def;}
	.row-text {display: block; float: left; margin-left: 16px; line-height: 1.5em; max-width: 552px;}
	.row-text span {line-height: inherit;}
	.clearfix {content: ""; clear: both; display: table;}
	.publication {margin-bottom: 32px; margin-left: 16px;}
	.press {width: 100px; height: 80px; border: 1px solid #def; margin-right: 12px; background-size: cover;}  
	.img-contain {background-size: contain !important;}
	.footer {background-color: #345; width: 100%}
	.footer-content {color: #fff; font-size: 10px; padding: 6px 0; max-width: 900px; margin: auto;}




	@media only screen and (max-width: 1150px) {
		.header-profile-picture, .header-text {display: block; margin: auto; text-align: center;}
		.header-profile-picture {margin-bottom: 12px; width: 140px; height: 140px;}
		body {font-size: 18px;}
		a.btn {font-size: 14px; padding: 2px 6px;}
	}
	
	@media only screen and (max-width: 900px) {
		.publication {margin-bottom: 46px;}
		.publication .row-media {width: 260px; height: 130px; margin: auto; margin-bottom: 12px; display: block;}
		.publication .row-text {display: block; width: 100%; margin-left: 0;}
		.press {display: block;}
	}
	</style>
</head>

<body>

<div id="layout-content" style="margin-top:25px">
<table cellpadding="11px">
	<tbody>
		<tr>
			<td width="720px">
				<div id="toptitle">
					<h1>Lu Dong (董璐) &nbsp; </h1>
				</div>
                <h3>Ph.D. Student</h3>       
				<p>
					<a href="https://engineering.buffalo.edu/computer-science-engineering.html">Department of Computer Science and Engineering</a><br>
					<a href="https://www.buffalo.edu/">University at Buffalo, SUNY (UB)</a><br>
					301 Davis Hall, Buffalo, New York, US, 14260 <br>
					<br>
					Email:  <a href="ludong@buffalo.edu"> ludong@buffalo.edu </a><br>
					<br>
          <a href="./files/Lu_Dong_Resume240921.pdf"> <img src="./files/logo-cv.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
					<a href="https://github.com/dongludeeplearning"> <img src="./files/logo-github.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
          <a href="https://scholar.google.com/citations?user=48ReRMkAAAAJ&hl=en"> <img src="./files/logo-googlescholar.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
					<a href="https://www.linkedin.com/in/lu-dong-71bbb0224/"> <img src="./files/logo-linkin.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
                </p>
			</td>
			<td valign="middle">
				<img src="./files/LuDong.jpg" border="0" width="139"><br><br>
			</td>
		</tr>
	</tbody>
</table>









<h2>About Me</h2>
	<p style="text-align:justify;">I am a Ph.D. student (2021-Present) at the Department of Computer Science and Engineering (CSE), <a href="https://www.buffalo.edu">University at Buffalo-The State University of New York (UB) </a>, working with <a href="https://scholar.google.com/citations?user=pCOmTY0AAAAJ&hl=en"> Prof. Ifeoma Nwogu </a> at the Human Behavior Modeling Lab. Prior to my Ph.D. studies, I obtained a Master's degree in Computer Science and Technology from the School of Computer Science and Technology at <a href="http://en.xjtu.edu.cn/">Xi'an Jiaotong University (XJTU) </a> in China, where I was advised by  <a href="https://gr.xjtu.edu.cn/web/xyyang">Prof. Xinyu Yang </a> at the<a href="https://gr.xjtu.edu.cn/web/xyyang/11"> YLab </a>. 
	</p>
	<p style="text-align:justify;">My research focuses on computer vision (CV), large language models (LLMs), 3D human body and face modeling, AI-generated content (AIGC), and their applications in various aspects of human behavior, including sign language, children's education, and VR/AR. I am open to postdoctoral positions, faculty roles, and research-focused opportunities in industry.
	</p>


<h2>News [<img src="./index_files//update.gif">]</h2>

<div style="overflow-y: scroll; height: 200px; max-width: 1050px; margin: 0 auto;">
  <table border="1" style="border-width: 0px; width: 100%;">
    <tbody>
      <tr>
        <td style="border-style: none; border-width: medium;">
          <ul>
			<li type="circle">2025.04: I successfully passed the Ph.D. dissertation proposal defense at CSE Department of UB.
			<li type="circle">2025.03: I was invited to give a talk on AI for Human Behavior at <strong> Women in Tech Western New York </strong>. </li>
            <li type="circle">2024.12: I’m honored to share that I have been awarded the <strong>Best AI Project Award </strong> at the 2024 CSE Poster Competition. </li>
            <li type="circle">2024.11: I will be presenting my work at the EMNLP 2024 Conference on November 12. See you in Miami! </li>
            <li type="circle">2024.10: After a competitive process, six outstanding candidates have advanced to the final phase of <strong>Research Acceleration </strong>. Congratulations to them and best wishes for their continued success! </li>
            <li type="circle">2024.10: We are launching an initiative called the <strong> Research Acceleration Program </strong>, aimed at helping early-stage AI researchers accelerate their growth, focusing on AIGC, Human Motion Generation, with applications in children's educational interactions, sign language synthesis, and social intelligence. UB master's and undergraduate students are encouraged to apply. If you're interested, please feel free to send me your resume. </li>
            <li type="circle">2024.10: Happy to be <strong> invited as a speaker </strong> for a panel discussion on 'AI Research and Career Development' at UB. </li>
            <li type="circle">2024.09: I’ll be presenting my work at ECCV 2024 on September 30 and October 4. See you in Milan, Italy!</li>
            <li type="circle">2024.09: One first-author paper on 3D sign language motion generation has been accepted by  <strong> EMNLP 2024 </strong>. </li>
            <li type="circle">2024.09: I’m honored to share that I have received the <strong> DEI Leadership Award </strong> at the IJCB 2024 Conference. </li>
            <li type="circle">2024.09: I’m excited to serve as the <strong> Local Student Chair </strong> for the IJCB 2024 Conference Organizing Team. </li>
            <li type="circle">2024.08: Two papers have been accepted by <strong> ECCV 2024</strong>: one on enhancing facial expression inference, and the other on open-domain multi-person motion generation. </li>
            <li type="circle">2024.08: I am honored to share that my work has been recognized by National AI Institute for Exceptional Education (AI4ExceptionalEd), the Institute for Artificial Intelligence and Data Science (IAD) and UB-CSE.
              <a href="https://www.linkedin.com/feed/update/urn:li:activity:7227312617697013760/">[Read] </a> <a href="https://www.linkedin.com/posts/ubcse_ubuffalo-signlanguagegeneration-biometrics-activity-7229188970151129088-lRk2/?utm_source=share&utm_medium=member_desktop">[More]</a>. 
            </li>
            <li type="circle">2024.05: I will present my work at FG 2024 Conference on May 27 and 30. See you in Istanbul, Turkey.</li>
            <li type="circle">2024.04: Two papers on sign language generation have been accepted by <strong>FG 2024</strong>.</li>
            <li type="circle">2024.03: I participated in the AI4EE: 
              <a href="https://www.linkedin.com/feed/update/urn:li:activity:7175489894306189312/">Year 1 Annual Review Site Visit </a>
              and presented our work in the event.</li>
            <li type="circle">2023.09: The National AI Institute for Exceptional Education 
              <a href="https://www.buffalo.edu/ai4exceptionaled.html">(AI4EE)</a> will support my research aimed at analyzing and modeling children's non-verbal behaviors, such as facial expressions and body gestures, to enhance educational performance.
            </li>
            <li type="circle">2023.08: I was invited to <strong>give a talk</strong> on Internships in the course CSE501, Fall2023, UB.</li>
            <li type="circle">2023.07: One paper on human motion synthesis has been accepted by <strong>ACM MM 2023</strong>.</li>
            <li type="circle">2023.06: I successfully passed my Oral Qualifying Exam (<strong>OQE</strong>) and became a PhD candidate at UB.</li>
            <li type="circle">2023.05: Started my research intern journey at <strong>InnoPeak Technology</strong> (OPPO US Research) in Seattle, WA. (on-site)</li>
            <li type="circle">2022.11: I was invited to be a <strong>judge</strong> of the 2022 <strong>UB Hacking Competition!</strong></li>
            <li type="circle">2022.10: I was invited to <strong>give a talk</strong> in the course CSE501, Fall2022, UB.</li>
            <li type="circle">2022.05: Started my research intern journey at <strong>InnoPeak Technology</strong> (OPPO US Research) in Palo Alto, CA. (on-site)</li>
            <li type="circle">2021.08: Started my Ph.D. journey following my advisor at <strong>UB</strong>, Buffalo, NY.</li>
          </ul>
          <br>
        </td>
      </tr>
    </tbody>
  </table>
</div>










<h2>Selected Research</h2>


<div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/autoMisty.png);"></div>
	<div class="row-text">
		<a href="https://wangxiaoshawn.github.io/AutoMisty.html" target="_blank"><strong>AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in the Misty Social Robot</strong><br/></a>
		Xiao Wang*, <strong>Lu Dong*</strong>,  Sahana Rangasrinivasan, Ifeoma Nwogu, Srirangaraj Setlur, Venu Govindaraju <br/> 
		International Conference on Intelligent Robots and Systems <strong> (IROS2025 under review)</strong> <br/> 
		<a class="btn btn-orange" href=" ">DOI</a> 
		<a class="btn btn-red" href="https://arxiv.org/pdf/2503.06791">PDF</a>
		<a class="btn" href=" ">BibTeX</a>
    <a class="btn" href="https://wangxiaoshawn.github.io/AutoMisty.html" target="_blank"> Project Webpage </a>
	</div>
  </div>



  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/EMNLP.gif);"></div>
	<div class="row-text">
		<a href="wSignGen.html" target="_blank"><strong>Word-Conditioned 3D American Sign Language Motion Generation</strong><br/></a>
    <strong>Lu Dong</strong>, Xiao Wang, Ifeoma Nwogu. <br/> 
    In Findings of the Association for Computational Linguistics <strong> EMNLP 2024</strong> <br/> 
		<a class="btn btn-orange" href=" ">DOI</a> 
		<a class="btn btn-red" href="https://aclanthology.org/2024.findings-emnlp.584/">PDF</a>
		<a class="btn" href="https://aclanthology.org/2024.findings-emnlp.584/">BibTeX</a>
    <a class="btn" href="wSignGen.html" target="_blank"> Project Webpage </a>
	</div>
  </div>







  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/ECCVW.gif);"></div>
	<div class="row-text">
		<a href="Ig3D.html" target="_blank"><strong>Ig3D: Integrating 3D Face Representations in Facial Expression Inference</strong><br/></a>
    <strong>Lu Dong*</strong>, Xiao Wang*, Srirangaraj Setlur, Venu Govindaraju, Ifeoma Nwogu. <br/> 
    The 18th European Conference on Computer Vision <strong>(ECCV 2024)</strong> Workshop <br/> 
		<a class="btn btn-orange" href=" ">DOI</a> 
		<a class="btn btn-red" href=" ">PDF</a>
		<a class="btn" href=" ">BibTeX</a>
    <a class="btn" href="Ig3D.html" target="_blank"> Project Webpage </a>
	</div>
  </div>





  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/MMPG.gif);"></div>
	<div class="row-text">
		<a href="https://shanmy.github.io/Multi-Motion/" target="_blank"><strong>Towards Open Domain Text-Driven Synthesis of Multi-Person Motions</strong><br/></a>
    Mengyi Shan, <strong>Lu Dong</strong>, Yutao Han, Yuan Yao, Tao Liu, Ifeoma Nwogu, Guo-Jun Qi, Mitch Hill. <br/>
    The 18th European Conference on Computer Vision <strong> (ECCV 2024) </strong> <br/>
		<a class="btn btn-orange" href=" ">DOI</a> 
		<a class="btn btn-red" href="https://shanmy.github.io/Multi-Motion/static/pdfs/Multi_Person_Human_Motion_Diffusion_Model.pdf">PDF</a>
		<a class="btn" href=" ">BibTeX</a>
    <a class="btn" href="https://shanmy.github.io/Multi-Motion/" target="_blank"> Project Webpage </a>
	</div>
  </div>





  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/SignAvatar_Quick.gif);"></div>
	<div class="row-text">
		<a href="SignAvatar.html" target="_blank"><strong>SignAvatar: Sign Language 3D Motion Reconstruction and Generation</strong><br/></a>
    <strong>Lu Dong</strong>, Lipisha Chaudhary, Fei Xu, Xiao Wang, Mason Lary, Ifeoma Nwogu. <br/>
		<span class="italic"></i>The 18th IEEE International Conference on Automatic Face and Gesture Recognition (<strong>FG</strong>), 2024. </span><br/>
		<a class="btn btn-orange" href=" ">DOI</a> 
		<a class="btn btn-red" href="">PDF</a>
		<a class="btn" href=" ">BibTeX</a>
		<a class="btn" href="SignAvatar.html" target="_blank"> Project Webpage </a>
	</div>
  </div>




  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/FG_fei.gif);"></div>
	<div class="row-text">
		<a href="SignAvatar.html"><strong>A Comparative Study of Video-based Human Representations for American Sign Language Alphabet Generation </strong><br/></a>
    FeiXu, Lipisha Chaudhary, <strong>Lu Dong</strong>, Srirangaraj Setlur, Venu Govindaraju, Ifeoma Nwogu. <br/>
		<span class="italic"></i>The 18th IEEE International Conference on Automatic Face and Gesture Recognition (<strong>FG</strong>) Workshop, 2024. </span><br/>
		<a class="btn btn-orange" href=" ">DOI</a> 
		<a class="btn btn-red" href="">PDF</a>
		<a class="btn" href=" ">BibTeX</a>
	</div>
  </div>



  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/ATOM.gif);"></div>
	<div class="row-text">
		<a href="https://www.yhzhai.com/publication/mm-2023-atom/"><strong>Language-guided Human Motion Synthesis with Atomic Actions</strong><br/></a>
    Yuanhao Zhai, Mingzhen Huang, Tianyu Luan,  <strong>Lu Dong </strong>, Ifeoma Nwogu, Siwei Lyu, David Doermann, Junsong Yuan <br/>
		<span class="italic"></i>ACM Multimedia (<strong>MM</strong>), 2023. </span><br/>
    <span class="italic"></i>Please check title link for more details.</span><br/>
		<a class="btn btn-orange" href=" ">DOI</a> 
		<a class="btn btn-red" href="https://arxiv.org/abs/2308.09611">PDF</a>
		<a class="btn" href="bibs/xintianyou.txt">BibTeX</a>
    <a class="btn" href="https://www.yhzhai.com/publication/mm-2023-atom/"> Project Webpage </a>
	</div>
  </div>




  <h3>Previous</h3>

  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/Music.gif);"></div>
	<div class="row-text">
		<a href="Music.html"><strong>Exploring the General Melodic Characteristics of XinTianYou Folk Songs</strong><br/></a>
		Juan Li, <strong>Lu Dong</strong>, Jianhang Ding, Xinyu Yang<br/>
		<span class="italic"></i>12th Sound and Music Computing Conference(<strong>SMC</strong>) </span><br/>
		<a class="btn btn-orange" href="https://zenodo.org/record/851035#.Y2nrz-yZPeo">DOI</a> 
		<a class="btn btn-red" href="https://www.semanticscholar.org/paper/Exploring-the-General-Melodic-Characteristics-of-Li-Dong/2ccbf8ede81c2f41320cd046d045898cd9325b84">PDF</a>
		<a class="btn" href="bibs/ATOM.txt">BibTeX</a>
    <a class="btn" href="Music.html">Project Webpage</a>
	</div>
  </div>




<h2>Selected Project</h2>

  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/Human_Pose.gif);">   </div>
	<div class="row-text" align="justify">
	 <a href="Human_Pose.html">	<strong> A smooth 3D Human Pose Estimation pipeline for video in the wild </strong> <br/></a>
The majority of current models have been trained on limited close set data, which often results in subpar performance when applied to real-world video data. One of the major challenges in this context is the issue of self-occlusion, which refers to instances where parts of a subject's body obstruct or cover other parts. This results in a less smooth and precise performance. This project aims to tackle this issue.
<br/>
    <span class="italic"></i>Please check title link for more details.</span><br/>
	</div>
  </div>




  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/Training_chatbot.gif);"></div>
	<div class="row-text" align="justify">
	 <a href="chatbot.html">	<strong> A Training ChatBot to facilitate medical knowledge dissemination in underdeveloped regions</strong> <br/></a>
This project is undertaken in providing for support for a non-profit organization with the aim of addressing the lack of medical knowledge in underdeveloped regions of India. This shortfall leads to an alarming number of preventable fatalities each year. We have developed a training chatbot to enhance the understanding of medical knowledge and local resources by volunteers and the local population. The chatbot will serve as an educational tool to improve medical literacy and ultimately, save lives.<br/>
    <span class="italic"></i>Please check title link for more details.</span><br/>
	</div>
  </div>	



  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/covid_search_engine.gif);"></div>
	<div class="row-text" align="justify">
	 <a href="covid_search.html">	<strong> A Covid Analysis Search Engine: Dissecting Twitter data to analyze government & public attitude towards Covid and Vaccines</strong> <br/></a>
Do authoritative figures have any influence on the trend of COVID-19, what is the attitude of the general public toward COVID-19 and vaccines, whether changes in public attitudes are influenced by authoritative speech? The aim of this project is to design and develop a full-stack search engine that integrates advanced functionalities for retrieval, translation, sentiment analysis, attitude tracking, topic & area statistics, and disinformation detection from multiple dimensions. <br/>
    <span class="italic"></i>Please check title link for more details.</span><br/>
	</div>
  </div>		








<h2>Experience</h2>
  <ul>
   <li type="disc">
    <strong>Research Assitant</strong> National AI Institute for Exceptional Education, University at Buaffalo SUNY (UB), Sep 2023- Now.
		</li>
   <li type="disc">
    <strong>Research Internship </strong> InnoPeak Technology, Seattle, WA, On-Site, June 2023- Aug 2023.
		</li> 
	<li type="disc">
    <strong>Research Internship </strong> InnoPeak Technology, Palo Alto, CA, On-Site, May 2022- Aug 2022.
		</li>  
  <li type="disc">
    <strong>Research Assitant</strong> Human Behavior Modeling Lab, University at Buaffalo SUNY (UB), Aug 2021- Now.
		</li>
  <li type="disc">
    <strong>Research Assitant</strong> Rochester Institute of Technology(RIT), Aug 2020- May 2021.
  	</li>   
  <li type="disc">
    <strong>Senior Data Analyst</strong> Shaanxi Haina Electronic Technology Co.,LT, Sep 2016- Apr 2020.
		</li>    
  <li type="disc">
    <strong>Research Assitant</strong> XI'An Jiaotong University (XJTU), Aug 2013- May 2016.
		</li>    
  </ul>	






<h2>Selected Awards & Honors</h2>

  	<ul>
  		<li type="disc"> <strong> Best AI Project </strong>, CSE Poster Competition 2024. </li>
  		<li type="disc"> <strong> IJCB DEI Leadership Award </strong> 2024. </li>
  	  <li type="disc"> <strong>IEEE FG Travel Grant </strong> 2024. </li>
  	  <li type="disc"> <strong>Outstanding Leadership Award</strong>, Shaanxi Haina Electronic Technology Co.,LT. 2018 </li>
  	  <li type="disc"> <strong>National Graduate Academic Scholarship </strong>, Xi'an Jiaotong University, 2013-2016. </li>
  	  <li type="disc"> <strong>Excellent Postgraduate Student </strong>, Xi'an Jiaotong University, 2014 & 2015.</li>
  	  <li type="disc"> <strong>Silver Metal</strong> for Women's Hurdle at the Intercollegiate Athletic Meet，Xi'an Jiaotong University, 2014. </li>
  	  <li type="disc"> <strong> Champion Team </strong>, CS Department Undergraduate Women’s Basketball— Team Captain, First-time achievement, 2010. </li>
  	  <br>
  	</ul>
​    


<h2>Academic Services</h2>
	<h3>Conference  Reviewer</h3>
	<ul>
		<li type="disc">ACL 2025 (Association for Computational Linguistics) </a></li>
		<li type="disc">ICCV 2025 (International Conference on Computer Vision) </a></li>
		<li type="disc">IEEE CAI 2025 (IEEE Conference on Artificial Intelligence) </a></li>
		<li type="disc">ACM MM 2022, 2023, 2024 (ACM International Conference on Multimedia)</a></li>
	</ul>
	<h3>Journal  Reviewer</h3>
	<ul>
		<li type="disc">SN MVA 2024 (Springer Nature, Machine Vision and Applications) </a></li>
		<li type="disc">IEEE TAFFC 2024 (IEEE Transactions on Affective Computing)</a></li>
	</ul>

  <h3>Conference Organization</h3>
 	<ul>
 	<li type="disc">2024.09  Served as the <strong> Local Student Chair </strong> for IJCB 2024 Conference @ Buffalo, NY. </li>
 	</ul>

  <h3>Competition</h3>

  	<ul>
  		<li type="disc">2022.11.06 Invited as a <strong> Judge </strong> for <a href="https://www.ubhacking.com/"> 2022 UB Hacking Competition. </a></li>
  	</ul>

 <h3>Membership</h3>

  	<ul>
  		<li type="disc">ACL Member. </a></li>
  		<li type="disc">IEEE Student Member. </a></li>
  		<li type="disc">IEEE Biometrics Council Member. </a></li>
  	</ul>


  <h3>Invited Talks</h3>
  	<ul>
		<li type="disc">2025.03: I was invited to give a talk on AI for Human Behavior at <strong> Women in Tech Western New York </strong>.</li>
  		<li type="disc">2024.10: I was invited as a speaker for a panel discussion on 'AI Research and Career Development' at UB.</li>
  	  <li type="disc">2023.8: I was invited to give a talk on Internships in the course CSE501, Fall2023, UB.</li>
  	  <li type="disc">2022.10: Delivering a talk, introducing Human Pose Estimation and Ph.D Life Guidance in the course CSE-501, Fall2022.</li>
  	</ul>






<h2>Selected Photos</h2>

  	
  	<div style="width:100%; max-width:1024px; overflow-x:auto; border:1px solid #ddd; padding:10px; box-sizing:border-box;">
  	    <div style="display:flex; gap:10px;">
			<img src="./files/womenTech.jpg" alt="womenTech" style="height:auto; max-height:200px; width:auto; max-width:100%;"/>
  	    	<img src="./files/emnlp02.jpg" alt="emnlp02" style="height:auto; max-height:200px; width:auto; max-width:100%;"/>
  	    	<img src="./files/emnlp01.jpg" alt="emnlp01" style="height:auto; max-height:200px; width:auto; max-width:100%;"/>
  	        <img src="./files/ECCV01.jpeg" alt="ECCV01" style="height:auto; max-height:200px; width:auto; max-width:100%;"/>
  	        <img src="./files/FG01.jpeg" alt="FG01" style="height:auto; max-height:200px; width:auto; max-width:100%;"/>
  	        <img src="./files/FG02.jpeg" alt="FG02" style="height:auto; max-height:200px; width:auto; max-width:100%;"/>
  	        <img src="./files/FG03.jpeg" alt="FG03" style="height:auto; max-height:200px; width:auto; max-width:100%;"/>
  	        <img src="./files/99.jpeg" alt="99" style="height:auto; max-height:200px; width:auto; max-width:100%;"/>
  	        <img src="./files/66.png" alt="66" style="height:auto; max-height:200px; width:auto; max-width:100%;"/>
  	    </div>
  	</div>


 





<hr>
<table cellpadding="0px">
	<tbody>
		<tr>
			<td width="720px">
			<div id="clustrmaps-widget"></div>
				<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=7seMHMuQZlvELLsuK6wd30IX5cz7U58mGsA8iV8s6_o"></script></script>
				</script>
			<div class="jvectormap-tip"></div>
			</td>
			<td valign="top">
				<div style="clear:both;">
				<p align="right"><font size="2">Last Updated on December, 2024<br>
				</div>
				<div style="clear: both;">
				<p align="right"><font size="5"><img src="./index_files//happy.gif"></font></p>
				</div>
			</td>
		</tr>
	</tbody>
</table>







</body>
</html>