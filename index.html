	<html>

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">	
	<title>Lu Dong</title>
	<meta content="LuDong, Lu Dong UB, lu dong ub, ludong,  https://dongludeeplearning.github.io/" name="keywords">
	<link rel="stylesheet" href="./index_files/jemdoc.css" type="text/css">
	<script async="" src="http://www.google-analytics.com/analytics.js"></script>
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
		ga('create', 'UA-66888300-1', 'auto');
		ga('send', 'pageview');
	</script>
	<script type="text/javascript" src="./index_files/jquery-1.12.4.min.js"></script>
	<style>
	a {color: #2471a3; text-decoration: none;}
	a:hover {color: #5499c7;}
	a.btn {background-color: #2471a3; color: #fff; font-size: 12px; margin-top: 4px; display: inline-block; padding: 0 4px; border-radius: 2px; line-height: 1.5em;}
	a.btn:hover {background-color: #174e74;}
	a.btn.btn-red {background-color: #d63a3a;}
	a.btn.btn-red:hover {background-color: #a02727;}
	a.btn.btn-orange {background-color: #e2700c;}
	a.btn.btn-orange:hover {background-color: #c46009;}
	a.btn.btn-dark {background-color: #345;}
	a.btn.btn-dark:hover {background-color: #234;}
	p {line-height: 1.5em;}
	.nobreak {white-space: nowrap;}
	.noselect {-webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none;}
	.bold {font-weight: bold;}
	.italic {font-style: italic;}
	.bulletpoints {line-height: 1.5em;}
	.row {box-sizing: border-box;}
	.row-media {display: block; float: left; width: 280px; height: 150px; background-position: center; background-size: contain; background-repeat: no-repeat; border-radius: 6px; border: 1px solid #def;}
	.row-text {display: block; float: left; margin-left: 16px; line-height: 1.5em; max-width: 552px;}
	.row-text span {line-height: inherit;}
	.clearfix {content: ""; clear: both; display: table;}
	.publication {margin-bottom: 32px; margin-left: 16px;}
	.press {width: 100px; height: 80px; border: 1px solid #def; margin-right: 12px; background-size: cover;}  
	.img-contain {background-size: contain !important;}
	.footer {background-color: #345; width: 100%}
	.footer-content {color: #fff; font-size: 10px; padding: 6px 0; max-width: 900px; margin: auto;}




	@media only screen and (max-width: 1150px) {
		.header-profile-picture, .header-text {display: block; margin: auto; text-align: center;}
		.header-profile-picture {margin-bottom: 12px; width: 140px; height: 140px;}
		body {font-size: 18px;}
		a.btn {font-size: 14px; padding: 2px 6px;}
	}
	
	@media only screen and (max-width: 900px) {
		.publication {margin-bottom: 46px;}
		.publication .row-media {width: 260px; height: 130px; margin: auto; margin-bottom: 12px; display: block;}
		.publication .row-text {display: block; width: 100%; margin-left: 0;}
		.press {display: block;}
	}
	</style>
</head>

<body>

<div id="layout-content" style="margin-top:25px">
<table cellpadding="11px">
	<tbody>
		<tr>
			<td width="720px">
				<div id="toptitle">
					<h1>Lu Dong (董璐) &nbsp; </h1>
				</div>
                <h3>Ph.D. Student</h3>       
				<p>
					<a href="https://engineering.buffalo.edu/computer-science-engineering.html">Department of Computer Science and Engineering</a><br>
					<a href="https://www.buffalo.edu/">University at Buffalo, SUNY (UB)</a><br>
					Davis Hall, Buffalo, New York, U.S.A<br>
					<br>
					Email:  <a href="dongludeeplearning@gmail.com">dongludeeplearning@gmail.com</a><br>
					<br>
					<a href="./files/ML_LuDONG1127.pdf"> <img src="./files/logo-cv.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
					<a href="https://github.com/dongludeeplearning"> <img src="./files/logo-github.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
					<a href="https://www.linkedin.com/in/lu-dong-71bbb0224/"> <img src="./files/logo-linkin.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
                </p>
			</td>
			<td valign="middle">
				<img src="./files/LuDong.jpg" border="0" width="139"><br><br>
			</td>
		</tr>
	</tbody>
</table>



<h2>About Me</h2>
	<p style="text-align:justify;">I am a Ph.D. student (2021-Present) at the Department of Computer Science and Engineering (CSE), <a href="https://www.buffalo.edu">University at Buffalo-The State University of New York (UB) </a>, under the supervision of  <a href="https://engineering.buffalo.edu/computer-science-engineering/people/faculty-directory.host.html/content/shared/engineering/computer-science-engineering/profiles/faculty/nwogu-ifeoma.html"> Prof. Ifeoma Nwogu </a> at the Human Behavior Modeling Lab. Prior to my Ph.D. studies, I obtained a Master's degree in Computer Science and Technology from the School of Computer Science and Technology at <a href="http://en.xjtu.edu.cn/">Xi'an Jiaotong University (XJTU) </a> in China, where I was advised by  <a href="https://gr.xjtu.edu.cn/web/xyyang">Prof. Xinyu Yang </a> at the<a href="https://gr.xjtu.edu.cn/web/xyyang/11"> YLab </a>. 
	</p>
	<p style="text-align:justify;">My research interests are Human Pose Estimation, 3D Mesh Reconstruction, Robotics Physics Simulation,  Multimodal, Language-driven Motion, Sign Language Translation & Generation, and Video Understanding. My long-term goal is primarily in developing Computer Vision, Natural Language Processing, Reinforcement Learning, Statistic Machine Learning, and Mathematical Modeling to study multimodal human behavior and make generative models more effective in serving human needs. Besides, some of my early works are related to Speech Sentiment Analysis, Music Analysis with Machine Learning and Data Science techniques including Data Crawling, Pattern Mining, Information Retrieval, and Search Engine Optimization. Feel free to reach out to me if you are interested in collaborating. I am also actively looking for research intern positions.
	</p>


<h2>News [<img src="./index_files//update.gif">]</h2>
	<div  style="overflow-y: scroll; height:200px;">
	<table border="1" style="border-width: 0px;" width="1050">
	<tbody>
	<tr>
	<td style="border-style: none; border-width: medium;">
	<ul>
		<li type="circle">2022.11: I was invited to be the <strong>judge</strong> of the 2022  <strong>UB Hacking Competition! </strong> </li>
		<li type="circle">2022.10: I was invited to <strong> give a talk </strong> in the course CSE501, Fall2022, UB.</li>
		<li type="circle">2022.05: Start my internship at <strong> OPPO U.S. Research Institute</strong> at Palo Alto, CA. (on-site)</li>
		<li type="circle">2021.08: Start my new Ph.D journey at <strong>UB</strong>, Buffalo, NY.</li>
		<li type="circle">2021.05: I passed the Ph.D Research Potential Assessment at RIT!</li>
		<li type="circle">2020.08: Start my new Ph.D journey at <strong>RIT</strong>, Rochester, NY.</li>
	</ul><br>
	</td>
	</tr>
	</tbody>
	</table>
	</div>

<h2>Selected Research</h2>

  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/AtomVAE_Demo.gif);"></div>
	<div class="row-text" align="justify">
		<strong>AtomVAE: Towards Zero-Shot Text-to-Motion Synthesis (CVPR 2023 under review)</strong> <br/>
Human motion synthesis is an important task due to its wide applications in computer graphics, human behavior understanding, human-robotic interactions, etc. Existing methods focus on closed-set human action synthesis, limiting their ability to generate actions of novel classes that are not seen during training. To address this problem, we propose AtomVAE for zero-shot text-to-motion synthesis, which aims to generate novel categories of actions that do not belong to the training set. Specifically, the proposed AtomVAE learns a mapping from the input text space that describes the action to the output motion space that represent the action, using limited number of training labels. To facilitate zero-shot text-to-motion synthesis, we propose to decompose seen actions into a set of atomic actions, such that by leveraging the similarity between input text and the learned atomic actions, our model can learn to compose novel actions using the atomic actions. The atomic actions are learned in an end-to-end manner, with diversity and sparsity constrains enforcing the atomicity and robustness. Our method not only achieves promising results on zero-shot synthesis, but also outperforms state-of-the-art approaches by a large margin in the traditional closed-set synthesis task.<br/>
	</div>
  </div>  



  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/SignClip.png);"></div>
	<div class="row-text" align="justify">
		<strong>SignCLIP: A New Framework for Sign Language 3D Mesh Generation using CLIP </strong> <br/>
Similar to any language, understanding and communicating sign language can be quite challenging. To make sign language spread over multiple ways like other languages, we proposed a framework to generate 3D mesh sign videos from the image or text. Specifically, we applied SMPL-X model to get the expressive pose including the upper body, face, and hands. Then the Transformer-based model has been applied to analyze and reconstruct the pose sequences. Moreover, we introduced the CLIP model to improve performance when matching the image, text and sign sequence. Our work builds a new baseline for the sign language generation community. Experiments showcase that our model not only achieves promising results on zero-shot generation but also proved can be better understood by the community.<br/>
	</div>
  </div>


  <h3>Previous</h3>

  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/Music.gif);"></div>
	<div class="row-text">
		<a href="Music.html"><strong>Exploring the General Melodic Characteristics of XinTianYou Folk Songs</strong><br/></a>
		Juan Li, <strong>Lu Dong</strong>, Jianhang Ding, Xinyu Yang<br/>
		<span class="italic"></i>12th Sound and Music Computing Conference(<strong>SMC</strong>) </span><br/>
    <span class="italic"></i>Please check title link for more details.</span><br/>
		<a class="btn btn-orange" href="https://zenodo.org/record/851035#.Y2nrz-yZPeo">DOI</a> 
		<a class="btn btn-red" href="https://github.com/dongludeeplearning/MIR/blob/master/Exploring%20the%20General%20Melodic%20Characteristics%20of%20XinTianYou%20Folk%20Songs.pdf">PDF</a>
		<a class="btn" href="bibs/xintianyou.txt">BibTeX</a>
	</div>
  </div>



<h2>Selected Project</h2>

  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/Human_Pose.gif);">   </div>
	<div class="row-text" align="justify">
	 <a href="Human_Pose.html">	<strong> A smooth 3D Human Pose Estimation pipeline for video in the wild</strong> <br/></a>
The majority of current models have been trained on limited close set data, which often results in subpar performance when applied to real-world video data. One of the major challenges in this context is the issue of self-occlusion, which refers to instances where parts of a subject's body obstruct or cover other parts. This results in a less smooth and precise performance. This project aims to tackle this issue.
<br/>
    <span class="italic"></i>Please check title link for more details.</span><br/>
	</div>
  </div>



  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/Training_chatbot.gif);"></div>
	<div class="row-text" align="justify">
	 <a href="chatbot.html">	<strong> A Training ChatBot to facilitate medical knowledge dissemination in underdeveloped regions</strong> <br/></a>
This project is undertaken in providing for support for a non-profit organization with the aim of addressing the lack of medical knowledge in underdeveloped regions of India. This shortfall leads to an alarming number of preventable fatalities each year. We have developed a training chatbot to enhance the understanding of medical knowledge and local resources by volunteers and the local population. The chatbot will serve as an educational tool to improve medical literacy and ultimately, save lives.<br/>
    <span class="italic"></i>Please check title link for more details.</span><br/>
	</div>
  </div>	



  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/covid_search_engine.gif);"></div>
	<div class="row-text" align="justify">
	 <a href="covid_search.html">	<strong> A Covid Analysis Search Engine: Dissecting Twitter data to analyze government & public attitude towards Covid and Vaccines</strong> <br/></a>
Do authoritative figures have any influence on the trend of COVID-19, what is the attitude of the general public toward COVID-19 and vaccines, whether changes in public attitudes are influenced by authoritative speech? The aim of this project is to design and develop a full-stack search engine that integrates advanced functionalities for retrieval, translation, sentiment analysis, attitude tracking, topic & area statistics, and disinformation detection from multiple dimensions. <br/>
    <span class="italic"></i>Please check title link for more details.</span><br/>
	</div>
  </div>		










<h2>Experience</h2>
  <ul>
	<li type="disc">
    <strong>Research Internship </strong> OPPO US Research Institute, Palo Alto, CA, On-Site, May 2022- Aug 2022.
		</li>  
  <li type="disc">
    <strong>Research Assitant</strong> University at Buaffalo SUNY (UB), Aug 2021- Now.
		</li>
  <li type="disc">
    <strong>Research Assitant</strong> Rochester Institute of Technology(RIT), Aug 2020- May 2021.
  	</li>   
  <li type="disc">
    <strong>Senior Data Analyst</strong> Shaanxi Haina Electronic Technology Co.,LT, Sep 2016- Apr 2020.
		</li>    
  <li type="disc">
    <strong>Research Assitant</strong> XI'An Jiaotong University (XJTU), Aug 2013- May 2016.
		</li>    
  </ul>	




<h2>Selected Awards & Honors</h2>
  <h3>Awards</h3>
  	<ul>
      <li type="disc"> <strong>Outstanding Leadership Award</strong>, Shaanxi Haina Electronic Technology Co.,LT. 2018 </li>
      <li type="disc"> <strong>National Graduate Academic Scholarship </strong>, Xi'an Jiaotong University (XJTU), 2013-2016. </li>
      <li type="disc"> <strong>Silver Metal</strong>, Universiade Women's Hurdle，Xi'an Jiaotong University (XJTU), 2014. </li>
      <li type="disc"> <strong>National Encouragement Scholarship</strong>, Northeast Electric Power University (NEEPU), 2010.(top 5%) </li>
      <li type="disc"> <strong>The Academic Scholarship </strong>, Northeast Electric Power University (NEEPU), 2010. (top 10%) </li>
      <li type="disc"> <strong>Champion & MVP </strong>, College Women's Basketball of NEEPU, 2010. </li>
      <br>
</ul>      
  <h3>Honors</h3>
  	<ul>
      <li type="disc"> <strong>Excellent Postgraduate Student </strong>, XI'an Jiaotong University (XJTU), 2014 & 2015. (top 10%)</li>
      <li type="disc"> <strong>Outstanding Leadership among Students</strong>, Northeast Electric Power University (NEEPU), 2010. (top 3 /120)</li> 
      <li type="disc"> <strong>Excellent Undergraduate Student </strong>,Northeast Electric Power University (NEEPU).(top 10%)</li> 
</ul>






<h2>Academic Services</h2>
  <h3>Competition</h3>

  	<ul>
  		<li type="disc">2022.11.06 I was invited as a <strong> Judge </strong> for <a href="https://www.ubhacking.com/"> 2022 UB Hacking Competition. </a></li>
  	</ul>



  <h3>Talks</h3>
  	<ul>
  		<li type="disc">2022.10.18: Delivering a talk, introducing Human Pose Estimation and Ph.D Life Guidance in the course CSE-501, Fall2022.</li>
  	</ul>





<h2>Selected Photos</h2>

  	<ul>
  		<div style="width:960px;overflow-x:scroll">
  		<div style="width:2280px">
        <img src="./files/66.png"  border="0" width="390"/>
        <img src="./files/33.jpeg"  border="0" width="390"/>
        <img src="./files/intern.jpeg"  border="0" width="360"/>
 		 	 	<img src="./files/11.png" border="0" width="380"/>
        <img src="./files/77.png" border="0" width="290"/>
 		  </div>
			</div>
  	</ul>



<hr>
<table cellpadding="0px">
	<tbody>
		<tr>
			<td width="720px">
			<div id="clustrmaps-widget"></div>
				<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=7seMHMuQZlvELLsuK6wd30IX5cz7U58mGsA8iV8s6_o"></script></script>
				</script>
			<div class="jvectormap-tip"></div>
			</td>
			<td valign="top">
				<div style="clear:both;">
				<p align="right"><font size="2">Last Updated on Feb, 2023<br>
				</div>
				<div style="clear: both;">
				<p align="right"><font size="5"><img src="./index_files//happy.gif"></font></p>
				</div>
			</td>
		</tr>
	</tbody>
</table>




</body>
</html>