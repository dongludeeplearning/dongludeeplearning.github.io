<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Word-Conditioned 3D American Sign Language Motion Generation.">
  <meta name="keywords" content="wSignGen, SMPLX, 3D Mesh">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Word-Conditioned 3D American Sign Language Motion Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Word-Conditioned 3D American Sign Language Motion Generation </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://dongludeeplearning.github.io/">Lu Dong</a>,</span>
            <span class="author-block">
              <a href="https://wangxiaoshawn.github.io/">Xiao Wang</a>,</span>
            <span class="author-block">
              <a href=" ">Ifeoma Nwogu</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University at Buffalo,SUNY</span>

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://aclanthology.org/2024.findings-emnlp.584/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Poster Link. -->
              <span class="link-block">
                <a href="./files/pubs/EMNLP2056_Poster.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Poster</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="./files/pubs/EMNLP2056_Video.mp4"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/dongludeeplearning/wsigngen"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link.
              <span class="link-block">
                <a href=" "
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./files/pubs/wSignGen01.png" alt="SignAvatar Teaser" style="width:90%; height:auto; margin-left:3%">
      <h2 class="subtitle has-text-centered" style="font-size:16px">
        <span class="dnerf"> wSignGen </span>  Top row: given a text word in dataset, wSignGen can generate a 3D signing avatar corresponding to that
        word. Also, wSignGen supports unseen but semantically close words. 
        Bottom row: given a semantically meaningful
        image, the closest associated word is identified via CLIP and wSignGen generates the corresponding sign.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p style="text-align:justify;">  Sign words are the fundamental building blocks of any sign language. 
            In this work, we introduce wSignGen, a word-conditioned 3D American Sign Language (ASL) generation model designed to synthesize realistic and grammatically accurate motion sequences for signed words. 
            Our approach employs a transformer-based diffusion model, trained and evaluated on a curated dataset of 3D motion mesh sequences derived from word-level ASL videos. 
            By integrating CLIP, wSignGen offers two advantages: image-based generation, which is beneficial for non-English speakers and learners, and generalization to unseen synonyms. 
            Experimental results demonstrate that wSignGen significantly outperforms the baseline model. 
            Moreover, human evaluation experiments show that wSignGen can generate high-quality, grammatically correct ASL signs effectively conveyed through 3D avatars.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <section class="main-idea">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img src="./files/pubs/wSignGen02.png" alt="SignAvatar" style="width:90%; height:auto; margin-left:5%">
          <h2 class="subtitle has-text-centered">
            <span class="dnerf"> wSignGen Overview</span> 
          </h2>
        </div>
      </div>
    </section>


<!-- 
  <section class="main-idea">
    <div class="container is-max-desktop">
      <div class="main-body">
        <img src="./files/pubs/SignAvatar_p2.png" alt="SignAvatar" style="width:90%; height:auto; margin-left:5%">
        <h2 class="subtitle has-text-centered" style="font-size:16px">
          <span class="dnerf"> SignAvatar Pipeline</span> The upper row represents the reconstruction process, absorbing knowledge and analyzing their relationships, while the lower row
          indicates the generation process, which outputs knowledge. Unlike the rigid mapping of sign language production, the input text or images
          in sign language generation showcase greater semantic flexibility.
        </h2>
      </div>
    </div>
  </section> -->

  <!-- <section class="main-idea">
    <div class="container is-max-desktop">
      <div class="main-body">
        <img src="./files/pubs/SignAvatar_book.png" alt="SignAvatar" style="width:100%; height:auto">
        <h2 class="subtitle has-text-centered" style="font-size:16px">
          <span class="dnerf"> SignAvatar </span> can accept images as input. Given an image on the left, and using the text-image embedding of CLIP, SignAvatar can
          recognize the corresponding semantics - "book", and generate the corresponding 3D signing motion. The upper row is the front view and
          the lower row is the side view.
        </h2>
      </div>
    </div>
  </section> -->
    
<!-- </section> -->

<section class="main-idea">
  <div class="container is-max-desktop">
    <div class="main-body">
      <video width="90%" style="margin-left:5%" controls>
        <source src="./files/pubs/EMNLP2056_Video.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <h2 class="subtitle has-text-centered" style="font-size:16px">
        <span class="dnerf"> wSignGen Video</span> 
      </h2>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{dong2024word,
  title     = {Word-Conditioned 3D American Sign Language Motion Generation},
  author    = {Dong, Lu and Wang, Xiao and Nwogu, Ifeoma},
  year      = {2024},
  organization = {Association for Computational Linguistics}
}</code></pre>
  </div>
</section>

Website template modified from <a href="https://nerfies.github.io/" target="_blank">NeRFies</a>.
</body>
</html>
