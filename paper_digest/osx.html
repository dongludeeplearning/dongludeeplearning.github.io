<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ CVPR 2023
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">One-Stage 3D Whole-Body Mesh Recovery with Component Aware Transformer</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Jing Lin, Ailing Zeng, Haoqian Wang, Lei Zhang, Yu Li<br>
        <span style="opacity:0.8">Multiple Institutions</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How can we accurately estimate 3D human body, face, and hands parameters from a single image using a single network, despite resolution issues where face and hands are located in extremely small regions, without requiring separate networks and manual post-processing fusion?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å°½ç®¡é¢éƒ¨å’Œæ‰‹éƒ¨ä½äºæå°çš„åŒºåŸŸå­˜åœ¨åˆ†è¾¨ç‡é—®é¢˜ï¼Œå¦‚ä½•åœ¨ä¸ä½¿ç”¨å•ç‹¬ç½‘ç»œå’Œæ‰‹åŠ¨åå¤„ç†èåˆçš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨å•ä¸ªç½‘ç»œä»å•å¼ å›¾åƒå‡†ç¡®ä¼°è®¡3Däººä½“ã€é¢éƒ¨å’Œæ‰‹éƒ¨å‚æ•°ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>One-Stage Whole-Body Pipeline (OSX):</b> Introduced OSX, a one-stage pipeline for expressive whole-body mesh recovery without separate networks for each body part, avoiding implausible 3D rotations and unnatural poses that arise from late fusion of body, face, and hand predictions.</div>
            <div class="lang-zh" style="display:none"><b>å•é˜¶æ®µå…¨èº«æµç¨‹ï¼ˆOSXï¼‰ï¼š</b>å¼•å…¥OSXï¼Œä¸€ä¸ªç”¨äºè¡¨è¾¾æ€§å…¨èº«ç½‘æ ¼æ¢å¤çš„å•é˜¶æ®µæµç¨‹ï¼Œæ— éœ€ä¸ºæ¯ä¸ªèº«ä½“éƒ¨ä½ä½¿ç”¨å•ç‹¬ç½‘ç»œï¼Œé¿å…äº†ç”±èº«ä½“ã€é¢éƒ¨å’Œæ‰‹éƒ¨é¢„æµ‹çš„åæœŸèåˆå¼•èµ·çš„ä¸å¯ä¿¡çš„3Dæ—‹è½¬å’Œä¸è‡ªç„¶å§¿æ€ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Component Aware Transformer (CAT):</b> Designed CAT composed of a global body encoder and a local face/hand decoder. The encoder predicts body parameters and provides high-quality feature maps for the decoder, which performs feature-level upsample-crop to extract high-resolution part-specific features.</div>
            <div class="lang-zh" style="display:none"><b>ç»„ä»¶æ„ŸçŸ¥Transformerï¼ˆCATï¼‰ï¼š</b>è®¾è®¡äº†CATï¼Œç”±å…¨å±€èº«ä½“ç¼–ç å™¨å’Œå±€éƒ¨é¢éƒ¨/æ‰‹éƒ¨è§£ç å™¨ç»„æˆã€‚ç¼–ç å™¨é¢„æµ‹èº«ä½“å‚æ•°å¹¶ä¸ºè§£ç å™¨æä¾›é«˜è´¨é‡ç‰¹å¾å›¾ï¼Œè§£ç å™¨æ‰§è¡Œç‰¹å¾çº§ä¸Šé‡‡æ ·è£å‰ªä»¥æå–é«˜åˆ†è¾¨ç‡éƒ¨åˆ†ç‰¹å®šç‰¹å¾ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Keypoint-Guided Deformable Attention:</b> The decoder adopts keypoint-guided deformable attention to estimate hand and face parameters precisely, enabling the model to focus on fine-grained details in extremely small regions where face and hands are typically located.</div>
            <div class="lang-zh" style="display:none"><b>å…³é”®ç‚¹å¼•å¯¼çš„å¯å˜å½¢æ³¨æ„åŠ›ï¼š</b>è§£ç å™¨é‡‡ç”¨å…³é”®ç‚¹å¼•å¯¼çš„å¯å˜å½¢æ³¨æ„åŠ›æ¥ç²¾ç¡®ä¼°è®¡æ‰‹å’Œé¢éƒ¨å‚æ•°ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå…³æ³¨é€šå¸¸ä½äºæå°åŒºåŸŸçš„é¢éƒ¨å’Œæ‰‹éƒ¨çš„ç»†ç²’åº¦ç»†èŠ‚ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>UBody Dataset:</b> Built a large-scale Upper-Body dataset (UBody) with high-quality 2D and 3D whole-body annotations, containing persons with partially visible bodies in diverse real-life scenarios to bridge the gap between basic tasks and downstream applications.</div>
            <div class="lang-zh" style="display:none"><b>UBodyæ•°æ®é›†ï¼š</b>æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„ä¸ŠåŠèº«æ•°æ®é›†ï¼ˆUBodyï¼‰ï¼Œå…·æœ‰é«˜è´¨é‡çš„2Då’Œ3Då…¨èº«æ ‡æ³¨ï¼ŒåŒ…å«åœ¨å¤šæ ·åŒ–çœŸå®åœºæ™¯ä¸­éƒ¨åˆ†å¯è§èº«ä½“çš„äººå‘˜ï¼Œä»¥å¼¥åˆåŸºæœ¬ä»»åŠ¡ä¸ä¸‹æ¸¸åº”ç”¨ä¹‹é—´çš„å·®è·ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Resolution Issues:</b> Face and hands are usually located in extremely small regions in full-body images, making it extremely challenging to perform whole-body mesh recovery with a single network due to limited resolution and detail visibility.</div>
            <div class="lang-zh" style="display:none"><b>åˆ†è¾¨ç‡é—®é¢˜ï¼š</b>é¢éƒ¨å’Œæ‰‹éƒ¨é€šå¸¸ä½äºå…¨èº«å›¾åƒä¸­æå°çš„åŒºåŸŸï¼Œç”±äºåˆ†è¾¨ç‡æœ‰é™å’Œç»†èŠ‚å¯è§æ€§ï¼Œä½¿ç”¨å•ä¸ªç½‘ç»œæ‰§è¡Œå…¨èº«ç½‘æ ¼æ¢å¤æå…¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Copy-Paste Pipeline Limitations:</b> Existing works usually detect hands and faces, enlarge their resolution to feed into specific networks, and finally fuse results. While this pipeline captures fine-grained details, connections between different parts cannot be easily recovered in late fusion, leading to implausible 3D rotations and unnatural poses.</div>
            <div class="lang-zh" style="display:none"><b>å¤åˆ¶ç²˜è´´æµç¨‹é™åˆ¶ï¼š</b>ç°æœ‰å·¥ä½œé€šå¸¸æ£€æµ‹æ‰‹å’Œé¢éƒ¨ï¼Œæ”¾å¤§å…¶åˆ†è¾¨ç‡è¾“å…¥åˆ°ç‰¹å®šç½‘ç»œï¼Œæœ€åèåˆç»“æœã€‚è™½ç„¶è¿™ç§æµç¨‹æ•è·äº†ç»†ç²’åº¦ç»†èŠ‚ï¼Œä½†ä¸åŒéƒ¨åˆ†ä¹‹é—´çš„è¿æ¥æ— æ³•åœ¨åæœŸèåˆä¸­è½»æ¾æ¢å¤ï¼Œå¯¼è‡´ä¸å¯ä¿¡çš„3Dæ—‹è½¬å’Œä¸è‡ªç„¶å§¿æ€ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Component Integration:</b> Simultaneously modeling body, face, and hands with proper spatial relationships and avoiding discontinuities at joints requires sophisticated architecture design that can handle multi-scale features and component-specific representations.</div>
            <div class="lang-zh" style="display:none"><b>ç»„ä»¶é›†æˆï¼š</b>åŒæ—¶å»ºæ¨¡èº«ä½“ã€é¢éƒ¨å’Œæ‰‹éƒ¨å¹¶ä¿æŒé€‚å½“çš„ç©ºé—´å…³ç³»ï¼Œé¿å…å…³èŠ‚å¤„çš„ä¸è¿ç»­æ€§ï¼Œéœ€è¦èƒ½å¤Ÿå¤„ç†å¤šå°ºåº¦ç‰¹å¾å’Œç»„ä»¶ç‰¹å®šè¡¨ç¤ºçš„å¤æ‚æ¶æ„è®¾è®¡ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Lack of Training Data:</b> Existing datasets lack comprehensive whole-body annotations with high-quality 2D and 3D labels, especially for scenarios with partially visible bodies in diverse real-life situations, limiting model training and evaluation.</div>
            <div class="lang-zh" style="display:none"><b>ç¼ºä¹è®­ç»ƒæ•°æ®ï¼š</b>ç°æœ‰æ•°æ®é›†ç¼ºä¹å…·æœ‰é«˜è´¨é‡2Då’Œ3Dæ ‡ç­¾çš„å…¨é¢å…¨èº«æ ‡æ³¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ ·åŒ–çœŸå®åœºæ™¯ä¸­éƒ¨åˆ†å¯è§èº«ä½“çš„æƒ…å†µï¼Œé™åˆ¶äº†æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <div style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>OSX uses Component Aware Transformer (CAT) for one-stage whole-body mesh recovery:</p>
            <ol style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>Global Body Encoder:</b> Processes the full-body image and predicts body parameters (SMPL-X) while generating high-quality feature maps that preserve spatial information and multi-scale features necessary for face and hand reconstruction.</li>
                <li style="margin-bottom:6px;"><b>Local Face/Hand Decoder:</b> Uses the high-quality feature maps from the encoder and performs feature-level upsample-crop scheme to extract high-resolution part-specific features for face and hands, addressing resolution issues without separate detection and cropping stages.</li>
                <li style="margin-bottom:6px;"><b>Keypoint-Guided Deformable Attention:</b> Adopts keypoint-guided deformable attention mechanism in the decoder to precisely estimate hand and face parameters by focusing on fine-grained details in extremely small regions, enabling accurate reconstruction despite limited resolution.</li>
                <li style="margin-bottom:6px;"><b>End-to-End Training:</b> The entire pipeline is trained end-to-end without any manual post-processing, naturally avoiding implausible predictions and ensuring consistent spatial relationships between body, face, and hands.</li>
                <li style="margin-bottom:6px;"><b>UBody Dataset:</b> Provides large-scale training data with high-quality 2D and 3D whole-body annotations, including diverse real-life scenarios with partially visible bodies to bridge the gap between basic research and practical applications.</li>
            </ol>
          </div>
          <div class="lang-zh" style="display: none;">
            <p>OSXä½¿ç”¨ç»„ä»¶æ„ŸçŸ¥Transformerï¼ˆCATï¼‰è¿›è¡Œå•é˜¶æ®µå…¨èº«ç½‘æ ¼æ¢å¤ï¼š</p>
            <ol style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>å…¨å±€èº«ä½“ç¼–ç å™¨ï¼š</b>å¤„ç†å…¨èº«å›¾åƒå¹¶é¢„æµ‹èº«ä½“å‚æ•°ï¼ˆSMPL-Xï¼‰ï¼ŒåŒæ—¶ç”Ÿæˆé«˜è´¨é‡ç‰¹å¾å›¾ï¼Œä¿ç•™é¢éƒ¨å’Œæ‰‹éƒ¨é‡å»ºæ‰€éœ€çš„ç©ºé—´ä¿¡æ¯å’Œå¤šå°ºåº¦ç‰¹å¾ã€‚</li>
                <li style="margin-bottom:6px;"><b>å±€éƒ¨é¢éƒ¨/æ‰‹éƒ¨è§£ç å™¨ï¼š</b>ä½¿ç”¨ç¼–ç å™¨çš„é«˜è´¨é‡ç‰¹å¾å›¾ï¼Œæ‰§è¡Œç‰¹å¾çº§ä¸Šé‡‡æ ·è£å‰ªæ–¹æ¡ˆä»¥æå–é¢éƒ¨å’Œæ‰‹éƒ¨çš„é«˜åˆ†è¾¨ç‡éƒ¨åˆ†ç‰¹å®šç‰¹å¾ï¼Œæ— éœ€å•ç‹¬çš„æ£€æµ‹å’Œè£å‰ªé˜¶æ®µå³å¯è§£å†³åˆ†è¾¨ç‡é—®é¢˜ã€‚</li>
                <li style="margin-bottom:6px;"><b>å…³é”®ç‚¹å¼•å¯¼çš„å¯å˜å½¢æ³¨æ„åŠ›ï¼š</b>åœ¨è§£ç å™¨ä¸­é‡‡ç”¨å…³é”®ç‚¹å¼•å¯¼çš„å¯å˜å½¢æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡å…³æ³¨æå°åŒºåŸŸä¸­çš„ç»†ç²’åº¦ç»†èŠ‚æ¥ç²¾ç¡®ä¼°è®¡æ‰‹å’Œé¢éƒ¨å‚æ•°ï¼Œå°½ç®¡åˆ†è¾¨ç‡æœ‰é™ä»èƒ½å®ç°å‡†ç¡®é‡å»ºã€‚</li>
                <li style="margin-bottom:6px;"><b>ç«¯åˆ°ç«¯è®­ç»ƒï¼š</b>æ•´ä¸ªæµç¨‹ç«¯åˆ°ç«¯è®­ç»ƒï¼Œæ— éœ€ä»»ä½•æ‰‹åŠ¨åå¤„ç†ï¼Œè‡ªç„¶é¿å…ä¸å¯ä¿¡é¢„æµ‹å¹¶ç¡®ä¿èº«ä½“ã€é¢éƒ¨å’Œæ‰‹éƒ¨ä¹‹é—´ä¸€è‡´çš„ç©ºé—´å…³ç³»ã€‚</li>
                <li style="margin-bottom:6px;"><b>UBodyæ•°æ®é›†ï¼š</b>æä¾›å…·æœ‰é«˜è´¨é‡2Då’Œ3Då…¨èº«æ ‡æ³¨çš„å¤§è§„æ¨¡è®­ç»ƒæ•°æ®ï¼ŒåŒ…æ‹¬å…·æœ‰éƒ¨åˆ†å¯è§èº«ä½“çš„å¤šæ ·åŒ–çœŸå®åœºæ™¯ï¼Œä»¥å¼¥åˆåŸºç¡€ç ”ç©¶ä¸å®é™…åº”ç”¨ä¹‹é—´çš„å·®è·ã€‚</li>
            </ol>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆå¼•è¨€å›¾ï¼‰</h2>
        <div style="border-radius:14px; overflow:hidden;">
            <img src="Figures/osx_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" onerror="this.style.display='none'; this.parentElement.innerHTML='<div style=\'color:rgba(232,236,255,.5); text-align:center; padding:20px;\'>Intro figure not found. Please add Figures/osx_intro.png</div>'"/>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/osx_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" onerror="this.style.display='none'; this.parentElement.innerHTML='<div style=\'color:rgba(232,236,255,.5); text-align:center; padding:20px;\'>Overview figure not found. Please add Figures/osx_overview.png</div>'"/>
            <div style="height:1px; background:rgba(255,255,255,.10); margin:12px 0;"></div>
            <p>OSX uses Component Aware Transformer (CAT) with a global body encoder and local face/hand decoder for one-stage whole-body mesh recovery. The encoder predicts body parameters and provides high-quality feature maps, while the decoder performs feature-level upsample-crop and keypoint-guided deformable attention to precisely estimate face and hand parameters.</p>
            <p>Note: OSX achieves Top-1 performance on AGORA SMPLX benchmark and demonstrates superior results compared to copy-paste pipelines by naturally avoiding implausible predictions and maintaining consistent spatial relationships between body components. The whole pipeline is simple yet effective without any manual post-processing.</p>

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('arxiv_osx.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('arxiv_osx.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <h3 style="margin:12px 0 6px;font-size:14px;color:#8bffcf;">Why it Works?</h3>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>OSX succeeds by using component-aware architecture and feature-level processing:</p>
            <ul style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>Unified Feature Representation:</b> The global body encoder processes the entire image and generates high-quality feature maps that preserve spatial relationships and multi-scale information, enabling the decoder to access both global context and local details simultaneously.</li>
                <li style="margin-bottom:6px;"><b>Feature-Level Upsample-Crop:</b> Instead of image-level cropping which loses context, OSX performs feature-level upsample-crop to extract high-resolution part-specific features, maintaining spatial relationships while addressing resolution issues for small regions like face and hands.</li>
                <li style="margin-bottom:6px;"><b>Keypoint-Guided Attention:</b> The deformable attention mechanism guided by keypoints enables precise focus on fine-grained details in extremely small regions, allowing accurate parameter estimation despite limited resolution where face and hands are typically located.</li>
                <li style="margin-bottom:6px;"><b>End-to-End Consistency:</b> Training the entire pipeline end-to-end ensures that all components (body, face, hands) are optimized together, naturally avoiding implausible predictions and maintaining consistent spatial relationships without manual post-processing fusion.</li>
                <li style="margin-bottom:6px;"><b>Component-Aware Design:</b> The encoder-decoder architecture with component-specific processing (global for body, local for face/hands) balances between global context understanding and fine-grained detail capture, enabling accurate whole-body mesh recovery.</li>
            </ul>
          </div>
          <div class="lang-zh" style="display:none">
            <p>OSXé€šè¿‡ä½¿ç”¨ç»„ä»¶æ„ŸçŸ¥æ¶æ„å’Œç‰¹å¾çº§å¤„ç†è€ŒæˆåŠŸï¼š</p>
            <ul style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>ç»Ÿä¸€ç‰¹å¾è¡¨ç¤ºï¼š</b>å…¨å±€èº«ä½“ç¼–ç å™¨å¤„ç†æ•´ä¸ªå›¾åƒå¹¶ç”Ÿæˆé«˜è´¨é‡ç‰¹å¾å›¾ï¼Œä¿ç•™ç©ºé—´å…³ç³»å’Œå¤šå°ºåº¦ä¿¡æ¯ï¼Œä½¿è§£ç å™¨èƒ½å¤ŸåŒæ—¶è®¿é—®å…¨å±€ä¸Šä¸‹æ–‡å’Œå±€éƒ¨ç»†èŠ‚ã€‚</li>
                <li style="margin-bottom:6px;"><b>ç‰¹å¾çº§ä¸Šé‡‡æ ·è£å‰ªï¼š</b>OSXæ‰§è¡Œç‰¹å¾çº§ä¸Šé‡‡æ ·è£å‰ªä»¥æå–é«˜åˆ†è¾¨ç‡éƒ¨åˆ†ç‰¹å®šç‰¹å¾ï¼Œè€Œä¸æ˜¯ä¼šä¸¢å¤±ä¸Šä¸‹æ–‡çš„å›¾åƒçº§è£å‰ªï¼Œåœ¨è§£å†³å°åŒºåŸŸï¼ˆå¦‚é¢éƒ¨å’Œæ‰‹éƒ¨ï¼‰åˆ†è¾¨ç‡é—®é¢˜çš„åŒæ—¶ä¿æŒç©ºé—´å…³ç³»ã€‚</li>
                <li style="margin-bottom:6px;"><b>å…³é”®ç‚¹å¼•å¯¼æ³¨æ„åŠ›ï¼š</b>ç”±å…³é”®ç‚¹å¼•å¯¼çš„å¯å˜å½¢æ³¨æ„åŠ›æœºåˆ¶èƒ½å¤Ÿåœ¨æå°åŒºåŸŸç²¾ç¡®å…³æ³¨ç»†ç²’åº¦ç»†èŠ‚ï¼Œå°½ç®¡é€šå¸¸ä½äºæå°åŒºåŸŸçš„é¢éƒ¨å’Œæ‰‹éƒ¨åˆ†è¾¨ç‡æœ‰é™ï¼Œä»èƒ½å®ç°å‡†ç¡®çš„å‚æ•°ä¼°è®¡ã€‚</li>
                <li style="margin-bottom:6px;"><b>ç«¯åˆ°ç«¯ä¸€è‡´æ€§ï¼š</b>ç«¯åˆ°ç«¯è®­ç»ƒæ•´ä¸ªæµç¨‹ç¡®ä¿æ‰€æœ‰ç»„ä»¶ï¼ˆèº«ä½“ã€é¢éƒ¨ã€æ‰‹éƒ¨ï¼‰ä¸€èµ·ä¼˜åŒ–ï¼Œè‡ªç„¶é¿å…ä¸å¯ä¿¡é¢„æµ‹å¹¶åœ¨æ— éœ€æ‰‹åŠ¨åå¤„ç†èåˆçš„æƒ…å†µä¸‹ä¿æŒä¸€è‡´çš„ç©ºé—´å…³ç³»ã€‚</li>
                <li style="margin-bottom:6px;"><b>ç»„ä»¶æ„ŸçŸ¥è®¾è®¡ï¼š</b>å…·æœ‰ç»„ä»¶ç‰¹å®šå¤„ç†ï¼ˆèº«ä½“ä¸ºå…¨å±€ï¼Œé¢éƒ¨/æ‰‹éƒ¨ä¸ºå±€éƒ¨ï¼‰çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„åœ¨å…¨å±€ä¸Šä¸‹æ–‡ç†è§£å’Œç»†ç²’åº¦ç»†èŠ‚æ•è·ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œå®ç°å‡†ç¡®çš„å…¨èº«ç½‘æ ¼æ¢å¤ã€‚</li>
            </ul>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>This groundbreaking work introduces OSX, a one-stage pipeline for expressive 3D whole-body mesh recovery that successfully addresses the resolution challenges in simultaneously reconstructing body, face, and hands from a single image. By designing Component Aware Transformer (CAT) with a global body encoder and local face/hand decoder, OSX effectively handles the multi-scale nature of whole-body reconstruction where face and hands occupy extremely small regions. The feature-level upsample-crop scheme and keypoint-guided deformable attention enable precise estimation of fine-grained parameters despite limited resolution, while the end-to-end training naturally maintains consistent spatial relationships between all body components. Comprehensive experiments demonstrate OSX's superior performance, achieving Top-1 on the AGORA SMPLX benchmark and significantly outperforming copy-paste pipelines that suffer from implausible predictions due to late fusion. The contribution of UBody, a large-scale dataset with high-quality whole-body annotations including partially visible bodies in diverse scenarios, bridges the gap between basic research and practical applications. This work represents a significant advancement in whole-body mesh recovery, showing that unified architectures can outperform modular approaches when properly designed to handle component-specific challenges while maintaining global consistency. OSX's simple yet effective design without manual post-processing makes it particularly valuable for real-world applications requiring accurate and natural whole-body mesh reconstruction.</p>
          </div>
          <div class="lang-zh" style="display:none">
            <p>è¿™é¡¹å¼€åˆ›æ€§å·¥ä½œå¼•å…¥äº†OSXï¼Œä¸€ä¸ªç”¨äºè¡¨è¾¾æ€§3Då…¨èº«ç½‘æ ¼æ¢å¤çš„å•é˜¶æ®µæµç¨‹ï¼ŒæˆåŠŸè§£å†³äº†ä»å•å¼ å›¾åƒåŒæ—¶é‡å»ºèº«ä½“ã€é¢éƒ¨å’Œæ‰‹éƒ¨çš„åˆ†è¾¨ç‡æŒ‘æˆ˜ã€‚é€šè¿‡è®¾è®¡å…·æœ‰å…¨å±€èº«ä½“ç¼–ç å™¨å’Œå±€éƒ¨é¢éƒ¨/æ‰‹éƒ¨è§£ç å™¨çš„ç»„ä»¶æ„ŸçŸ¥Transformerï¼ˆCATï¼‰ï¼ŒOSXæœ‰æ•ˆå¤„ç†äº†å…¨èº«é‡å»ºçš„å¤šå°ºåº¦ç‰¹æ€§ï¼Œå…¶ä¸­é¢éƒ¨å’Œæ‰‹éƒ¨å æ®æå°åŒºåŸŸã€‚ç‰¹å¾çº§ä¸Šé‡‡æ ·è£å‰ªæ–¹æ¡ˆå’Œå…³é”®ç‚¹å¼•å¯¼çš„å¯å˜å½¢æ³¨æ„åŠ›èƒ½å¤Ÿåœ¨åˆ†è¾¨ç‡æœ‰é™çš„æƒ…å†µä¸‹ç²¾ç¡®ä¼°è®¡ç»†ç²’åº¦å‚æ•°ï¼Œè€Œç«¯åˆ°ç«¯è®­ç»ƒè‡ªç„¶ä¿æŒäº†æ‰€æœ‰èº«ä½“ç»„ä»¶ä¹‹é—´ä¸€è‡´çš„ç©ºé—´å…³ç³»ã€‚å¹¿æ³›å®éªŒè¯æ˜äº†OSXçš„ä¼˜è¶Šæ€§èƒ½ï¼Œåœ¨AGORA SMPLXåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°Top-1ï¼Œå¹¶æ˜¾è‘—ä¼˜äºå› åæœŸèåˆè€Œäº§ç”Ÿä¸å¯ä¿¡é¢„æµ‹çš„å¤åˆ¶ç²˜è´´æµç¨‹ã€‚UBodyä½œä¸ºå…·æœ‰é«˜è´¨é‡å…¨èº«æ ‡æ³¨çš„å¤§è§„æ¨¡æ•°æ®é›†çš„è´¡çŒ®ï¼ŒåŒ…æ‹¬å¤šæ ·åŒ–åœºæ™¯ä¸­éƒ¨åˆ†å¯è§çš„èº«ä½“ï¼Œå¼¥åˆäº†åŸºç¡€ç ”ç©¶ä¸å®é™…åº”ç”¨ä¹‹é—´çš„å·®è·ã€‚è¿™é¡¹å·¥ä½œä»£è¡¨äº†å…¨èº«ç½‘æ ¼æ¢å¤çš„é‡å¤§è¿›æ­¥ï¼Œè¡¨æ˜å½“ç»Ÿä¸€æ¶æ„è¢«æ­£ç¡®è®¾è®¡ä»¥å¤„ç†ç»„ä»¶ç‰¹å®šæŒ‘æˆ˜åŒæ—¶ä¿æŒå…¨å±€ä¸€è‡´æ€§æ—¶ï¼Œå¯ä»¥ä¼˜äºæ¨¡å—åŒ–æ–¹æ³•ã€‚OSXçš„ç®€å•è€Œæœ‰æ•ˆçš„è®¾è®¡æ— éœ€æ‰‹åŠ¨åå¤„ç†ï¼Œä½¿å…¶å¯¹éœ€è¦å‡†ç¡®å’Œè‡ªç„¶çš„å…¨èº«ç½‘æ ¼é‡å»ºçš„å®é™…åº”ç”¨ç‰¹åˆ«æœ‰ä»·å€¼ã€‚</p>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Official Code</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <p><b>ArXiv:</b> <a href="https://arxiv.org/abs/2303.16160" target="_blank" style="color:#8bffcf;">2303.16160</a></p>
          <p><b>PDF:</b> <a href="https://arxiv.org/pdf/2303.16160.pdf" target="_blank" style="color:#8bffcf;">https://arxiv.org/pdf/2303.16160.pdf</a></p>
          <p><b>Project Page:</b> <a href="https://osx-ubody.github.io/" target="_blank" style="color:#8bffcf;">https://osx-ubody.github.io/</a></p>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Core Code Implementationï¼ˆæ ¸å¿ƒä»£ç ï¼‰</h2>
        <div style="background:rgba(0,0,0,0.5); border:1px solid rgba(255,255,255,0.1); border-radius:8px; padding:12px; font-family:ui-monospace,Menlo,Consolas,monospace; font-size:12px; color:#8bffcf; margin:8px 0; overflow-x:auto;">
# OSX Implementation<br>
<br>
// Component Aware Transformer (CAT)<br>
<span style="color:#569cd6;">class</span> <span style="color:#dcdcaa;">ComponentAwareTransformer</span>(nn.Module):<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">__init__</span>(<span style="color:#569cd6;">self</span>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Global body encoder</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">self</span>.body_encoder = BodyEncoder()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Local face/hand decoder</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">self</span>.face_hand_decoder = FaceHandDecoder()<br>
<br>
// Global body encoder<br>
<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">body_encoder</span>(image):<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""Encode full-body image and predict body parameters"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;body_features = backbone(image)<br>
&nbsp;&nbsp;&nbsp;&nbsp;body_params = body_head(body_features)  <span style="color:#6a9955;"># SMPL-X body parameters</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Provide high-quality feature maps for decoder</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;feature_maps = extract_feature_maps(body_features)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> body_params, feature_maps<br>
<br>
// Feature-level upsample-crop<br>
<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">feature_level_upsample_crop</span>(feature_maps, keypoints, part_type):<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""Extract high-resolution part-specific features"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Upsample feature maps for higher resolution</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;upsampled_features = upsample(feature_maps)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Crop based on keypoint locations</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;part_features = crop_features(upsampled_features, keypoints, part_type)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> part_features<br>
<br>
// Keypoint-guided deformable attention<br>
<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">keypoint_guided_deformable_attention</span>(part_features, keypoints):<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""Apply deformable attention guided by keypoints"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Generate attention offsets from keypoints</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;offsets = generate_offsets(keypoints)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Apply deformable attention</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;attended_features = deformable_attention(part_features, offsets)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> attended_features<br>
<br>
// Face/hand decoder<br>
<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">face_hand_decoder</span>(feature_maps, body_keypoints):<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""Decode face and hand parameters from feature maps"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Extract face features</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;face_features = feature_level_upsample_crop(feature_maps, body_keypoints, <span style="color:#ce9178;">'face'</span>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;face_features = keypoint_guided_deformable_attention(face_features, face_keypoints)<br>
&nbsp;&nbsp;&nbsp;&nbsp;face_params = face_head(face_features)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Extract hand features</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;hand_features = feature_level_upsample_crop(feature_maps, body_keypoints, <span style="color:#ce9178;">'hands'</span>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;hand_features = keypoint_guided_deformable_attention(hand_features, hand_keypoints)<br>
&nbsp;&nbsp;&nbsp;&nbsp;hand_params = hand_head(hand_features)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> face_params, hand_params<br>
<br>
// Main pipeline<br>
<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">osx_pipeline</span>(image):<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""One-stage whole-body mesh recovery"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Step 1: Encode body and get feature maps</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;body_params, feature_maps = body_encoder(image)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Step 2: Decode face and hands from feature maps</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;face_params, hand_params = face_hand_decoder(feature_maps, body_params.keypoints)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Step 3: Combine all parameters</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;whole_body_params = combine_params(body_params, face_params, hand_params)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> whole_body_params<br>
        </div>
      </div>
    </div>
</section>
</body>
</html>

