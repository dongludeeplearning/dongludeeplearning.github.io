<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius: 16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ ECCV 2024
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">Controllable Human-Object Interaction Synthesis</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Jiaman Li, Alexander Clegg, Roozbeh Mottaghi, Jiajun Wu, Xavier Puig, C. Karen Liu<br>
        <span style="opacity:0.8">Stanford University</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to generate synchronized human-object interactions in 3D scenes guided by language descriptions, initial states, and sparse object waypoints?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•åœ¨3Dåœºæ™¯ä¸­ç”Ÿæˆç”±è¯­è¨€æè¿°ã€åˆå§‹çŠ¶æ€å’Œç¨€ç–å¯¹è±¡è·¯å¾„ç‚¹å¼•å¯¼çš„åŒæ­¥äºº-ç‰©äº¤äº’ï¼Ÿ
        </div>
      </div>
    </div>
  
    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>CHOIS Framework:</b> A conditional diffusion model that simultaneously generates synchronized object motion and human motion guided by language descriptions and sparse object waypoints.</div>
            <div class="lang-zh" style="display:none"><b>CHOIS æ¡†æ¶ï¼š</b>ä¸€ä¸ªæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ŒåŒæ—¶ç”Ÿæˆç”±è¯­è¨€æè¿°å’Œç¨€ç–å¯¹è±¡è·¯å¾„ç‚¹å¼•å¯¼çš„åŒæ­¥å¯¹è±¡è¿åŠ¨å’Œäººç±»è¿åŠ¨ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Object Geometry Loss:</b> Additional supervision during training to improve alignment between generated object motion and input waypoints.</div>
            <div class="lang-zh" style="display:none"><b>å¯¹è±¡å‡ ä½•æŸå¤±ï¼š</b>è®­ç»ƒæœŸé—´çš„é¢å¤–ç›‘ç£ï¼Œä»¥æ”¹å–„ç”Ÿæˆçš„å¯¹è±¡è¿åŠ¨ä¸è¾“å…¥è·¯å¾„ç‚¹ä¹‹é—´çš„å¯¹é½ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Contact Constraints Guidance:</b> Guidance terms during sampling to enforce realistic hand-object and human-floor contact constraints.</div>
            <div class="lang-zh" style="display:none"><b>æ¥è§¦çº¦æŸå¼•å¯¼ï¼š</b>é‡‡æ ·è¿‡ç¨‹ä¸­çš„å¼•å¯¼é¡¹ï¼Œä»¥å¼ºåˆ¶æ‰§è¡ŒçœŸå®çš„æ‰‹-ç‰©å’Œäºº-åœ°é¢æ¥è§¦çº¦æŸã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Planning Integration:</b> Seamless integration with path planning modules to enable generation of long-term interactions in 3D environments.</div>
            <div class="lang-zh" style="display:none"><b>è§„åˆ’é›†æˆï¼š</b>ä¸è·¯å¾„è§„åˆ’æ¨¡å—çš„æ— ç¼é›†æˆï¼Œä»¥å®ç°3Dç¯å¢ƒä¸­é•¿æœŸäº¤äº’çš„ç”Ÿæˆã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆç¤ºä¾‹ï¼‰</h2>
        <div style="border-radius:14px; overflow:hidden;">
             <img src="Figures/chois_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />
        </div>
      </div>
  
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Synchronized Motion Generation:</b> Generating coherent human and object motions that are temporally aligned and semantically meaningful.</div>
            <div class="lang-zh" style="display:none"><b>åŒæ­¥è¿åŠ¨ç”Ÿæˆï¼š</b>ç”Ÿæˆæ—¶é—´å¯¹é½ä¸”è¯­ä¹‰æœ‰æ„ä¹‰çš„è¿è´¯äººç±»å’Œå¯¹è±¡è¿åŠ¨ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Waypoint Adherence:</b> Ensuring generated object motion accurately follows sparse input waypoints while maintaining natural motion trajectories.</div>
            <div class="lang-zh" style="display:none"><b>è·¯å¾„ç‚¹éµå¾ªï¼š</b>ç¡®ä¿ç”Ÿæˆçš„å¯¹è±¡è¿åŠ¨å‡†ç¡®éµå¾ªç¨€ç–è¾“å…¥è·¯å¾„ç‚¹ï¼ŒåŒæ—¶ä¿æŒè‡ªç„¶çš„è¿åŠ¨è½¨è¿¹ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Contact Constraints:</b> Enforcing realistic physical constraints for hand-object contact and human-floor interaction during motion synthesis.</div>
            <div class="lang-zh" style="display:none"><b>æ¥è§¦çº¦æŸï¼š</b>åœ¨è¿åŠ¨åˆæˆæœŸé—´å¼ºåˆ¶æ‰§è¡Œæ‰‹-ç‰©æ¥è§¦å’Œäºº-åœ°é¢äº¤äº’çš„çœŸå®ç‰©ç†çº¦æŸã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Long-horizon Synthesis:</b> Extending interaction synthesis from short clips to long-term sequences that maintain coherence across multiple actions.</div>
            <div class="lang-zh" style="display:none"><b>é•¿æ—¶ç¨‹åˆæˆï¼š</b>å°†äº¤äº’åˆæˆä»çŸ­ç‰‡æ®µæ‰©å±•åˆ°ä¿æŒè·¨å¤šä¸ªåŠ¨ä½œä¸€è‡´æ€§çš„é•¿æœŸåºåˆ—ã€‚</div>
          </li>
        </ul>
      </div>
  
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Conditional Diffusion Model:</b> Jointly models human and object motion conditioned on language descriptions, initial states, and sparse object waypoints.</div>
            <div class="lang-zh" style="display:none"><b>æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼š</b>è”åˆå»ºæ¨¡äººç±»å’Œå¯¹è±¡è¿åŠ¨ï¼Œä»¥è¯­è¨€æè¿°ã€åˆå§‹çŠ¶æ€å’Œç¨€ç–å¯¹è±¡è·¯å¾„ç‚¹ä¸ºæ¡ä»¶ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Object Geometry Loss:</b> During training, adds supervision to minimize distance between generated object positions and input waypoints at specified timestamps.</div>
            <div class="lang-zh" style="display:none"><b>å¯¹è±¡å‡ ä½•æŸå¤±ï¼š</b>åœ¨è®­ç»ƒæœŸé—´ï¼Œæ·»åŠ ç›‘ç£ä»¥æœ€å°åŒ–ç”Ÿæˆçš„å¯¹è±¡ä½ç½®ä¸æŒ‡å®šæ—¶é—´æˆ³çš„è¾“å…¥è·¯å¾„ç‚¹ä¹‹é—´çš„è·ç¦»ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Contact Guidance:</b> During sampling, applies classifier-free guidance to enforce hand-object contact and prevent foot-floor penetration.</div>
            <div class="lang-zh" style="display:none"><b>æ¥è§¦å¼•å¯¼ï¼š</b>åœ¨é‡‡æ ·æœŸé—´ï¼Œåº”ç”¨æ— åˆ†ç±»å™¨å¼•å¯¼æ¥å¼ºåˆ¶æ‰§è¡Œæ‰‹-ç‰©æ¥è§¦å¹¶é˜²æ­¢è„š-åœ°é¢ç©¿é€ã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Planning Integration:</b> Combines with high-level path planning to generate waypoint sequences, enabling long-term interaction synthesis in complex 3D environments.</div>
            <div class="lang-zh" style="display:none"><b>è§„åˆ’é›†æˆï¼š</b>ä¸é«˜å±‚è·¯å¾„è§„åˆ’ç›¸ç»“åˆä»¥ç”Ÿæˆè·¯å¾„ç‚¹åºåˆ—ï¼Œå®ç°å¤æ‚3Dç¯å¢ƒä¸­é•¿æœŸäº¤äº’åˆæˆçš„èƒ½åŠ›ã€‚</div>
          </li>
        </ol>
      </div>
  
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/chois_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />
            
            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('2312.03913.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('2312.03913.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                CHOIS enables controllable synthesis of human-object interactions in 3D scenes, adhering to language descriptions and sparse waypoint constraints.
            </div>
            <div class="lang-zh" style="display:none">
                CHOIS å®ç°äº†3Dåœºæ™¯ä¸­äºº-ç‰©äº¤äº’çš„å¯æ§åˆæˆï¼Œéµå¾ªè¯­è¨€æè¿°å’Œç¨€ç–è·¯å¾„ç‚¹çº¦æŸã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                The combination of object geometry loss and contact guidance ensures realistic physical interactions while maintaining semantic coherence.
            </div>
            <div class="lang-zh" style="display:none">
                å¯¹è±¡å‡ ä½•æŸå¤±å’Œæ¥è§¦å¼•å¯¼çš„ç»“åˆç¡®ä¿äº†çœŸå®çš„ç‰©ç†äº¤äº’åŒæ—¶ä¿æŒè¯­ä¹‰è¿è´¯æ€§ã€‚
            </div>
          </li>
          <li>
            <div class="lang-en">
                Integration with planning systems enables long-horizon interaction synthesis, opening possibilities for interactive virtual environments and robotics applications.
            </div>
            <div class="lang-zh" style="display:none">
                ä¸è§„åˆ’ç³»ç»Ÿçš„é›†æˆå®ç°äº†é•¿æ—¶ç¨‹äº¤äº’åˆæˆï¼Œä¸ºäº¤äº’å¼è™šæ‹Ÿç¯å¢ƒå’Œæœºå™¨äººåº”ç”¨å¼€è¾Ÿäº†å¯èƒ½æ€§ã€‚
            </div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Core Code Implementationï¼ˆæ ¸å¿ƒä»£ç å®ç°ï¼‰</h2>
        <div style="font-family:ui-monospace,monospace;font-size:13px;color:rgba(232,236,255,.8);background:rgba(0,0,0,.3);padding:16px;border-radius:8px;border:1px solid rgba(255,255,255,.05);">
          <div class="lang-en">
            <pre><code># CHOIS: Conditional Diffusion Model for Human-Object Interaction
import torch
import torch.nn as nn
from diffusion_model import ConditionalDiffusion

class CHOIS(nn.Module):
    def __init__(self, human_dim=135, object_dim=9, cond_dim=512):
        super().__init__()
        self.diffusion = ConditionalDiffusion(human_dim + object_dim)
        self.text_encoder = TextEncoder()  # CLIP or similar
        self.waypoint_encoder = WaypointEncoder()
        self.contact_predictor = ContactPredictor()

    def forward(self, text, waypoints, human_init, object_init, timesteps):
        # Encode conditions
        text_emb = self.text_encoder(text)  # [B, cond_dim]
        waypoint_emb = self.waypoint_encoder(waypoints)  # [B, T, cond_dim]

        # Concatenate conditions
        conditions = torch.cat([text_emb, waypoint_emb], dim=-1)

        # Joint human-object motion
        joint_motion = torch.cat([human_init, object_init], dim=-1)

        # Denoising step
        noise_pred = self.diffusion(joint_motion, conditions, timesteps)

        return noise_pred

    def sample_with_guidance(self, text, waypoints, num_steps=100):
        # Initial noise
        joint_noise = torch.randn(batch_size, seq_len, human_dim + object_dim)

        for t in reversed(range(num_steps)):
            # Predict noise
            noise_pred = self(joint_noise, text, waypoints, t)

            # Contact guidance (classifier-free guidance)
            contact_score = self.contact_predictor(joint_noise)
            guidance_scale = 1.5
            noise_pred = noise_pred + guidance_scale * contact_score

            # Geometry guidance for waypoints
            waypoint_loss = self.compute_waypoint_loss(joint_noise, waypoints, t)
            noise_pred = noise_pred - 0.1 * waypoint_loss

            # Update
            joint_noise = self.diffusion.update_sample(joint_noise, noise_pred, t)

        return joint_noise

    def compute_waypoint_loss(self, pred_motion, waypoints, t):
        # Extract object motion from joint prediction
        obj_motion = pred_motion[..., -object_dim:]

        # Compute distance to waypoints at specific timestamps
        waypoint_timestamps = torch.linspace(0, seq_len-1, num_waypoints, dtype=int)
        pred_positions = obj_motion[:, waypoint_timestamps]
        waypoint_positions = waypoints

        return torch.mean((pred_positions - waypoint_positions)**2)

# Training with object geometry loss
def train_step(model, batch):
    text, waypoints, human_gt, object_gt = batch

    # Joint ground truth
    joint_gt = torch.cat([human_gt, object_gt], dim=-1)

    # Add noise
    noise = torch.randn_like(joint_gt)
    timesteps = torch.randint(0, 1000, (batch_size,))
    noisy_joint = model.diffusion.add_noise(joint_gt, noise, timesteps)

    # Predict noise
    noise_pred = model(text, waypoints, noisy_joint, timesteps)

    # Diffusion loss
    diffusion_loss = nn.MSELoss()(noise_pred, noise)

    # Object geometry loss (additional supervision)
    with torch.no_grad():
        pred_clean = model.diffusion.predict_clean(noisy_joint, noise_pred, timesteps)
        geom_loss = model.compute_waypoint_loss(pred_clean, waypoints, timesteps)

    total_loss = diffusion_loss + 0.1 * geom_loss
    return total_loss

# Integration with planning system
class CHOISPlanner:
    def __init__(self, chois_model, path_planner):
        self.chois = chois_model
        self.planner = path_planner

    def generate_long_term_interaction(self, scene, start_human, start_objects, goal_description):
        # High-level planning for object waypoints
        waypoints = self.planner.plan_path(scene, start_objects, goal_description)

        # Generate interaction sequence
        interaction_sequence = []
        current_human = start_human
        current_objects = start_objects

        for i, waypoint_set in enumerate(waypoints):
            # Generate segment with CHOIS
            text_prompt = f"human interacts with object moving to {waypoint_set}"
            segment = self.chois.sample_with_guidance(text_prompt, waypoint_set)

            # Update states for next segment
            current_human = segment['human'][-1]
            current_objects = segment['objects'][-1]

            interaction_sequence.append(segment)

        return interaction_sequence</code></pre>
          </div>
          <div class="lang-zh" style="display:none">
            <pre><code># CHOIS: äºº-ç‰©äº¤äº’æ¡ä»¶æ‰©æ•£æ¨¡å‹
import torch
import torch.nn as nn
from diffusion_model import ConditionalDiffusion

class CHOIS(nn.Module):
    def __init__(self, human_dim=135, object_dim=9, cond_dim=512):
        super().__init__()
        self.diffusion = ConditionalDiffusion(human_dim + object_dim)  # è”åˆå»ºæ¨¡äºº+ç‰©è¿åŠ¨
        self.text_encoder = TextEncoder()  # æ–‡æœ¬ç¼–ç å™¨ (CLIPç­‰)
        self.waypoint_encoder = WaypointEncoder()  # è·¯å¾„ç‚¹ç¼–ç å™¨
        self.contact_predictor = ContactPredictor()  # æ¥è§¦é¢„æµ‹å™¨

    def forward(self, text, waypoints, joint_motion, timesteps):
        # ç¼–ç æ¡ä»¶ä¿¡æ¯
        text_emb = self.text_encoder(text)  # æ–‡æœ¬åµŒå…¥
        waypoint_emb = self.waypoint_encoder(waypoints)  # è·¯å¾„ç‚¹åµŒå…¥

        # æ‹¼æ¥æ¡ä»¶
        conditions = torch.cat([text_emb, waypoint_emb], dim=-1)

        # å»å™ªé¢„æµ‹
        noise_pred = self.diffusion(joint_motion, conditions, timesteps)
        return noise_pred

    def sample_with_guidance(self, text, waypoints, num_steps=100):
        # åˆå§‹åŒ–å™ªå£°
        joint_noise = torch.randn(batch_size, seq_len, human_dim + object_dim)

        for t in reversed(range(num_steps)):
            # é¢„æµ‹å™ªå£°
            noise_pred = self(joint_noise, text, waypoints, t)

            # æ¥è§¦çº¦æŸå¼•å¯¼ (æ— åˆ†ç±»å™¨å¼•å¯¼)
            contact_score = self.contact_predictor(joint_noise)
            guidance_scale = 1.5
            noise_pred = noise_pred + guidance_scale * contact_score

            # å‡ ä½•å¼•å¯¼ç”¨äºè·¯å¾„ç‚¹
            waypoint_loss = self.compute_waypoint_loss(joint_noise, waypoints, t)
            noise_pred = noise_pred - 0.1 * waypoint_loss

            # æ›´æ–°æ ·æœ¬
            joint_noise = self.diffusion.update_sample(joint_noise, noise_pred, t)

        return joint_noise

    def compute_waypoint_loss(self, pred_motion, waypoints, t):
        # ä»è”åˆé¢„æµ‹ä¸­æå–ç‰©ä½“è¿åŠ¨
        obj_motion = pred_motion[..., -object_dim:]

        # è®¡ç®—åˆ°è·¯å¾„ç‚¹çš„è·ç¦»
        waypoint_timestamps = torch.linspace(0, seq_len-1, num_waypoints, dtype=int)
        pred_positions = obj_motion[:, waypoint_timestamps]

        return torch.mean((pred_positions - waypoints)**2)

# å¸¦å¯¹è±¡å‡ ä½•æŸå¤±çš„è®­ç»ƒ
def train_step(model, batch):
    text, waypoints, human_gt, object_gt = batch

    # è”åˆçœŸå®æ•°æ®
    joint_gt = torch.cat([human_gt, object_gt], dim=-1)

    # æ·»åŠ å™ªå£°
    noise = torch.randn_like(joint_gt)
    timesteps = torch.randint(0, 1000, (batch_size,))
    noisy_joint = model.diffusion.add_noise(joint_gt, noise, timesteps)

    # é¢„æµ‹å™ªå£°
    noise_pred = model(text, waypoints, noisy_joint, timesteps)

    # æ‰©æ•£æŸå¤±
    diffusion_loss = nn.MSELoss()(noise_pred, noise)

    # å¯¹è±¡å‡ ä½•æŸå¤± (é¢å¤–ç›‘ç£)
    with torch.no_grad():
        pred_clean = model.diffusion.predict_clean(noisy_joint, noise_pred, timesteps)
        geom_loss = model.compute_waypoint_loss(pred_clean, waypoints, timesteps)

    total_loss = diffusion_loss + 0.1 * geom_loss
    return total_loss

# ä¸è§„åˆ’ç³»ç»Ÿçš„é›†æˆ
class CHOISPlanner:
    def __init__(self, chois_model, path_planner):
        self.chois = chois_model
        self.planner = path_planner

    def generate_long_term_interaction(self, scene, start_human, start_objects, goal_description):
        # é«˜å±‚è§„åˆ’ç‰©ä½“è·¯å¾„ç‚¹
        waypoints = self.planner.plan_path(scene, start_objects, goal_description)

        # ç”Ÿæˆäº¤äº’åºåˆ—
        interaction_sequence = []
        current_human = start_human
        current_objects = start_objects

        for waypoint_set in waypoints:
            # ä½¿ç”¨CHOISç”Ÿæˆç‰‡æ®µ
            text_prompt = f"human interacts with object moving to {waypoint_set}"
            segment = self.chois.sample_with_guidance(text_prompt, waypoint_set)

            # ä¸ºä¸‹ä¸€ç‰‡æ®µæ›´æ–°çŠ¶æ€
            current_human = segment['human'][-1]
            current_objects = segment['objects'][-1]

            interaction_sequence.append(segment)

        return interaction_sequence</code></pre>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Code:</h2>
        <a href="https://lijiaman.github.io/projects/chois/" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          Project Page
        </a>
      </div>

    </div>
  </section>
  <script>
    function toggleLang(btn) {
      const container = btn.closest('div');
      const enElements = container.querySelectorAll('.lang-en');
      const zhElements = container.querySelectorAll('.lang-zh');
      
      enElements.forEach(el => {
        el.style.display = (el.style.display === 'none') ? 'block' : 'none';
      });
      
      zhElements.forEach(el => {
        el.style.display = (el.style.display === 'none') ? 'block' : 'none';
      });
    }

    function openLocalPdf(filename) {
      window.open('pdfs/' + filename, '_blank');
    }

    function delLocalPdf(filename) {
      // User will implement this themselves
      alert("Please implement the delete logic or delete the file manually: pdfs/" + filename);
    }
  </script>
</body>
</html>

