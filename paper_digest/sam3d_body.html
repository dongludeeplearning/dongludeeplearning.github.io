<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  // ç›´æ¥æ‰“å¼€PDFæ–‡ä»¶
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ Meta 2025
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">SAM 3D Body: Robust Full-Body Human Mesh Recovery</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Xitong Yang, Devansh Kukreja, Don Pinkus, Anushka Sagar, Taosha Fan, Jinhyung Park, Soyong Shin, Jinkun Cao, Jiawei Liu, Nicolas Ugrinovic, Matt Feiszli, Jitendra Malik, Piotr DollÃ¡r, Kris Kitani<br>
        <span style="opacity:0.8">Meta Superintelligence Labs</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to create a robust full-body human mesh recovery model from single images that works reliably in diverse in-the-wild conditions, particularly for challenging poses, severe occlusion, and uncommon viewpoints, while enabling interactive user-guided inference?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•ä»å•ä¸ªå›¾åƒåˆ›å»ºä¸€ä¸ªå¥å£®çš„å®Œæ•´äººä½“ç½‘æ ¼æ¢å¤æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨å¤šæ ·åŒ–çš„é‡å¤–æ¡ä»¶ä¸‹å¯é å·¥ä½œï¼Œç‰¹åˆ«æ˜¯å¯¹äºå…·æœ‰æŒ‘æˆ˜æ€§çš„å§¿åŠ¿ã€ä¸¥é‡é®æŒ¡å’Œä¸å¯»å¸¸è§†ç‚¹çš„åœºæ™¯ï¼ŒåŒæ—¶å®ç°äº¤äº’å¼çš„ç”¨æˆ·å¼•å¯¼æ¨ç†ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>SAM 3D Body (3DB) Model:</b> Introduced a promptable full-body human mesh recovery model that achieves state-of-the-art performance with strong generalization across diverse in-the-wild conditions, estimating body, feet, and hands pose in a unified framework.</div>
            <div class="lang-zh" style="display:none"><b>SAM 3D Body (3DB)æ¨¡å‹ï¼š</b>å¼•å…¥äº†ä¸€ä¸ªå¯æç¤ºçš„å®Œæ•´äººä½“ç½‘æ ¼æ¢å¤æ¨¡å‹ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨å¤šæ ·åŒ–çš„é‡å¤–æ¡ä»¶ä¸‹å…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨ç»Ÿä¸€æ¡†æ¶ä¸­ä¼°è®¡èº«ä½“ã€è„šå’Œæ‰‹å§¿åŠ¿ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Momentum Human Rig (MHR):</b> Pioneered a new parametric mesh representation that decouples skeletal structure and surface shape, providing richer control, better interpretability, and more accurate full-body reconstruction compared to traditional SMPL models.</div>
            <div class="lang-zh" style="display:none"><b>Momentum Human Rig (MHR)ï¼š</b>å¼€åˆ›äº†ä¸€ç§æ–°çš„å‚æ•°åŒ–ç½‘æ ¼è¡¨ç¤ºï¼Œå°†éª¨éª¼ç»“æ„å’Œè¡¨é¢å½¢çŠ¶åˆ†ç¦»ï¼Œä¸ä¼ ç»Ÿçš„SMPLæ¨¡å‹ç›¸æ¯”æä¾›æ›´ä¸°å¯Œçš„æ§åˆ¶ã€æ›´é«˜çš„å¯è§£é‡Šæ€§å’Œæ›´å‡†ç¡®çš„å®Œæ•´äººä½“é‡å»ºã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Promptable Architecture:</b> Developed a novel encoder-decoder architecture supporting auxiliary prompts (2D keypoints, masks, camera information) for controllable pose estimation, enabling user-guided inference similar to the SAM family while integrating hand and body predictions coherently.</div>
            <div class="lang-zh" style="display:none"><b>å¯æç¤ºæ¶æ„ï¼š</b>å¼€å‘äº†ä¸€ç§æ–°é¢–çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œæ”¯æŒè¾…åŠ©æç¤ºï¼ˆ2Då…³é”®ç‚¹ã€é®ç½©ã€ç›¸æœºä¿¡æ¯ï¼‰ä»¥å®ç°å¯æ§å§¿åŠ¿ä¼°è®¡ï¼Œç±»ä¼¼äºSAMå®¶æ—å®ç°ç”¨æˆ·å¼•å¯¼æ¨ç†ï¼ŒåŒæ—¶è¿è´¯åœ°é›†æˆæ‰‹å’Œèº«ä½“é¢„æµ‹ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Data Engine for Diversity:</b> Created a VLM-driven data engine that mines challenging in-the-wild images and routes them for annotation, ensuring coverage of rare poses, difficult viewpoints, and varied appearances through iterative failure analysis and rule updates.</div>
            <div class="lang-zh" style="display:none"><b>å¤šæ ·æ€§æ•°æ®å¼•æ“ï¼š</b>åˆ›å»ºäº†ä¸€ä¸ªVLMé©±åŠ¨çš„æ•°æ®å¼•æ“ï¼Œç”¨äºæŒ–æ˜å…·æœ‰æŒ‘æˆ˜æ€§çš„é‡å¤–å›¾åƒå¹¶å°†å…¶è·¯ç”±è¿›è¡Œæ³¨é‡Šï¼Œé€šè¿‡è¿­ä»£æ•…éšœåˆ†æå’Œè§„åˆ™æ›´æ–°ç¡®ä¿è¦†ç›–ç½•è§å§¿åŠ¿ã€å›°éš¾è§†ç‚¹å’Œå¤šæ ·å¤–è§‚ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multi-Stage Annotation Pipeline:</b> Designed a comprehensive annotation pipeline combining manual keypoint annotation, dense keypoint detection, geometric constraints, parametric priors, and robust optimization to produce high-quality 3D human mesh annotations at scale.</div>
            <div class="lang-zh" style="display:none"><b>å¤šé˜¶æ®µæ³¨é‡Šç®¡é“ï¼š</b>è®¾è®¡äº†ä¸€ä¸ªå…¨é¢çš„æ³¨é‡Šç®¡é“ï¼Œç»“åˆæ‰‹åŠ¨å…³é”®ç‚¹æ³¨é‡Šã€å¯†é›†å…³é”®ç‚¹æ£€æµ‹ã€å‡ ä½•çº¦æŸã€å‚æ•°åŒ–å…ˆéªŒå’Œé²æ£’ä¼˜åŒ–ï¼Œä»¥è§„æ¨¡åŒ–ç”Ÿäº§é«˜è´¨é‡çš„3Däººä½“ç½‘æ ¼æ³¨é‡Šã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Superior Performance:</b> Achieved 5:1 win rate in human preference studies with 7,800 participants, outperforming prior methods on standard metrics while generalizing better to unseen datasets and enabling interactive control for challenging poses.</div>
            <div class="lang-zh" style="display:none"><b>å“è¶Šæ€§èƒ½ï¼š</b>åœ¨7800åå‚ä¸è€…çš„äººç±»åå¥½ç ”ç©¶ä¸­å®ç°äº†5:1çš„èƒœç‡ï¼Œåœ¨æ ‡å‡†æŒ‡æ ‡ä¸Šä¼˜äºä»¥å‰çš„æ–¹æ³•ï¼ŒåŒæ—¶æ›´å¥½åœ°æ³›åŒ–åˆ°æœªè§æ•°æ®é›†ï¼Œå¹¶ä¸ºå…·æœ‰æŒ‘æˆ˜æ€§çš„å§¿åŠ¿å®ç°äº¤äº’å¼æ§åˆ¶ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆå¼•è¨€ç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/sam3d_body_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('sam3d_body.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('sam3d_body.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/sam3d_body_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('sam3d_body.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('sam3d_body.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Limited Robustness in Wild Conditions:</b> Existing HMR models exhibit unsatisfactory robustness when applied to in-the-wild images with challenging poses, severe occlusion, or uncommon viewpoints, limiting their applicability to real-world robotics and biomechanics scenarios.</div>
            <div class="lang-zh" style="display:none"><b>é‡å¤–æ¡ä»¶ä¸‹çš„æœ‰é™é²æ£’æ€§ï¼š</b>ç°æœ‰çš„HMRæ¨¡å‹åœ¨åº”ç”¨äºå…·æœ‰æŒ‘æˆ˜æ€§å§¿åŠ¿ã€ä¸¥é‡é®æŒ¡æˆ–ä¸å¯»å¸¸è§†ç‚¹çš„é‡å¤–å›¾åƒæ—¶è¡¨ç°å‡ºä¸ä»¤äººæ»¡æ„çš„é²æ£’æ€§ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨çœŸå®ä¸–ç•Œæœºå™¨äººå’Œç”Ÿç‰©åŠ›å­¦åœºæ™¯ä¸­çš„é€‚ç”¨æ€§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Unreliable Full-Body Estimation:</b> Current models struggle to reliably estimate both overall body pose and fine details of hands and feet in a unified framework, with separate optimization mechanisms creating conflicts in resolution, camera estimation, and supervision objectives.</div>
            <div class="lang-zh" style="display:none"><b>ä¸å¯é çš„å®Œæ•´èº«ä½“ä¼°è®¡ï¼š</b>å½“å‰æ¨¡å‹éš¾ä»¥åœ¨ç»Ÿä¸€æ¡†æ¶ä¸­å¯é åœ°ä¼°è®¡æ•´ä½“èº«ä½“å§¿åŠ¿å’Œæ‰‹è„šçš„ç²¾ç»†ç»†èŠ‚ï¼Œåˆ†å¼€çš„ä¼˜åŒ–æœºåˆ¶åœ¨åˆ†è¾¨ç‡ã€ç›¸æœºä¼°è®¡å’Œç›‘ç£ç›®æ ‡æ–¹é¢äº§ç”Ÿå†²çªã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Data Quality and Scale Bottlenecks:</b> Collecting large-scale, diverse human pose datasets with high-quality mesh annotations is computationally costly and difficult, with existing datasets suffering from low diversity or low mesh quality due to laboratory settings or pseudo-labeling.</div>
            <div class="lang-zh" style="display:none"><b>æ•°æ®è´¨é‡å’Œè§„æ¨¡ç“¶é¢ˆï¼š</b>æ”¶é›†å¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„äººä½“å§¿åŠ¿æ•°æ®é›†ä»¥åŠé«˜è´¨é‡ç½‘æ ¼æ³¨é‡Šåœ¨è®¡ç®—ä¸Šæ˜¯æ˜‚è´µçš„ä¸”å›°éš¾çš„ï¼Œç°æœ‰çš„æ•°æ®é›†ç”±äºå®éªŒå®¤è®¾ç½®æˆ–ä¼ªæ ‡è®°è€Œé­å—ä½å¤šæ ·æ€§æˆ–ä½ç½‘æ ¼è´¨é‡ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Architecture Limitations:</b> Traditional HMR architectures fail to adequately address distinct optimization requirements for body and hand pose estimation, nor do they incorporate effective training strategies to handle uncertainty and ambiguity from monocular images.</div>
            <div class="lang-zh" style="display:none"><b>æ¶æ„å±€é™æ€§ï¼š</b>ä¼ ç»Ÿçš„HMRæ¶æ„æœªèƒ½å……åˆ†è§£å†³èº«ä½“å’Œæ‰‹å§¿åŠ¿ä¼°è®¡çš„ä¸åŒä¼˜åŒ–éœ€æ±‚ï¼Œä¹Ÿæ²¡æœ‰çº³å…¥æœ‰æ•ˆçš„è®­ç»ƒç­–ç•¥æ¥å¤„ç†æ¥è‡ªå•ç›®å›¾åƒçš„ä¸ç¡®å®šæ€§å’Œæ­§ä¹‰ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Lack of Interactive Control:</b> Existing models lack mechanisms for user-guided inference, preventing users from providing corrective input for ambiguous scenarios or challenging poses that automatic methods struggle with.</div>
            <div class="lang-zh" style="display:none"><b>ç¼ºä¹äº¤äº’æ§åˆ¶ï¼š</b>ç°æœ‰æ¨¡å‹ç¼ºä¹ç”¨æˆ·å¼•å¯¼æ¨ç†çš„æœºåˆ¶ï¼Œé˜»æ­¢ç”¨æˆ·ä¸ºè‡ªåŠ¨æ–¹æ³•éš¾ä»¥å¤„ç†çš„æ­§ä¹‰åœºæ™¯æˆ–æŒ‘æˆ˜æ€§å§¿åŠ¿æä¾›çº æ­£è¾“å…¥ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Domain Gap Issues:</b> Models trained on synthetic or constrained datasets struggle to generalize to real-world images with diverse appearances, poses, and imaging conditions, requiring sophisticated alignment techniques.</div>
            <div class="lang-zh" style="display:none"><b>é¢†åŸŸå·®è·é—®é¢˜ï¼š</b>åœ¨åˆæˆæˆ–å—é™æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹éš¾ä»¥æ³›åŒ–åˆ°å…·æœ‰å¤šæ ·åŒ–å¤–è§‚ã€å§¿åŠ¿å’Œæˆåƒæ¡ä»¶çš„çœŸå®ä¸–ç•Œå›¾åƒï¼Œéœ€è¦å¤æ‚çš„å¯¹é½æŠ€æœ¯ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Promptable Encoder-Decoder Architecture:</b> Designed a promptable encoder-decoder with shared image encoder and separate body/hand decoders, supporting auxiliary prompts (2D keypoints, masks, camera info) for controllable pose estimation and coherent integration of hand and body predictions.</div>
            <div class="lang-zh" style="display:none"><b>å¯æç¤ºç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼š</b>è®¾è®¡äº†ä¸€ä¸ªå¯æç¤ºçš„ç¼–ç å™¨-è§£ç å™¨ï¼Œå…·æœ‰å…±äº«å›¾åƒç¼–ç å™¨å’Œç‹¬ç«‹çš„èº«ä½“/æ‰‹è§£ç å™¨ï¼Œæ”¯æŒè¾…åŠ©æç¤ºï¼ˆ2Då…³é”®ç‚¹ã€é®ç½©ã€ç›¸æœºä¿¡æ¯ï¼‰ä»¥å®ç°å¯æ§å§¿åŠ¿ä¼°è®¡å’Œæ‰‹ä¸èº«ä½“é¢„æµ‹çš„è¿è´¯é›†æˆã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Momentum Human Rig (MHR):</b> Adopted a new parametric mesh representation that decouples skeletal structure and surface shape, providing richer control, better interpretability, and more accurate full-body reconstruction than intertwined SMPL models.</div>
            <div class="lang-zh" style="display:none"><b>Momentum Human Rig (MHR)ï¼š</b>é‡‡ç”¨äº†ä¸€ç§æ–°çš„å‚æ•°åŒ–ç½‘æ ¼è¡¨ç¤ºï¼Œå°†éª¨éª¼ç»“æ„å’Œè¡¨é¢å½¢çŠ¶åˆ†ç¦»ï¼Œä¸äº¤ç»‡çš„SMPLæ¨¡å‹ç›¸æ¯”æä¾›æ›´ä¸°å¯Œçš„æ§åˆ¶ã€æ›´é«˜çš„å¯è§£é‡Šæ€§å’Œæ›´å‡†ç¡®çš„å®Œæ•´èº«ä½“é‡å»ºã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>VLM-Driven Data Engine:</b> Implemented a vision-language model driven mining strategy that automatically generates and updates rules to identify challenging in-the-wild images for annotation, ensuring data diversity through iterative failure analysis and adaptive rule updates.</div>
            <div class="lang-zh" style="display:none"><b>VLMé©±åŠ¨çš„æ•°æ®å¼•æ“ï¼š</b>å®æ–½äº†ä¸€ä¸ªè§†è§‰-è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æŒ–æ˜ç­–ç•¥ï¼Œè‡ªåŠ¨ç”Ÿæˆå’Œæ›´æ–°è§„åˆ™ä»¥è¯†åˆ«éœ€è¦æ³¨é‡Šçš„å…·æœ‰æŒ‘æˆ˜æ€§çš„é‡å¤–å›¾åƒï¼Œé€šè¿‡è¿­ä»£æ•…éšœåˆ†æå’Œè‡ªé€‚åº”è§„åˆ™æ›´æ–°ç¡®ä¿æ•°æ®å¤šæ ·æ€§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multi-Stage Annotation Pipeline:</b> Developed a comprehensive pipeline combining manual keypoint annotation, dense keypoint detection, geometric constraints, parametric priors, and robust optimization to produce high-quality 3D mesh annotations from single-view and multi-view datasets.</div>
            <div class="lang-zh" style="display:none"><b>å¤šé˜¶æ®µæ³¨é‡Šç®¡é“ï¼š</b>å¼€å‘äº†ä¸€ä¸ªå…¨é¢çš„ç®¡é“ï¼Œç»“åˆæ‰‹åŠ¨å…³é”®ç‚¹æ³¨é‡Šã€å¯†é›†å…³é”®ç‚¹æ£€æµ‹ã€å‡ ä½•çº¦æŸã€å‚æ•°åŒ–å…ˆéªŒå’Œé²æ£’ä¼˜åŒ–ï¼Œä»å•è§†å›¾å’Œå¤šè§†å›¾æ•°æ®é›†ä¸­ç”Ÿäº§é«˜è´¨é‡çš„3Dç½‘æ ¼æ³¨é‡Šã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Comprehensive Training Datasets:</b> Curated 7 million images from diverse sources including licensed stock photos, multi-view captures, and synthetic data, covering body pose, hands, interactions, and in-the-wild conditions for robust full-body HMR.</div>
            <div class="lang-zh" style="display:none"><b>å…¨é¢è®­ç»ƒæ•°æ®é›†ï¼š</b>ä»å¤šæ ·åŒ–æ¥æºæ•´ç†äº†700ä¸‡ä¸ªå›¾åƒï¼ŒåŒ…æ‹¬è®¸å¯çš„åº“å­˜ç…§ç‰‡ã€å¤šè§†å›¾æ•è·å’Œåˆæˆæ•°æ®ï¼Œæ¶µç›–èº«ä½“å§¿åŠ¿ã€æ‰‹éƒ¨ã€äº¤äº’å’Œé‡å¤–æ¡ä»¶ï¼Œä»¥å®ç°é²æ£’çš„å®Œæ•´èº«ä½“HMRã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multi-Task Loss with Uncertainty:</b> Employed comprehensive loss functions with learnable per-joint uncertainty modulation and prompt-aware training strategies to handle monocular image ambiguities and provide strong supervision across all prediction heads.</div>
            <div class="lang-zh" style="display:none"><b>å…·æœ‰ä¸ç¡®å®šæ€§çš„å¤šä»»åŠ¡æŸå¤±ï¼š</b>é‡‡ç”¨å…¨é¢çš„æŸå¤±å‡½æ•°ï¼Œå…·æœ‰å¯å­¦ä¹ çš„æ¯ä¸ªå…³èŠ‚ä¸ç¡®å®šæ€§è°ƒåˆ¶å’Œæç¤ºæ„ŸçŸ¥è®­ç»ƒç­–ç•¥ï¼Œä»¥å¤„ç†å•ç›®å›¾åƒæ­§ä¹‰å¹¶ä¸ºæ‰€æœ‰é¢„æµ‹å¤´æä¾›å¼ºå¤§çš„ç›‘ç£ã€‚</div>
          </li>
        </ol>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Unified Full-Body Framework:</b> 3DB represents the first single model to deliver state-of-the-art performance on both body and hand pose estimation, achieving comparable results to hand-specialized models while maintaining superiority over body-specialized approaches in a unified architecture.
            </div>
            <div class="lang-zh" style="display:none">
                <b>ç»Ÿä¸€çš„å®Œæ•´èº«ä½“æ¡†æ¶ï¼š</b>3DBä»£è¡¨äº†ç¬¬ä¸€ä¸ªåœ¨èº«ä½“å’Œæ‰‹å§¿åŠ¿ä¼°è®¡ä¸Šéƒ½æä¾›æœ€å…ˆè¿›æ€§èƒ½çš„å•ä¸€æ¨¡å‹ï¼Œåœ¨ç»Ÿä¸€æ¶æ„ä¸­å®ç°ä¸æ‰‹éƒ¨ä¸“ç”¨æ¨¡å‹ç›¸å½“çš„ç»“æœï¼ŒåŒæ—¶ä¿æŒå¯¹èº«ä½“ä¸“ç”¨æ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Data-Driven Robustness:</b> The combination of a sophisticated data engine for diversity and multi-stage annotation pipeline for quality enables 3DB to overcome fundamental data bottlenecks in HMR, resulting in unprecedented generalization to challenging in-the-wild scenarios.
            </div>
            <div class="lang-zh" style="display:none">
                <b>æ•°æ®é©±åŠ¨çš„é²æ£’æ€§ï¼š</b>å¤šæ ·æ€§æ•°æ®å¼•æ“å’Œè´¨é‡å¤šé˜¶æ®µæ³¨é‡Šç®¡é“çš„ç»“åˆä½¿3DBèƒ½å¤Ÿå…‹æœHMRä¸­çš„åŸºæœ¬æ•°æ®ç“¶é¢ˆï¼Œä»è€Œå®ç°å¯¹å…·æœ‰æŒ‘æˆ˜æ€§çš„é‡å¤–åœºæ™¯çš„ç©ºå‰æ³›åŒ–ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Interactive Promptability:</b> By supporting auxiliary prompts similar to the SAM family, 3DB enables user-guided inference that allows correction of ambiguous scenarios, providing a practical solution for real-world deployment where perfect automatic performance remains challenging.
            </div>
            <div class="lang-zh" style="display:none">
                <b>äº¤äº’å¯æç¤ºæ€§ï¼š</b>é€šè¿‡æ”¯æŒç±»ä¼¼äºSAMå®¶æ—çš„è¾…åŠ©æç¤ºï¼Œ3DBå®ç°äº†ç”¨æˆ·å¼•å¯¼æ¨ç†ï¼Œå…è®¸çº æ­£æ­§ä¹‰åœºæ™¯ï¼Œä¸ºå®Œç¾è‡ªåŠ¨æ€§èƒ½ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®ä¸–ç•Œéƒ¨ç½²æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚
            </div>
          </li>
        </ul>

        <div style="margin-top:16px; padding-top:12px; border-top:1px dashed rgba(255,255,255,.15);">
             <h3 style="margin:0 0 6px; font-size:14px; color:#8bffcf;">
               <span class="lang-en">High-Level Insights: Why it Works?</span>
               <span class="lang-zh" style="display:none">é«˜å±‚æ´å¯Ÿï¼šä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ</span>
             </h3>
             <div class="lang-en" style="color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                It works because 3DB addresses both the data and model challenges in full-body HMR through a comprehensive approach: the MHR representation provides better control and interpretability, the promptable architecture enables interactive refinement, and the sophisticated data engine ensures the quality and diversity needed for robust generalization to diverse real-world conditions.
             </div>
             <div class="lang-zh" style="display:none; color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸º3DBé€šè¿‡å…¨é¢æ–¹æ³•è§£å†³äº†å®Œæ•´èº«ä½“HMRä¸­çš„æ•°æ®å’Œæ¨¡å‹æŒ‘æˆ˜ï¼šMHRè¡¨ç¤ºæä¾›æ›´å¥½çš„æ§åˆ¶å’Œå¯è§£é‡Šæ€§ï¼Œå¯æç¤ºæ¶æ„å®ç°äº¤äº’ç»†åŒ–ï¼Œå¤æ‚çš„æ•°æ®å¼•æ“ç¡®ä¿äº†é²æ£’æ³›åŒ–åˆ°å¤šæ ·åŒ–çœŸå®ä¸–ç•Œæ¡ä»¶æ‰€éœ€çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚
             </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            This paper introduces SAM 3D Body (3DB), a robust full-body human mesh recovery model that demonstrates state-of-the-art performance with strong generalization across diverse in-the-wild conditions. 3DB is the first model to use the Momentum Human Rig (MHR) representation, which decouples skeletal structure and surface shape for richer control and interpretability. The promptable encoder-decoder architecture supports auxiliary prompts for user-guided inference, enabling correction of challenging scenarios. A sophisticated data engine ensures diversity by mining difficult cases, while a multi-stage annotation pipeline produces high-quality 3D annotations from 7 million images. Extensive experiments show 3DB outperforms prior methods with a 5:1 win rate in human preference studies, achieves superior quantitative results on standard benchmarks, and generalizes better to unseen datasets. Both 3DB and MHR are open-source, providing the foundation for more robust and interactive human mesh recovery systems.
          </div>
          <div class="lang-zh" style="display:none">
            æœ¬æ–‡ä»‹ç»äº†SAM 3D Body (3DB)ï¼Œä¸€ä¸ªå¥å£®çš„å®Œæ•´äººä½“ç½‘æ ¼æ¢å¤æ¨¡å‹ï¼Œå±•ç¤ºäº†åœ¨å¤šæ ·åŒ–çš„é‡å¤–æ¡ä»¶ä¸‹å…·æœ‰å¼ºå¤§æ³›åŒ–çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚3DBæ˜¯ç¬¬ä¸€ä¸ªä½¿ç”¨Momentum Human Rig (MHR)è¡¨ç¤ºçš„æ¨¡å‹ï¼Œè¯¥è¡¨ç¤ºå°†éª¨éª¼ç»“æ„å’Œè¡¨é¢å½¢çŠ¶åˆ†ç¦»ï¼Œä»¥å®ç°æ›´ä¸°å¯Œçš„æ§åˆ¶å’Œå¯è§£é‡Šæ€§ã€‚å¯æç¤ºçš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„æ”¯æŒè¾…åŠ©æç¤ºä»¥å®ç°ç”¨æˆ·å¼•å¯¼æ¨ç†ï¼Œèƒ½å¤Ÿçº æ­£å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ã€‚ä¸€ä¸ªå¤æ‚çš„æ•°æ®å¼•æ“é€šè¿‡æŒ–æ˜å›°éš¾æ¡ˆä¾‹ç¡®ä¿å¤šæ ·æ€§ï¼Œè€Œå¤šé˜¶æ®µæ³¨é‡Šç®¡é“ä»700ä¸‡ä¸ªå›¾åƒä¸­ç”Ÿäº§é«˜è´¨é‡çš„3Dæ³¨é‡Šã€‚å¹¿æ³›å®éªŒæ˜¾ç¤ºï¼Œ3DBåœ¨äººç±»åå¥½ç ”ç©¶ä¸­ä»¥5:1çš„èƒœç‡ä¼˜äºä»¥å‰çš„æ–¹æ³•ï¼Œåœ¨æ ‡å‡†åŸºå‡†ä¸Šå®ç°äº†å“è¶Šçš„å®šé‡ç»“æœï¼Œå¹¶æ›´å¥½åœ°æ³›åŒ–åˆ°æœªè§æ•°æ®é›†ã€‚3DBå’ŒMHRéƒ½æ˜¯å¼€æºçš„ï¼Œä¸ºæ›´å¥å£®å’Œäº¤äº’å¼çš„äººä½“ç½‘æ ¼æ¢å¤ç³»ç»Ÿæä¾›äº†åŸºç¡€ã€‚
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Links:</h2>
        <a href="https://ai.meta.com/sam3d" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          Website
        </a>
        <a href="https://www.aidemos.meta.com/segment-anything/editor/convert-body-to-3d" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          Online Demo
        </a>
        <a href="https://github.com/facebookresearch/sam-3d-body" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          GitHub Code
        </a>
      </div>
    </div>
</section>
</body>
</html>
