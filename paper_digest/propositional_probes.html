<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ ArXiv 2024
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">Monitoring Latent World States in Language Models with Propositional Probes</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Jiahai Feng, Stuart Russell, Jacob Steinhardt<br>
        <span style="opacity:0.8">UC Berkeley</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How can we interpret internal activations of language models to extract faithful representations of input contexts as logical propositions, enabling monitoring of unfaithful behavior while maintaining model interpretability?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•è§£é‡Šè¯­è¨€æ¨¡å‹çš„å†…éƒ¨æ¿€æ´»ä»¥æå–è¾“å…¥ä¸Šä¸‹æ–‡çš„å¿ å®é€»è¾‘å‘½é¢˜è¡¨ç¤ºï¼Œå®ç°å¯¹ä¸å¿ å®è¡Œä¸ºçš„ç›‘æ§åŒæ—¶ä¿æŒæ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Propositional Probes:</b> Introduced propositional probes that decode logical propositions from language model activations, compositionally combining domain probes with binding similarity metrics to extract faithful world state representations.</div>
            <div class="lang-zh" style="display:none"><b>å‘½é¢˜æ¢é’ˆï¼š</b>å¼•å…¥äº†å‘½é¢˜æ¢é’ˆï¼Œèƒ½å¤Ÿä»è¯­è¨€æ¨¡å‹æ¿€æ´»ä¸­è§£ç é€»è¾‘å‘½é¢˜ï¼Œé€šè¿‡ç»„åˆé¢†åŸŸæ¢é’ˆä¸ç»‘å®šç›¸ä¼¼åº¦åº¦é‡æ¥æå–å¿ å®çš„ä¸–ç•ŒçŠ¶æ€è¡¨ç¤ºã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Hessian-Based Binding Subspace:</b> Developed a novel Hessian-based algorithm to identify the binding subspace in activation space, enabling causal interventions that mediate entity-attribute binding relationships.</div>
            <div class="lang-zh" style="display:none"><b>åŸºäºHessiançš„ç»‘å®šå­ç©ºé—´ï¼š</b>å¼€å‘äº†ä¸€ç§æ–°é¢–çš„åŸºäºHessiançš„ç®—æ³•æ¥è¯†åˆ«æ¿€æ´»ç©ºé—´ä¸­çš„ç»‘å®šå­ç©ºé—´ï¼Œå®ç°è°ƒè§£å®ä½“-å±æ€§ç»‘å®šå…³ç³»çš„å› æœå¹²é¢„ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Faithful World State Monitoring:</b> Demonstrated that propositional probes remain faithful to input contexts even when language models exhibit unfaithful behavior due to prompt injections, backdoors, and gender bias, suggesting models encode faithful latent world models.</div>
            <div class="lang-zh" style="display:none"><b>å¿ å®ä¸–ç•ŒçŠ¶æ€ç›‘æ§ï¼š</b>è¯æ˜äº†å‘½é¢˜æ¢é’ˆå³ä½¿åœ¨è¯­è¨€æ¨¡å‹ç”±äºæç¤ºæ³¨å…¥ã€åé—¨å’Œæ€§åˆ«åè§è€Œè¡¨ç°å‡ºä¸å¿ å®è¡Œä¸ºæ—¶ä»ä¿æŒå¯¹è¾“å…¥ä¸Šä¸‹æ–‡çš„å¿ å®ï¼Œè¡¨æ˜æ¨¡å‹ç¼–ç äº†å¿ å®çš„æ½œåœ¨ä¸–ç•Œæ¨¡å‹ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Out-of-Distribution Generalization:</b> Showed that probes trained on simple templated contexts generalize to complex paraphrased stories and Spanish translations, validating the robustness of the approach for real-world monitoring applications.</div>
            <div class="lang-zh" style="display:none"><b>åˆ†å¸ƒå¤–æ³›åŒ–ï¼š</b>å±•ç¤ºäº†åœ¨ç®€å•æ¨¡æ¿åŒ–ä¸Šä¸‹æ–‡ä¸­è®­ç»ƒçš„æ¢é’ˆèƒ½å¤Ÿæ³›åŒ–åˆ°å¤æ‚çš„é‡Šä¹‰æ•…äº‹å’Œè¥¿ç­ç‰™è¯­ç¿»è¯‘ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•å¯¹ç°å®ä¸–ç•Œç›‘æ§åº”ç”¨çš„é²æ£’æ€§ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Binding Representation:</b> Understanding how language models represent entity-attribute binding relationships in their internal activations, particularly how to decompose activations into content and binding components.</div>
            <div class="lang-zh" style="display:none"><b>ç»‘å®šè¡¨ç¤ºï¼š</b>ç†è§£è¯­è¨€æ¨¡å‹å¦‚ä½•åœ¨å…¶å†…éƒ¨æ¿€æ´»ä¸­è¡¨ç¤ºå®ä½“-å±æ€§ç»‘å®šå…³ç³»ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•å°†æ¿€æ´»åˆ†è§£ä¸ºå†…å®¹å’Œç»‘å®šç»„ä»¶ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Scalable Proposition Extraction:</b> Developing methods to extract logical propositions from high-dimensional activation spaces that can scale beyond simple closed-world settings to more complex, open-ended scenarios.</div>
            <div class="lang-zh" style="display:none"><b>å¯æ‰©å±•å‘½é¢˜æå–ï¼š</b>å¼€å‘ä»é«˜ç»´æ¿€æ´»ç©ºé—´ä¸­æå–é€»è¾‘å‘½é¢˜çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿæ‰©å±•åˆ°è¶…å‡ºç®€å•å°é—­ä¸–ç•Œè®¾ç½®çš„æ›´å¤æ‚ã€å¼€æ”¾å¼åœºæ™¯ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Faithful vs Unfaithful Representations:</b> Investigating the discrepancy between faithful latent representations and unfaithful model outputs, and developing monitoring tools that can detect when models deviate from their internal understanding.</div>
            <div class="lang-zh" style="display:none"><b>å¿ å®vsä¸å¿ å®è¡¨ç¤ºï¼š</b>è°ƒæŸ¥å¿ å®æ½œåœ¨è¡¨ç¤ºä¸ä¸å¿ å®æ¨¡å‹è¾“å‡ºä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶å¼€å‘èƒ½å¤Ÿæ£€æµ‹æ¨¡å‹ä½•æ—¶åç¦»å…¶å†…éƒ¨ç†è§£çš„ç›‘æ§å·¥å…·ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Robustness to Adversarial Inputs:</b> Ensuring that interpretability methods remain reliable even when models are subjected to adversarial attacks, prompt injections, or other forms of manipulation that affect model behavior.</div>
            <div class="lang-zh" style="display:none"><b>å¯¹å¯¹æŠ—æ€§è¾“å…¥çš„é²æ£’æ€§ï¼š</b>ç¡®ä¿å¯è§£é‡Šæ€§æ–¹æ³•å³ä½¿åœ¨æ¨¡å‹å—åˆ°å¯¹æŠ—æ€§æ”»å‡»ã€æç¤ºæ³¨å…¥æˆ–å…¶ä»–å½±å“æ¨¡å‹è¡Œä¸ºçš„æ“çºµå½¢å¼æ—¶ä»ä¿æŒå¯é ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <div style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>The paper develops propositional probes to extract logical world states from language model activations:</p>
            <ol style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>Closed-World Proposition Representation:</b> Define a closed world of people and attributes (names, countries, occupations, foods) represented as logical propositions like LivesIn(Carol, Italy).</li>
                <li style="margin-bottom:6px;"><b>Hessian-Based Binding Subspace Identification:</b> Use second-derivative analysis of binding strength to identify subspaces in activation space where bound tokens have similar activations, enabling causal interventions.</li>
                <li style="margin-bottom:6px;"><b>Domain Probes Construction:</b> Train linear probes that classify activation vectors into domain values (names, countries, etc.) or null, using Grad-CAM attribution to identify informative layers and token positions.</li>
                <li style="margin-bottom:6px;"><b>Propositional Composition:</b> Combine domain probes with binding similarity metrics to compose propositions, using a lookup algorithm that matches names to their most similar attribute tokens.</li>
                <li style="margin-bottom:6px;"><b>Faithfulness Evaluation:</b> Test probes on unfaithful model behaviors (prompt injections, backdoors, gender bias) to verify they remain faithful to input contexts while model outputs do not.</li>
            </ol>
          </div>
          <div class="lang-zh" style="display: none;">
            <p>è®ºæ–‡å¼€å‘äº†å‘½é¢˜æ¢é’ˆæ¥ä»è¯­è¨€æ¨¡å‹æ¿€æ´»ä¸­æå–é€»è¾‘ä¸–ç•ŒçŠ¶æ€ï¼š</p>
            <ol style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>å°é—­ä¸–ç•Œå‘½é¢˜è¡¨ç¤ºï¼š</b>å®šä¹‰ä¸€ä¸ªäººå’Œå±æ€§ï¼ˆåç§°ã€å›½å®¶ã€èŒä¸šã€é£Ÿç‰©ï¼‰çš„å°é—­ä¸–ç•Œï¼Œè¡¨ç¤ºä¸ºé€»è¾‘å‘½é¢˜å¦‚LivesIn(Carol, Italy)ã€‚</li>
                <li style="margin-bottom:6px;"><b>åŸºäºHessiançš„ç»‘å®šå­ç©ºé—´è¯†åˆ«ï¼š</b>ä½¿ç”¨ç»‘å®šå¼ºåº¦çš„äºŒé˜¶å¯¼æ•°åˆ†ææ¥è¯†åˆ«æ¿€æ´»ç©ºé—´ä¸­çš„å­ç©ºé—´ï¼Œå…¶ä¸­ç»‘å®šæ ‡è®°å…·æœ‰ç›¸ä¼¼çš„æ¿€æ´»ï¼Œå®ç°å› æœå¹²é¢„ã€‚</li>
                <li style="margin-bottom:6px;"><b>é¢†åŸŸæ¢é’ˆæ„å»ºï¼š</b>è®­ç»ƒçº¿æ€§æ¢é’ˆï¼Œå°†æ¿€æ´»å‘é‡åˆ†ç±»ä¸ºé¢†åŸŸå€¼ï¼ˆåç§°ã€å›½å®¶ç­‰ï¼‰æˆ–nullï¼Œä½¿ç”¨Grad-CAMå½’å› æ¥è¯†åˆ«ä¿¡æ¯ä¸°å¯Œçš„å±‚å’Œæ ‡è®°ä½ç½®ã€‚</li>
                <li style="margin-bottom:6px;"><b>å‘½é¢˜ç»„åˆï¼š</b>å°†é¢†åŸŸæ¢é’ˆä¸ç»‘å®šç›¸ä¼¼åº¦åº¦é‡ç›¸ç»“åˆæ¥ç»„åˆå‘½é¢˜ï¼Œä½¿ç”¨æŸ¥æ‰¾ç®—æ³•å°†åç§°ä¸å…¶æœ€ç›¸ä¼¼çš„å±æ€§æ ‡è®°åŒ¹é…ã€‚</li>
                <li style="margin-bottom:6px;"><b>å¿ å®æ€§è¯„ä¼°ï¼š</b>åœ¨ä¸å¿ å®æ¨¡å‹è¡Œä¸ºï¼ˆæç¤ºæ³¨å…¥ã€åé—¨ã€æ€§åˆ«åè§ï¼‰ä¸Šæµ‹è¯•æ¢é’ˆï¼Œä»¥éªŒè¯å®ƒä»¬åœ¨æ¨¡å‹è¾“å‡ºä¸å¿ å®æ—¶ä»ä¿æŒå¯¹è¾“å…¥ä¸Šä¸‹æ–‡çš„å¿ å®ã€‚</li>
            </ol>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆå¼•è¨€å›¾ï¼‰</h2>
        <div style="border-radius:14px; overflow:hidden;">
            <img src="Figures/propositional_probes_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px solid rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/propositional_probes_overview01.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />
            <div style="height:1px; background:rgba(255,255,255,.10); margin:12px 0;"></div>
            <img src="Figures/propositional_probes_overview02.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />
            <p>Propositional probes extract logical propositions from LM activations by identifying binding subspaces and composing domain probes, enabling faithful monitoring of latent world states.</p>
            <p>Note: The approach shows that LMs may encode faithful internal world models but decode them unfaithfully, motivating the development of monitoring tools for detecting unfaithful behavior in AI systems.</p>

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('arxiv_propositional_probes.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('arxiv_propositional_probes.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <h3 style="margin:12px 0 6px;font-size:14px;color:#8bffcf;">Why it Works?</h3>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>The success of propositional probes stems from understanding the geometric structure of language model representations:</p>
            <ul style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>Binding Subspace Geometry:</b> The Hessian-based algorithm identifies low-dimensional subspaces that causally control entity-attribute binding, allowing interventions that swap bound relationships without affecting content.</li>
                <li style="margin-bottom:6px;"><b>Compositional Probe Design:</b> Domain probes leverage the locality of semantic information in activation space, while binding similarity metrics exploit the structured nature of predicate-argument relationships.</li>
                <li style="margin-bottom:6px;"><b>Faithful Latent Representations:</b> The finding that probes remain faithful while model outputs become unfaithful suggests that language models construct internal world models that are more truthful than their final generations.</li>
                <li style="margin-bottom:6px;"><b>Robust Attribution Methods:</b> Grad-CAM-style attribution identifies which layers and token positions carry semantic information, enabling probes to target the most informative activations for decoding.</li>
                <li style="margin-bottom:6px;"><b>Out-of-Distribution Robustness:</b> The generalization from templated to paraphrased and translated contexts demonstrates that the learned binding mechanisms capture fundamental linguistic structures rather than superficial patterns.</li>
            </ul>
          </div>
          <div class="lang-zh" style="display:none">
            <p>å‘½é¢˜æ¢é’ˆçš„æˆåŠŸæºäºç†è§£è¯­è¨€æ¨¡å‹è¡¨ç¤ºçš„å‡ ä½•ç»“æ„ï¼š</p>
            <ul style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>ç»‘å®šå­ç©ºé—´å‡ ä½•ï¼š</b>åŸºäºHessiançš„ç®—æ³•è¯†åˆ«å‡ºæ§åˆ¶å®ä½“-å±æ€§ç»‘å®šçš„ä½ç»´å­ç©ºé—´ï¼Œå…è®¸å¹²é¢„åœ¨ä¸å½±å“å†…å®¹çš„æƒ…å†µä¸‹äº¤æ¢ç»‘å®šå…³ç³»ã€‚</li>
                <li style="margin-bottom:6px;"><b>ç»„åˆæ¢é’ˆè®¾è®¡ï¼š</b>é¢†åŸŸæ¢é’ˆåˆ©ç”¨æ¿€æ´»ç©ºé—´ä¸­è¯­ä¹‰ä¿¡æ¯çš„å±€éƒ¨æ€§ï¼Œè€Œç»‘å®šç›¸ä¼¼åº¦åº¦é‡åˆ©ç”¨è°“è¯-å‚æ•°å…³ç³»çš„ç»“æ„åŒ–æ€§è´¨ã€‚</li>
                <li style="margin-bottom:6px;"><b>å¿ å®çš„æ½œåœ¨è¡¨ç¤ºï¼š</b>æ¢é’ˆä¿æŒå¿ å®è€Œæ¨¡å‹è¾“å‡ºå˜å¾—ä¸å¿ å®çš„å‘ç°è¡¨æ˜ï¼Œè¯­è¨€æ¨¡å‹æ„å»ºçš„å†…éƒ¨ä¸–ç•Œæ¨¡å‹æ¯”å…¶æœ€ç»ˆç”Ÿæˆæ›´çœŸå®ã€‚</li>
                <li style="margin-bottom:6px;"><b>é²æ£’å½’å› æ–¹æ³•ï¼š</b>Grad-CAMé£æ ¼çš„å½’å› è¯†åˆ«å“ªäº›å±‚å’Œæ ‡è®°ä½ç½®æºå¸¦è¯­ä¹‰ä¿¡æ¯ï¼Œä½¿æ¢é’ˆèƒ½å¤Ÿé’ˆå¯¹è§£ç çš„æœ€å…·ä¿¡æ¯é‡çš„æ¿€æ´»ã€‚</li>
                <li style="margin-bottom:6px;"><b>åˆ†å¸ƒå¤–é²æ£’æ€§ï¼š</b>ä»æ¨¡æ¿åŒ–åˆ°é‡Šä¹‰å’Œç¿»è¯‘ä¸Šä¸‹æ–‡çš„æ³›åŒ–è¡¨æ˜ï¼Œå­¦ä¹ çš„ç»‘å®šæœºåˆ¶æ•è·äº†åŸºæœ¬çš„è¯­è¨€ç»“æ„è€Œä¸æ˜¯è¡¨é¢æ¨¡å¼ã€‚</li>
            </ul>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>This groundbreaking work establishes a foundation for monitoring and interpreting the internal states of language models through propositional probes. By demonstrating that language models construct faithful latent representations of input contexts that can be decoded as logical propositions, the paper provides crucial insights into the discrepancy between internal model understanding and external behaviors. The Hessian-based approach for identifying binding subspaces represents a significant methodological advance in mechanistic interpretability, enabling causal interventions that reveal how language models represent entity-attribute relationships. The finding that propositional probes remain faithful to input contexts even when prompted models exhibit unfaithful behaviors due to biases, prompt injections, or backdoors has profound implications for AI safety and trustworthiness. This work suggests that language models may indeed construct internal "world models" that are more reliable than their outputs, opening avenues for developing monitoring systems that can detect when models deviate from their internal understanding. The successful generalization of probes to out-of-distribution contexts, including paraphrased stories and foreign languages, demonstrates the robustness of the approach for real-world applications. Future work could extend these methods to larger, more complex worlds, potentially enabling comprehensive monitoring of language model faithfulness at inference time. The paper represents a critical step toward understanding the internal mechanisms of large language models and developing the interpretability tools necessary for their safe and reliable deployment.</p>
          </div>
          <div class="lang-zh" style="display:none">
            <p>è¿™é¡¹å¼€åˆ›æ€§å·¥ä½œé€šè¿‡å‘½é¢˜æ¢é’ˆä¸ºç›‘æ§å’Œè§£é‡Šè¯­è¨€æ¨¡å‹çš„å†…éƒ¨çŠ¶æ€å¥ å®šäº†åŸºç¡€ã€‚é€šè¿‡è¯æ˜è¯­è¨€æ¨¡å‹æ„å»ºäº†å¯ä»¥è§£ç ä¸ºé€»è¾‘å‘½é¢˜çš„è¾“å…¥ä¸Šä¸‹æ–‡çš„å¿ å®æ½œåœ¨è¡¨ç¤ºï¼Œè®ºæ–‡æä¾›äº†å¯¹å†…éƒ¨æ¨¡å‹ç†è§£ä¸å¤–éƒ¨è¡Œä¸ºä¹‹é—´å·®å¼‚çš„å…³é”®æ´è§ã€‚ç”¨äºè¯†åˆ«ç»‘å®šå­ç©ºé—´çš„åŸºäºHessiançš„æ–¹æ³•ä»£è¡¨äº†æœºåˆ¶å¯è§£é‡Šæ€§ä¸­çš„é‡å¤§æ–¹æ³•è¿›æ­¥ï¼Œèƒ½å¤Ÿå®ç°æ­ç¤ºè¯­è¨€æ¨¡å‹å¦‚ä½•è¡¨ç¤ºå®ä½“-å±æ€§å…³ç³»çš„å› æœå¹²é¢„ã€‚å‘½é¢˜æ¢é’ˆåœ¨æ¨¡å‹ç”±äºåè§ã€æç¤ºæ³¨å…¥æˆ–åé—¨è€Œè¡¨ç°å‡ºä¸å¿ å®è¡Œä¸ºæ—¶ä»ä¿æŒå¯¹è¾“å…¥ä¸Šä¸‹æ–‡çš„å¿ å®çš„å‘ç°ï¼Œå¯¹AIå®‰å…¨æ€§å’Œå¯ä¿¡åº¦å…·æœ‰æ·±è¿œå½±å“ã€‚è¿™é¡¹å·¥ä½œè¡¨æ˜ï¼Œè¯­è¨€æ¨¡å‹å¯èƒ½ç¡®å®æ„å»ºäº†æ¯”å…¶è¾“å‡ºæ›´å¯é çš„å†…éƒ¨"ä¸–ç•Œæ¨¡å‹"ï¼Œä¸ºå¼€å‘èƒ½å¤Ÿåœ¨æ¨¡å‹åç¦»å…¶å†…éƒ¨ç†è§£æ—¶è¿›è¡Œæ£€æµ‹çš„ç›‘æ§ç³»ç»Ÿå¼€è¾Ÿäº†é€”å¾„ã€‚æ¢é’ˆæˆåŠŸæ³›åŒ–åˆ°åˆ†å¸ƒå¤–ä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬é‡Šä¹‰æ•…äº‹å’Œå¤–è¯­ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•å¯¹ç°å®ä¸–ç•Œåº”ç”¨çš„é²æ£’æ€§ã€‚æœªæ¥å·¥ä½œå¯ä»¥æ‰©å±•è¿™äº›æ–¹æ³•åˆ°æ›´å¤§ã€æ›´å¤æ‚çš„é¢†åŸŸï¼Œå¯èƒ½å®ç°å¯¹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†æ—¶çš„å¿ å®æ€§çš„å…¨é¢ç›‘æ§ã€‚è®ºæ–‡ä»£è¡¨äº†ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹å†…éƒ¨æœºåˆ¶çš„å…³é”®æ­¥éª¤ï¼Œå¹¶ä¸ºå¼€å‘å…¶å®‰å…¨å¯é éƒ¨ç½²æ‰€éœ€çš„å¯è§£é‡Šæ€§å·¥å…·å¥ å®šäº†åŸºç¡€ã€‚</p>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Official Code</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <p><b>ArXiv:</b> <a href="https://arxiv.org/abs/2406.19501" target="_blank" style="color:#8bffcf;">2406.19501</a></p>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Core Code Implementationï¼ˆæ ¸å¿ƒä»£ç ï¼‰</h2>
        <div style="background:rgba(0,0,0,0.5); border:1px solid rgba(255,255,255,0.1); border-radius:8px; padding:12px; font-family:ui-monospace,Menlo,Consolas,monospace; font-size:12px; color:#8bffcf; margin:8px 0; overflow-x:auto;">
# Propositional Probes Implementation<br>
<br>
// Hessian-based Binding Subspace Identification<br>
<span style="color:#569cd6;">class</span> <span style="color:#dcdcaa;">BindingSubspaceIdentifier</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""Identify binding subspace using Hessian analysis of binding strength"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">__init__</span>(self, language_model):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.lm = language_model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.layer = 15  <span style="color:#6a9955;"># Layer for binding similarity</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">compute_binding_strength</span>(self, context, query_entity, expected_attr):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Compute probability of correct attribute prediction after query"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;query = <span style="color:#ce9178;">f"What is {query_entity}'s attribute?"</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;full_input = context + query<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Get probability of expected attribute</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logits = self.lm.generate_logits(full_input)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prob_correct = torch.softmax(logits[:, -1], dim=-1)[expected_attr]<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> prob_correct<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">identify_binding_subspace</span>(self, contexts):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Use Hessian to identify binding subspace from contexts"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># For each context with two entities, compute binding differences</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;binding_vectors = []<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> context <span style="color:#569cd6;">in</span> contexts:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Extract entity and attribute activations</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activations = self.lm.get_activations(context, layer=self.layer)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Compute average difference in binding vectors</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delta_binding = self.compute_binding_differences(activations)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;binding_vectors.append(delta_binding)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Compute Hessian of binding strength function</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;H = self.compute_binding_hessian(binding_vectors)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Extract low-rank subspace via SVD</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;U, S, V = torch.svd(H)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;subspace_dim = 50  <span style="color:#6a9955;"># Use top 50 dimensions</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;binding_subspace = U[:, :subspace_dim]<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> binding_subspace<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">binding_similarity</span>(self, act1, act2, subspace):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Compute binding similarity between two activations"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;proj1 = subspace.T @ act1<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;proj2 = subspace.T @ act2<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;similarity = proj1.T @ proj2<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> similarity<br>
<br>
// Domain Probes for lexical information<br>
<span style="color:#569cd6;">class</span> <span style="color:#dcdcaa;">DomainProbe</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""Linear probe for classifying activations into domain values"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">__init__</span>(self, domain_values, hidden_dim):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.domain_values = domain_values + [<span style="color:#ce9178;">"NULL"</span>]<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.probe = nn.Linear(hidden_dim, len(self.domain_values))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.threshold = 0.0  <span style="color:#6a9955;"># Threshold for NULL classification</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">train</span>(self, activations, labels):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Train probe using difference-in-means initialization"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Initialize probe vectors to mean activations per class</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> i, value <span style="color:#569cd6;">in</span> enumerate(self.domain_values):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value_mask = labels == value<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">if</span> value_mask.any():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mean_activation = activations[value_mask].mean(dim=0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.probe.weight.data[i] = mean_activation<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">else</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.probe.weight.data[i] = torch.randn_like(self.probe.weight.data[i])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Fine-tune probe</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer = torch.optim.Adam(self.probe.parameters())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> _ <span style="color:#569cd6;">in</span> range(100):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logits = self.probe(activations)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss = F.cross_entropy(logits, labels)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.zero_grad()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss.backward()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.step()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">classify</span>(self, activation):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Classify activation into domain value or NULL"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logits = self.probe(activation)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_prob, pred_idx = torch.softmax(logits, dim=-1).max(dim=-1)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">if</span> max_prob > self.threshold:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> self.domain_values[pred_idx]<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">else</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> <span style="color:#ce9178;">"NULL"</span><br>
<br>
// Propositional Probes Composition<br>
<span style="color:#569cd6;">class</span> <span style="color:#dcdcaa;">PropositionalProbe</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""Compose domain probes into logical propositions using binding similarity"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">__init__</span>(self, domain_probes, binding_subspace, binding_identifier):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.domain_probes = domain_probes  <span style="color:#6a9955;"># Dict of domain_name -> probe</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.binding_subspace = binding_subspace<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.binding_identifier = binding_identifier<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">extract_propositions</span>(self, context):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Extract logical propositions from context activations"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Get activations at probe layer</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activations = self.binding_identifier.lm.get_activations(context, layer=20)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Identify names and attributes using domain probes</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;names = []<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attributes = {domain: [] <span style="color:#569cd6;">for</span> domain <span style="color:#569cd6;">in</span> self.domain_probes <span style="color:#569cd6;">if</span> domain != <span style="color:#ce9178;">"names"</span>}<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> i, act <span style="color:#569cd6;">in</span> enumerate(activations):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name = self.domain_probes[<span style="color:#ce9178;">"names"</span>].classify(act)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">if</span> name != <span style="color:#ce9178;">"NULL"</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;names.append((i, act, name))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> domain, probe <span style="color:#569cd6;">in</span> self.domain_probes.items():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">if</span> domain == <span style="color:#ce9178;">"names"</span>: <span style="color:#569cd6;">continue</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attr = probe.classify(act)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">if</span> attr != <span style="color:#ce9178;">"NULL"</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attributes[domain].append((i, act, attr))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Compose propositions by binding names to most similar attributes</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;propositions = []<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> _, name_act, name <span style="color:#569cd6;">in</span> names:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> domain, attr_list <span style="color:#569cd6;">in</span> attributes.items():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;best_attr = <span style="color:#569cd6;">None</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_similarity = -float(<span style="color:#ce9178;">'inf'</span>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> _, attr_act, attr <span style="color:#569cd6;">in</span> attr_list:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;similarity = self.binding_identifier.binding_similarity(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name_act, attr_act, self.binding_subspace)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">if</span> similarity > max_similarity:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_similarity = similarity<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;best_attr = attr<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">if</span> best_attr:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;propositions.append(<span style="color:#ce9178;">f"{domain.capitalize()}({name}, {best_attr})"</span>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> propositions<br>
        </div>
      </div>
    </div>
</section>
</body>
</html>
