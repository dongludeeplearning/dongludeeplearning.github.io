<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  // ç›´æ¥æ‰“å¼€PDFæ–‡ä»¶
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ ICLR 2026
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">SceneCOT: Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Xiongkun Linghu, Jiangyong Huang, Ziyu Zhu, Baoxiong Jia, Siyuan Huang<br>
        <span style="opacity:0.8">Beijing Institute for General Artificial Intelligence, Peking University, Tsinghua University</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to enable step-by-step, human-like grounded Chain-of-Thought reasoning in 3D scenes to overcome the limitations of current 3D Large Language Models that lack interpretable and coherent scene-object reasoning?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•åœ¨3Dåœºæ™¯ä¸­å®ç°é€æ­¥çš„ã€ç±»ä¼¼äººç±»çš„åŸºäºåœºæ™¯çš„Chain-of-Thoughtæ¨ç†ï¼Œä»¥å…‹æœå½“å‰3Då¤§è¯­è¨€æ¨¡å‹ç¼ºä¹å¯è§£é‡Šæ€§å’Œè¿è´¯çš„åœºæ™¯-å¯¹è±¡æ¨ç†çš„å±€é™æ€§ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>SceneCOT Framework:</b> Pioneering Chain-of-Thought reasoning framework for 3D scenes that decomposes complex reasoning tasks into four hierarchical stages: task recognition, region localization, entity grounding, and grounded reasoning, enabling human-like step-by-step scene understanding.</div>
            <div class="lang-zh" style="display:none"><b>SceneCOTæ¡†æ¶ï¼š</b>å¼€åˆ›æ€§çš„3Dåœºæ™¯Chain-of-Thoughtæ¨ç†æ¡†æ¶ï¼Œå°†å¤æ‚æ¨ç†ä»»åŠ¡åˆ†è§£ä¸ºå››ä¸ªå±‚æ¬¡é˜¶æ®µï¼šä»»åŠ¡è¯†åˆ«ã€åŒºåŸŸå®šä½ã€å®ä½“æ¥åœ°å’ŒåŸºäºåœºæ™¯çš„æ¨ç†ï¼Œå®ç°ç±»ä¼¼äººç±»çš„é€æ­¥åœºæ™¯ç†è§£ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>SceneCOT-185K Dataset:</b> First large-scale grounded CoT dataset for 3D reasoning with 185K high-quality instances covering situated reasoning and object-centric reasoning tasks, providing comprehensive training data for step-by-step 3D scene understanding.</div>
            <div class="lang-zh" style="display:none"><b>SceneCOT-185Kæ•°æ®é›†ï¼š</b>é¦–ä¸ªå¤§è§„æ¨¡3Dæ¨ç†åŸºäºåœºæ™¯çš„CoTæ•°æ®é›†ï¼ŒåŒ…å«185Ké«˜è´¨é‡å®ä¾‹ï¼Œæ¶µç›–æƒ…å¢ƒæ¨ç†å’Œä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„æ¨ç†ä»»åŠ¡ï¼Œä¸ºé€æ­¥3Dåœºæ™¯ç†è§£æä¾›å…¨é¢çš„è®­ç»ƒæ•°æ®ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multimodal Expert Integration:</b> Novel integration of specialized 3D-VL and 2D-VL models with symbolic engines within the CoT framework, enabling explicit grounding signals (object probabilities, locations, image tokens) for enhanced reasoning coherence.</div>
            <div class="lang-zh" style="display:none"><b>å¤šæ¨¡æ€ä¸“å®¶é›†æˆï¼š</b>åœ¨CoTæ¡†æ¶å†…æ–°é¢–åœ°é›†æˆä¸“é—¨çš„3D-VLå’Œ2D-VLæ¨¡å‹ä¸ç¬¦å·å¼•æ“ï¼Œå®ç°æ˜¾å¼æ¥åœ°ä¿¡å·ï¼ˆå¯¹è±¡æ¦‚ç‡ã€ä½ç½®ã€å›¾åƒä»¤ç‰Œï¼‰ä»¥å¢å¼ºæ¨ç†è¿è´¯æ€§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Superior Grounding-QA Coherence:</b> Achieves state-of-the-art performance on MSQA and Beacon3D benchmarks with significant improvements in grounding-QA coherence (34.7 GC score), demonstrating the effectiveness of step-by-step grounded reasoning in 3D scenes.</div>
            <div class="lang-zh" style="display:none"><b>å“è¶Šçš„æ¥åœ°-QAè¿è´¯æ€§ï¼š</b>åœ¨MSQAå’ŒBeacon3DåŸºå‡†ä¸Šå®ç°æœ€å…ˆè¿›æ€§èƒ½ï¼Œåœ¨æ¥åœ°-QAè¿è´¯æ€§æ–¹é¢å–å¾—æ˜¾è‘—æ”¹è¿›ï¼ˆ34.7 GCåˆ†æ•°ï¼‰ï¼Œè¯æ˜äº†3Dåœºæ™¯ä¸­é€æ­¥åŸºäºåœºæ™¯æ¨ç†çš„æœ‰æ•ˆæ€§ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆå¼•è¨€ç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/scenecot_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('2510.16714.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('2510.16714.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/scenecot_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('2510.16714.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('2510.16714.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Complex 3D Spatial Reasoning:</b> 3D scenes require navigating large spaces, interpreting intricate spatial relations, and coping with partial observability, making traditional end-to-end approaches insufficient for human-like embodied reasoning.</div>
            <div class="lang-zh" style="display:none"><b>å¤æ‚çš„3Dç©ºé—´æ¨ç†ï¼š</b>3Dåœºæ™¯éœ€è¦å¯¼èˆªå¤§ç©ºé—´ã€è§£é‡Šå¤æ‚çš„ç©ºé—´å…³ç³»å¹¶åº”å¯¹éƒ¨åˆ†å¯è§‚æµ‹æ€§ï¼Œä½¿å¾—ä¼ ç»Ÿçš„ç«¯åˆ°ç«¯æ–¹æ³•ä¸è¶³ä»¥å®ç°ç±»ä¼¼äººç±»çš„å…·èº«æ¨ç†ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Lack of Interpretability:</b> Current 3D LLMs produce plausible answers without explicit grounding in scene elements, leading to poor grounding-QA coherence and unreliable reasoning in complex scenarios.</div>
            <div class="lang-zh" style="display:none"><b>ç¼ºä¹å¯è§£é‡Šæ€§ï¼š</b>å½“å‰çš„3D LLMäº§ç”Ÿçœ‹ä¼¼åˆç†çš„ç­”æ¡ˆè€Œæ²¡æœ‰æ˜¾å¼åœ°åŸºäºåœºæ™¯å…ƒç´ ï¼Œå¯¼è‡´æ¥åœ°-QAè¿è´¯æ€§å·®ä»¥åŠåœ¨å¤æ‚åœºæ™¯ä¸­çš„ä¸å¯é æ¨ç†ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Task Decomposition Gap:</b> Existing methods lack principled approaches for breaking down complex 3D reasoning tasks into manageable subproblems, hindering the development of step-by-step reasoning mechanisms.</div>
            <div class="lang-zh" style="display:none"><b>ä»»åŠ¡åˆ†è§£å·®è·ï¼š</b>ç°æœ‰æ–¹æ³•ç¼ºä¹å°†å¤æ‚3Dæ¨ç†ä»»åŠ¡åˆ†è§£ä¸ºå¯ç®¡ç†å­é—®é¢˜çš„åŸåˆ™æ€§æ–¹æ³•ï¼Œé˜»ç¢äº†é€æ­¥æ¨ç†æœºåˆ¶çš„å‘å±•ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Grounding-Reasoning Disconnect:</b> Most 3D-LLMs encode multimodal representations but rarely incorporate structured reasoning processes that connect intermediate grounding steps with final reasoning outcomes.</div>
            <div class="lang-zh" style="display:none"><b>æ¥åœ°-æ¨ç†æ–­å¼€ï¼š</b>å¤§å¤šæ•°3D-LLMç¼–ç å¤šæ¨¡æ€è¡¨ç¤ºï¼Œä½†å¾ˆå°‘çº³å…¥å°†ä¸­é—´æ¥åœ°æ­¥éª¤ä¸æœ€ç»ˆæ¨ç†ç»“æœè¿æ¥èµ·æ¥çš„ç»“æ„åŒ–æ¨ç†è¿‡ç¨‹ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Limited CoT Exploration:</b> While Chain-of-Thought reasoning has revolutionized 2D multimodal models, its potential in 3D scene understanding remains largely untapped due to challenges in aligning language-based reasoning with 3D spatial representations.</div>
            <div class="lang-zh" style="display:none"><b>CoTæ¢ç´¢æœ‰é™ï¼š</b>è™½ç„¶Chain-of-Thoughtæ¨ç†å·²ç»å½»åº•æ”¹å˜äº†2Då¤šæ¨¡æ€æ¨¡å‹ï¼Œä½†ç”±äºå°†åŸºäºè¯­è¨€çš„æ¨ç†ä¸3Dç©ºé—´è¡¨ç¤ºå¯¹é½çš„æŒ‘æˆ˜ï¼Œå…¶åœ¨3Dåœºæ™¯ç†è§£ä¸­çš„æ½œåŠ›åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä»æœªè¢«å¼€å‘ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Hierarchical CoT Structure:</b> Four-stage reasoning process: (1) task recognition and analysis with <think_type>, (2) region localization with <think_rgn>, (3) entity grounding with multimodal experts via [OBJ] token, and (4) grounded reasoning with explicit grounding signals.</div>
            <div class="lang-zh" style="display:none"><b>åˆ†å±‚CoTç»“æ„ï¼š</b>å››é˜¶æ®µæ¨ç†è¿‡ç¨‹ï¼š(1) ä½¿ç”¨<think_type>è¿›è¡Œä»»åŠ¡è¯†åˆ«å’Œåˆ†æï¼Œ(2) ä½¿ç”¨<think_rgn>è¿›è¡ŒåŒºåŸŸå®šä½ï¼Œ(3) é€šè¿‡[OBJ]ä»¤ç‰Œä½¿ç”¨å¤šæ¨¡æ€ä¸“å®¶è¿›è¡Œå®ä½“æ¥åœ°ï¼Œä»¥åŠ(4) ä½¿ç”¨æ˜¾å¼æ¥åœ°ä¿¡å·è¿›è¡ŒåŸºäºåœºæ™¯çš„æ¨ç†ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multimodal Expert Modules:</b> Integration of 3D-VL grounding models (PQ3D), 2D-VL models for attribute recognition, and symbolic engines for spatial reasoning, invoked through special tokens to provide grounding signals like object probabilities, locations, and image tokens.</div>
            <div class="lang-zh" style="display:none"><b>å¤šæ¨¡æ€ä¸“å®¶æ¨¡å—ï¼š</b>é›†æˆ3D-VLæ¥åœ°æ¨¡å‹ï¼ˆPQ3Dï¼‰ã€ç”¨äºå±æ€§è¯†åˆ«çš„2D-VLæ¨¡å‹ä»¥åŠç”¨äºç©ºé—´æ¨ç†çš„ç¬¦å·å¼•æ“ï¼Œé€šè¿‡ç‰¹æ®Šä»¤ç‰Œè°ƒç”¨ä»¥æä¾›æ¥åœ°ä¿¡å·ï¼Œå¦‚å¯¹è±¡æ¦‚ç‡ã€ä½ç½®å’Œå›¾åƒä»¤ç‰Œã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>SceneCOT-185K Dataset:</b> Large-scale dataset with 185K instances covering situated reasoning (MSQA-based) and object-centric reasoning (Beacon3D-based), constructed through metadata collection and automated reasoning trace generation with rule-based object extraction and GPT-4o augmentation.</div>
            <div class="lang-zh" style="display:none"><b>SceneCOT-185Kæ•°æ®é›†ï¼š</b>å¤§è§„æ¨¡æ•°æ®é›†åŒ…å«185Kå®ä¾‹ï¼Œæ¶µç›–æƒ…å¢ƒæ¨ç†ï¼ˆåŸºäºMSQAï¼‰å’Œä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„æ¨ç†ï¼ˆåŸºäºBeacon3Dï¼‰ï¼Œé€šè¿‡å…ƒæ•°æ®æ”¶é›†å’Œè‡ªåŠ¨æ¨ç†è½¨è¿¹ç”Ÿæˆæ„å»ºï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„å¯¹è±¡æå–å’ŒGPT-4oå¢å¼ºã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Joint Training Objective:</b> Combined loss function (LCoT + Lans + Lground) for training multimodal LLM with LoRA, optimizing reasoning traces, final answers, and grounding accuracy while keeping expert modules updatable.</div>
            <div class="lang-zh" style="display:none"><b>è”åˆè®­ç»ƒç›®æ ‡ï¼š</b>ç»„åˆæŸå¤±å‡½æ•°ï¼ˆLCoT + Lans + Lgroundï¼‰ç”¨äºä½¿ç”¨LoRAè®­ç»ƒå¤šæ¨¡æ€LLMï¼ŒåŒæ—¶ä¼˜åŒ–æ¨ç†è½¨è¿¹ã€æœ€ç»ˆç­”æ¡ˆå’Œæ¥åœ°å‡†ç¡®æ€§ï¼Œå¹¶ä¿æŒä¸“å®¶æ¨¡å—å¯æ›´æ–°ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Inference Pipeline:</b> Step-by-step execution following predicted CoT structure, invoking external modules for grounding operations and concatenating results back into the reasoning chain for coherent final answers.</div>
            <div class="lang-zh" style="display:none"><b>æ¨ç†ç®¡é“ï¼š</b>éµå¾ªé¢„æµ‹çš„CoTç»“æ„é€æ­¥æ‰§è¡Œï¼Œä¸ºæ¥åœ°æ“ä½œè°ƒç”¨å¤–éƒ¨æ¨¡å—å¹¶å°†ç»“æœè¿æ¥å›æ¨ç†é“¾ä¸­ï¼Œä»¥è·å¾—è¿è´¯çš„æœ€ç»ˆç­”æ¡ˆã€‚</div>
          </li>
        </ol>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>CoT for 3D Reasoning:</b> SceneCOT successfully extends Chain-of-Thought reasoning from 2D to 3D domains by decomposing spatial reasoning tasks into hierarchical stages, enabling interpretable and grounded scene understanding that was previously unattainable.
            </div>
            <div class="lang-zh" style="display:none">
                <b>CoTç”¨äº3Dæ¨ç†ï¼š</b>SceneCOTæˆåŠŸåœ°å°†Chain-of-Thoughtæ¨ç†ä»2Dæ‰©å±•åˆ°3Dé¢†åŸŸï¼Œé€šè¿‡å°†ç©ºé—´æ¨ç†ä»»åŠ¡åˆ†è§£ä¸ºåˆ†å±‚é˜¶æ®µï¼Œå®ç°ä»¥å‰æ— æ³•å®ç°çš„æ˜“è§£é‡Šå’ŒåŸºäºåœºæ™¯çš„åœºæ™¯ç†è§£ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Grounding-QA Coherence:</b> By explicitly connecting intermediate grounding steps with final reasoning outcomes through structured CoT traces, SceneCOT achieves superior grounding-QA coherence compared to end-to-end approaches that produce plausible but ungrounded answers.
            </div>
            <div class="lang-zh" style="display:none">
                <b>æ¥åœ°-QAè¿è´¯æ€§ï¼š</b>é€šè¿‡ç»“æ„åŒ–CoTè½¨è¿¹å°†ä¸­é—´æ¥åœ°æ­¥éª¤ä¸æœ€ç»ˆæ¨ç†ç»“æœæ˜¾å¼è¿æ¥ï¼ŒSceneCOTç›¸æ¯”äº§ç”Ÿçœ‹ä¼¼åˆç†ä½†æ— æ ¹æ®ç­”æ¡ˆçš„ç«¯åˆ°ç«¯æ–¹æ³•å®ç°äº†å“è¶Šçš„æ¥åœ°-QAè¿è´¯æ€§ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Multimodal Integration:</b> The seamless integration of 3D-VL, 2D-VL, and symbolic reasoning components within the CoT framework demonstrates the potential for building more comprehensive embodied AI systems with explicit reasoning capabilities.
            </div>
            <div class="lang-zh" style="display:none">
                <b>å¤šæ¨¡æ€é›†æˆï¼š</b>åœ¨CoTæ¡†æ¶å†…æ— ç¼é›†æˆ3D-VLã€2D-VLå’Œç¬¦å·æ¨ç†ç»„ä»¶ï¼Œå±•ç¤ºäº†æ„å»ºå…·æœ‰æ˜¾å¼æ¨ç†èƒ½åŠ›çš„æ›´å…¨é¢çš„å…·èº«AIç³»ç»Ÿçš„æ½œåŠ›ã€‚
            </div>
          </li>
        </ul>

        <div style="margin-top:16px; padding-top:12px; border-top:1px dashed rgba(255,255,255,.15);">
             <h3 style="margin:0 0 6px; font-size:14px; color:#8bffcf;">
               <span class="lang-en">High-Level Insights: Why it Works?</span>
               <span class="lang-zh" style="display:none">é«˜å±‚æ´å¯Ÿï¼šä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ</span>
             </h3>
             <div class="lang-en" style="color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                It works because SceneCOT addresses the fundamental disconnect between multimodal scene understanding and coherent reasoning by introducing explicit, step-by-step grounding mechanisms. By decomposing complex 3D reasoning into manageable stages with concrete grounding signals, the framework ensures that answers are not just plausible but truly grounded in scene reality, enabling more reliable and interpretable embodied AI.
             </div>
             <div class="lang-zh" style="display:none; color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºSceneCOTé€šè¿‡å¼•å…¥æ˜¾å¼çš„ã€é€æ­¥çš„æ¥åœ°æœºåˆ¶æ¥è§£å†³å¤šæ¨¡æ€åœºæ™¯ç†è§£ä¸è¿è´¯æ¨ç†ä¹‹é—´çš„åŸºæœ¬è„±èŠ‚ã€‚é€šè¿‡å°†å¤æ‚çš„3Dæ¨ç†åˆ†è§£ä¸ºå…·æœ‰å…·ä½“æ¥åœ°ä¿¡å·çš„å¯ç®¡ç†é˜¶æ®µï¼Œè¯¥æ¡†æ¶ç¡®ä¿ç­”æ¡ˆä¸ä»…ä»…æ˜¯çœ‹ä¼¼åˆç†çš„ï¼Œè€Œæ˜¯çœŸæ­£åŸºäºåœºæ™¯ç°å®ï¼Œä»è€Œå®ç°æ›´å¯é å’Œæ˜“è§£é‡Šçš„å…·èº«AIã€‚
             </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            This paper introduces SceneCOT, a groundbreaking framework for eliciting grounded Chain-of-Thought reasoning in 3D scenes. By decomposing complex 3D reasoning tasks into four hierarchical stagesâ€”task recognition, region localization, entity grounding, and grounded reasoningâ€”SceneCOT enables step-by-step, human-like scene understanding that was previously unattainable. The construction of SceneCOT-185K, the first large-scale grounded CoT dataset with 185K high-quality instances, provides comprehensive training data for this paradigm. Through extensive experiments on MSQA and Beacon3D benchmarks, SceneCOT demonstrates superior performance with exceptional grounding-QA coherence (34.7 GC score), significantly outperforming baseline methods. This work represents the first successful application of CoT reasoning to 3D scene understanding, paving the way for more interpretable and reliable embodied AI systems.
          </div>
          <div class="lang-zh" style="display:none">
            æœ¬æ–‡ä»‹ç»äº†SceneCOTï¼Œä¸€ä¸ªå¼€åˆ›æ€§çš„æ¡†æ¶ï¼Œç”¨äºåœ¨3Dåœºæ™¯ä¸­å¼•å‘åŸºäºåœºæ™¯çš„Chain-of-Thoughtæ¨ç†ã€‚é€šè¿‡å°†å¤æ‚çš„3Dæ¨ç†ä»»åŠ¡åˆ†è§£ä¸ºå››ä¸ªå±‚æ¬¡é˜¶æ®µâ€”â€”ä»»åŠ¡è¯†åˆ«ã€åŒºåŸŸå®šä½ã€å®ä½“æ¥åœ°å’ŒåŸºäºåœºæ™¯çš„æ¨ç†â€”â€”SceneCOTå®ç°äº†ä»¥å‰æ— æ³•å®ç°çš„é€æ­¥ã€ç±»ä¼¼äººç±»çš„åœºæ™¯ç†è§£ã€‚SceneCOT-185Kçš„æ„å»ºæ˜¯é¦–ä¸ªå¤§è§„æ¨¡åŸºäºåœºæ™¯çš„CoTæ•°æ®é›†ï¼ŒåŒ…å«185Ké«˜è´¨é‡å®ä¾‹ï¼Œä¸ºè¿™ä¸€èŒƒå¼æä¾›äº†å…¨é¢çš„è®­ç»ƒæ•°æ®ã€‚é€šè¿‡åœ¨MSQAå’ŒBeacon3DåŸºå‡†ä¸Šçš„å¹¿æ³›å®éªŒï¼ŒSceneCOTå±•ç¤ºäº†å“è¶Šçš„æ€§èƒ½ï¼Œå…·æœ‰ exceptional çš„æ¥åœ°-QAè¿è´¯æ€§ï¼ˆ34.7 GCåˆ†æ•°ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚è¿™é¡¹å·¥ä½œä»£è¡¨äº†CoTæ¨ç†é¦–æ¬¡æˆåŠŸåº”ç”¨äº3Dåœºæ™¯ç†è§£ï¼Œä¸ºæ›´æ˜“è§£é‡Šå’Œå¯é çš„å…·èº«AIç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Code:</h2>
        <a href="https://scenecot.github.io/" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          Project Page
        </a>
      </div>
    </div>
</section>
</body>
</html>
