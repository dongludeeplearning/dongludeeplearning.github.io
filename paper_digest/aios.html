<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  // ç›´æ¥æ‰“å¼€PDFæ–‡ä»¶
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ CVPR 2024
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">AiOS: All-in-One-Stage Expressive Human Pose and Shape Estimation</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Qingping Sun, Yanjun Wang, Ailing Zeng, Wanqi Yin, Chen Wei, Wenjia Wang, Haiyi Mei, Chi-Sing Leung, Ziwei Liu, Lei Yang, Zhongang Cai<br>
        <span style="opacity:0.8">SenseTime Research, City University of Hong Kong, IDEA, Nanyang Technological University, Shanghai AI Laboratory</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to develop an end-to-end framework for expressive human pose and shape estimation that eliminates the need for multi-stage processing and bounding box detection, while maintaining high accuracy in crowded scenes and handling complex interactions between body parts and multiple people?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•å¼€å‘ä¸€ä¸ªç«¯åˆ°ç«¯çš„è¡¨è¾¾æ€§äººç±»å§¿åŠ¿å’Œå½¢çŠ¶ä¼°è®¡æ¡†æ¶ï¼Œæ¶ˆé™¤å¤šé˜¶æ®µå¤„ç†å’Œè¾¹ç•Œæ¡†æ£€æµ‹çš„éœ€æ±‚ï¼ŒåŒæ—¶åœ¨æ‹¥æŒ¤åœºæ™¯ä¸­ä¿æŒé«˜å‡†ç¡®æ€§å¹¶å¤„ç†èº«ä½“éƒ¨ä½ä¹‹é—´ä»¥åŠå¤šäººä¹‹é—´çš„å¤æ‚äº¤äº’ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>All-in-One-Stage Framework:</b> Introduced AiOS, the first end-to-end framework for expressive human pose and shape estimation that eliminates multi-stage processing and bounding box detection requirements, enabling direct prediction from full-frame images.</div>
            <div class="lang-zh" style="display:none"><b>å…¨ä¸€ä½“é˜¶æ®µæ¡†æ¶ï¼š</b>å¼•å…¥äº†AiOSï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºè¡¨è¾¾æ€§äººç±»å§¿åŠ¿å’Œå½¢çŠ¶ä¼°è®¡çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œæ¶ˆé™¤äº†å¤šé˜¶æ®µå¤„ç†å’Œè¾¹ç•Œæ¡†æ£€æµ‹éœ€æ±‚ï¼Œå®ç°ä»å®Œæ•´å¸§å›¾åƒçš„ç›´æ¥é¢„æµ‹ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Human-as-Tokens Design:</b> Pioneered a novel approach conceptualizing humans as collections of box tokens and joint tokens within a DETR-based architecture, enabling progressive set prediction for multi-person whole-body mesh recovery.</div>
            <div class="lang-zh" style="display:none"><b>Human-as-Tokensè®¾è®¡ï¼š</b>å¼€åˆ›äº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œåœ¨åŸºäºDETRçš„æ¶æ„ä¸­å°†äººç±»æ¦‚å¿µåŒ–ä¸ºæ¡†ä»¤ç‰Œå’Œå…³èŠ‚ä»¤ç‰Œçš„é›†åˆï¼Œå®ç°å¤šäººæ•´ä½“èº«ä½“ç½‘æ ¼æ¢å¤çš„æ¸è¿›é›†åˆé¢„æµ‹ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multi-Level Feature Integration:</b> Developed a hierarchical decoder structure that combines global and local feature representations through location-aware queries and cross-attention mechanisms, enabling accurate regression in crowded and occlusion-heavy environments.</div>
            <div class="lang-zh" style="display:none"><b>å¤šçº§ç‰¹å¾é›†æˆï¼š</b>å¼€å‘äº†åˆ†å±‚è§£ç å™¨ç»“æ„ï¼Œé€šè¿‡ä½ç½®æ„ŸçŸ¥æŸ¥è¯¢å’Œäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ç»“åˆå…¨å±€å’Œå±€éƒ¨ç‰¹å¾è¡¨ç¤ºï¼Œå®ç°æ‹¥æŒ¤å’Œé®æŒ¡ä¸¥é‡ç¯å¢ƒä¸­çš„å‡†ç¡®å›å½’ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>State-of-the-Art Performance:</b> Achieved superior results with 9% NMVE reduction on AGORA, 30% PVE reduction on EHF, 10% PVE reduction on ARCTIC, and 3% PVE reduction on EgoBody, demonstrating robust performance in diverse scenarios.</div>
            <div class="lang-zh" style="display:none"><b>æœ€å…ˆè¿›æ€§èƒ½ï¼š</b>å®ç°äº†å“è¶Šç»“æœï¼Œåœ¨AGORAä¸ŠNMVEé™ä½9%ï¼Œåœ¨EHFä¸ŠPVEé™ä½30%ï¼Œåœ¨ARCTICä¸ŠPVEé™ä½10%ï¼Œåœ¨EgoBodyä¸ŠPVEé™ä½3%ï¼Œå±•ç¤ºäº†åœ¨ä¸åŒåœºæ™¯ä¸­çš„å¼ºå¤§æ€§èƒ½ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆå¼•è¨€ç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/aios_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('aios_cvpr2024.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('aios_cvpr2024.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/aios_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('aios_cvpr2024.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('aios_cvpr2024.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multi-Stage Processing Complexity:</b> Traditional approaches require separate detection, cropping, and individual body part regression stages, leading to increased computational costs, inconsistent poses at joint connections, and blocking of inter-part and inter-human associations.</div>
            <div class="lang-zh" style="display:none"><b>å¤šé˜¶æ®µå¤„ç†å¤æ‚æ€§ï¼š</b>ä¼ ç»Ÿæ–¹æ³•éœ€è¦å•ç‹¬çš„æ£€æµ‹ã€è£å‰ªå’Œå„ä¸ªèº«ä½“éƒ¨ä½å›å½’é˜¶æ®µï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬å¢åŠ ã€å…³èŠ‚è¿æ¥å¤„å§¿åŠ¿ä¸ä¸€è‡´ä»¥åŠé˜»ç¢éƒ¨ä»¶é—´å’Œäººé™…å…³è”ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Contextual Information Loss:</b> Cropping operations discard valuable global contextual information including inter-person relationships, scene layout, and location cues, significantly degrading performance especially in crowded scenes with occlusions.</div>
            <div class="lang-zh" style="display:none"><b>ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸¢å¤±ï¼š</b>è£å‰ªæ“ä½œä¸¢å¼ƒäº†æœ‰ä»·å€¼çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒ…æ‹¬äººé™…å…³ç³»ã€åœºæ™¯å¸ƒå±€å’Œä½ç½®çº¿ç´¢ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰é®æŒ¡çš„æ‹¥æŒ¤åœºæ™¯ä¸­æ˜¾è‘—é™ä½æ€§èƒ½ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Bounding Box Dependency:</b> Reliance on external detectors or ground-truth bounding boxes creates practical limitations, as accurate boxes are unavailable in real-world scenarios and noisy boxes cause significant performance degradation.</div>
            <div class="lang-zh" style="display:none"><b>è¾¹ç•Œæ¡†ä¾èµ–æ€§ï¼š</b>ä¾èµ–å¤–éƒ¨æ£€æµ‹å™¨æˆ–åœ°é¢çœŸå®è¾¹ç•Œæ¡†ä¼šäº§ç”Ÿå®é™…é™åˆ¶ï¼Œå› ä¸ºå‡†ç¡®çš„æ¡†åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­ä¸å¯ç”¨ï¼Œè€Œæœ‰å™ªå£°çš„æ¡†ä¼šå¯¼è‡´æ˜¾è‘—çš„æ€§èƒ½ä¸‹é™ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Unified Feature Representation:</b> Existing one-stage methods for human pose estimation lack effective mechanisms to integrate global scene understanding with local part-wise features, making them insufficient for expressive whole-body mesh recovery requiring fine-grained details.</div>
            <div class="lang-zh" style="display:none"><b>ç»Ÿä¸€ç‰¹å¾è¡¨ç¤ºï¼š</b>ç°æœ‰çš„äººä½“å§¿åŠ¿ä¼°è®¡å•é˜¶æ®µæ–¹æ³•ç¼ºä¹å°†å…¨å±€åœºæ™¯ç†è§£ä¸å±€éƒ¨éƒ¨ä»¶ç‰¹å¾é›†æˆçš„æœ‰æ•ˆæœºåˆ¶ï¼Œä½¿å®ƒä»¬ä¸è¶³ä»¥è¿›è¡Œéœ€è¦ç»†ç²’åº¦ç»†èŠ‚çš„è¡¨è¾¾æ€§æ•´ä½“èº«ä½“ç½‘æ ¼æ¢å¤ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multi-Person Interaction Handling:</b> Complex scenarios with multiple overlapping people require sophisticated attention mechanisms to establish correct associations between body parts and individuals, which traditional approaches struggle to maintain.</div>
            <div class="lang-zh" style="display:none"><b>å¤šäººäº¤äº’å¤„ç†ï¼š</b>å…·æœ‰å¤šä¸ªé‡å äººå‘˜çš„å¤æ‚åœºæ™¯éœ€è¦å¤æ‚çš„æ³¨æ„åŠ›æœºåˆ¶æ¥å»ºç«‹èº«ä½“éƒ¨ä½å’Œä¸ªäººä¹‹é—´çš„æ­£ç¡®å…³è”ï¼Œè€Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥ç»´æŒè¿™ä¸€ç‚¹ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>DETR-Based Progressive Set Prediction:</b> Extended DETR architecture to treat multi-person whole-body mesh recovery as a progressive set prediction problem, enabling end-to-end detection and regression without external bounding boxes.</div>
            <div class="lang-zh" style="display:none"><b>åŸºäºDETRçš„æ¸è¿›é›†åˆé¢„æµ‹ï¼š</b>å°†DETRæ¶æ„æ‰©å±•åˆ°å°†å¤šäººæ•´ä½“èº«ä½“ç½‘æ ¼æ¢å¤è§†ä¸ºæ¸è¿›é›†åˆé¢„æµ‹é—®é¢˜ï¼Œå®ç°æ— éœ€å¤–éƒ¨è¾¹ç•Œæ¡†çš„ç«¯åˆ°ç«¯æ£€æµ‹å’Œå›å½’ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Human-as-Tokens Paradigm:</b> Conceptualized humans as collections of box tokens and joint tokens that aggregate both global and local features through cross-attention mechanisms, enabling robust handling of complex multi-person scenarios.</div>
            <div class="lang-zh" style="display:none"><b>Human-as-TokensèŒƒå¼ï¼š</b>å°†äººç±»æ¦‚å¿µåŒ–ä¸ºæ¡†ä»¤ç‰Œå’Œå…³èŠ‚ä»¤ç‰Œçš„é›†åˆï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶èšåˆå…¨å±€å’Œå±€éƒ¨ç‰¹å¾ï¼Œå®ç°å¯¹å¤æ‚å¤šäººåœºæ™¯çš„é²æ£’å¤„ç†ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Hierarchical Decoder Structure:</b> Implemented three-stage progressive decoding: body localization, body refinement with joint tokens, and whole-body refinement, allowing the model to first establish person identities then refine detailed pose and shape parameters.</div>
            <div class="lang-zh" style="display:none"><b>åˆ†å±‚è§£ç å™¨ç»“æ„ï¼š</b>å®ç°äº†ä¸‰é˜¶æ®µæ¸è¿›è§£ç ï¼šèº«ä½“å®šä½ã€å¸¦å…³èŠ‚ä»¤ç‰Œçš„èº«ä½“ç»†åŒ–å’Œæ•´ä½“èº«ä½“ç»†åŒ–ï¼Œå…è®¸æ¨¡å‹é¦–å…ˆå»ºç«‹äººå‘˜èº«ä»½ç„¶åç»†åŒ–è¯¦ç»†çš„å§¿åŠ¿å’Œå½¢çŠ¶å‚æ•°ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Location-Aware Feature Aggregation:</b> Used position queries and deformable attention to probe relevant features from full-frame images, enabling precise localization and feature extraction without cropping operations that lose contextual information.</div>
            <div class="lang-zh" style="display:none"><b>ä½ç½®æ„ŸçŸ¥ç‰¹å¾èšåˆï¼š</b>ä½¿ç”¨ä½ç½®æŸ¥è¯¢å’Œå¯å˜å½¢æ³¨æ„åŠ›ä»å®Œæ•´å¸§å›¾åƒä¸­æ¢æµ‹ç›¸å…³ç‰¹å¾ï¼Œå®ç°æ— éœ€è£å‰ªæ“ä½œï¼ˆä¼šä¸¢å¤±ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼‰çš„ç²¾ç¡®å®šä½å’Œç‰¹å¾æå–ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Inter-Part and Inter-Person Attention:</b> Employed self-attention and cross-attention with specialized masks to establish relationships between different body parts within individuals and between multiple people in crowded scenes.</div>
            <div class="lang-zh" style="display:none"><b>éƒ¨ä»¶é—´å’Œäººé™…æ³¨æ„åŠ›ï¼š</b>ä½¿ç”¨è‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›ä»¥åŠä¸“ç”¨æ©ç æ¥å»ºç«‹ä¸ªäººå†…éƒ¨ä¸åŒèº«ä½“éƒ¨ä½ä¹‹é—´ä»¥åŠæ‹¥æŒ¤åœºæ™¯ä¸­å¤šäººä¹‹é—´çš„å…³ç³»ã€‚</div>
          </li>
        </ol>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>End-to-End Paradigm Shift:</b> AiOS represents a fundamental shift from multi-stage pipelines to truly end-to-end processing, eliminating the dependency on external detectors and enabling direct processing of full-frame images with preserved contextual information.
            </div>
            <div class="lang-zh" style="display:none">
                <b>ç«¯åˆ°ç«¯èŒƒå¼è½¬å˜ï¼š</b>AiOSä»£è¡¨äº†ä»å¤šé˜¶æ®µç®¡é“åˆ°çœŸæ­£ç«¯åˆ°ç«¯å¤„ç†çš„æ ¹æœ¬è½¬å˜ï¼Œæ¶ˆé™¤äº†å¯¹å¤–éƒ¨æ£€æµ‹å™¨çš„ä¾èµ–ï¼Œå¹¶å®ç°äº†å¯¹ä¿ç•™ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å®Œæ•´å¸§å›¾åƒçš„ç›´æ¥å¤„ç†ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Unified Feature Representation:</b> The Human-as-Tokens approach provides a coherent framework for integrating global scene understanding with local part-wise features, enabling more accurate and robust expressive human pose and shape estimation.
            </div>
            <div class="lang-zh" style="display:none">
                <b>ç»Ÿä¸€ç‰¹å¾è¡¨ç¤ºï¼š</b>Human-as-Tokensæ–¹æ³•ä¸ºå°†å…¨å±€åœºæ™¯ç†è§£ä¸å±€éƒ¨éƒ¨ä»¶ç‰¹å¾é›†æˆæä¾›äº†è¿è´¯æ¡†æ¶ï¼Œå®ç°æ›´å‡†ç¡®å’Œé²æ£’çš„è¡¨è¾¾æ€§äººç±»å§¿åŠ¿å’Œå½¢çŠ¶ä¼°è®¡ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Attention-Based Relationship Modeling:</b> By leveraging transformer attention mechanisms to model inter-part and inter-person relationships, AiOS can effectively handle complex scenarios that were previously challenging for traditional approaches.
            </div>
            <div class="lang-zh" style="display:none">
                <b>åŸºäºæ³¨æ„åŠ›çš„å…³ç³»å»ºæ¨¡ï¼š</b>é€šè¿‡åˆ©ç”¨å˜æ¢å™¨æ³¨æ„åŠ›æœºåˆ¶æ¥å»ºæ¨¡éƒ¨ä»¶é—´å’Œäººé™…å…³ç³»ï¼ŒAiOSå¯ä»¥æœ‰æ•ˆåœ°å¤„ç†ä¼ ç»Ÿæ–¹æ³•ä»¥å‰å…·æœ‰æŒ‘æˆ˜æ€§çš„å¤æ‚åœºæ™¯ã€‚
            </div>
          </li>
        </ul>

        <div style="margin-top:16px; padding-top:12px; border-top:1px dashed rgba(255,255,255,.15);">
             <h3 style="margin:0 0 6px; font-size:14px; color:#8bffcf;">
               <span class="lang-en">High-Level Insights: Why it Works?</span>
               <span class="lang-zh" style="display:none">é«˜å±‚æ´å¯Ÿï¼šä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ</span>
             </h3>
             <div class="lang-en" style="color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                It works because AiOS addresses the core limitations of multi-stage approaches by enabling direct processing of full-frame images with preserved contextual information. The progressive token-based architecture allows for sophisticated relationship modeling between body parts and individuals, while the unified framework eliminates the artifacts and inconsistencies introduced by separate processing stages.
             </div>
             <div class="lang-zh" style="display:none; color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºAiOSé€šè¿‡å®ç°å¯¹ä¿ç•™ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å®Œæ•´å¸§å›¾åƒçš„ç›´æ¥å¤„ç†æ¥è§£å†³å¤šé˜¶æ®µæ–¹æ³•çš„æ ¸å¿ƒé™åˆ¶ã€‚æ¸è¿›ä»¤ç‰ŒåŸºç¡€æ¶æ„å…è®¸å¯¹èº«ä½“éƒ¨ä½å’Œä¸ªäººä¹‹é—´çš„å¤æ‚å…³ç³»å»ºæ¨¡ï¼Œè€Œç»Ÿä¸€æ¡†æ¶æ¶ˆé™¤äº†ç”±å•ç‹¬å¤„ç†é˜¶æ®µå¼•å…¥çš„ä¼ªå½±å’Œä¸ä¸€è‡´æ€§ã€‚
             </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            This paper introduces AiOS, the first all-in-one-stage framework for expressive human pose and shape estimation that eliminates the need for multi-stage processing and external detection. Built upon DETR with a novel Human-as-Tokens design, AiOS treats multi-person whole-body mesh recovery as a progressive set prediction problem, enabling direct regression from full-frame images. The framework combines global scene understanding with local part-wise features through sophisticated attention mechanisms, achieving superior performance with 9% NMVE reduction on AGORA, 30% PVE reduction on EHF, 10% PVE reduction on ARCTIC, and 3% PVE reduction on EgoBody. By preserving contextual information and establishing proper inter-part and inter-person relationships, AiOS demonstrates robust performance in crowded scenes and sets a new standard for end-to-end expressive human pose and shape estimation.
          </div>
          <div class="lang-zh" style="display:none">
            æœ¬æ–‡ä»‹ç»äº†AiOSï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºè¡¨è¾¾æ€§äººç±»å§¿åŠ¿å’Œå½¢çŠ¶ä¼°è®¡çš„å…¨ä¸€ä½“é˜¶æ®µæ¡†æ¶ï¼Œæ¶ˆé™¤äº†å¤šé˜¶æ®µå¤„ç†å’Œå¤–éƒ¨æ£€æµ‹çš„éœ€æ±‚ã€‚ä»¥DETRä¸ºåŸºç¡€å¹¶é‡‡ç”¨æ–°é¢–çš„Human-as-Tokensè®¾è®¡ï¼ŒAiOSå°†å¤šäººæ•´ä½“èº«ä½“ç½‘æ ¼æ¢å¤è§†ä¸ºæ¸è¿›é›†åˆé¢„æµ‹é—®é¢˜ï¼Œå®ç°ä»å®Œæ•´å¸§å›¾åƒçš„ç›´æ¥å›å½’ã€‚è¯¥æ¡†æ¶é€šè¿‡å¤æ‚çš„æ³¨æ„åŠ›æœºåˆ¶å°†å…¨å±€åœºæ™¯ç†è§£ä¸å±€éƒ¨éƒ¨ä»¶ç‰¹å¾ç›¸ç»“åˆï¼Œåœ¨AGORAä¸Šå®ç°NMVEé™ä½9%ï¼Œåœ¨EHFä¸ŠPVEé™ä½30%ï¼Œåœ¨ARCTICä¸ŠPVEé™ä½10%ï¼Œåœ¨EgoBodyä¸ŠPVEé™ä½3%ã€‚é€šè¿‡ä¿ç•™ä¸Šä¸‹æ–‡ä¿¡æ¯å¹¶å»ºç«‹é€‚å½“çš„éƒ¨ä»¶é—´å’Œäººé™…å…³ç³»ï¼ŒAiOSåœ¨æ‹¥æŒ¤åœºæ™¯ä¸­å±•ç¤ºäº†é²æ£’æ€§èƒ½ï¼Œå¹¶ä¸ºç«¯åˆ°ç«¯è¡¨è¾¾æ€§äººç±»å§¿åŠ¿å’Œå½¢çŠ¶ä¼°è®¡è®¾å®šäº†æ–°æ ‡å‡†ã€‚
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Links:</h2>
        <a href="https://ttxskk.github.io/AiOS/" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          Project Page
        </a>
      </div>
    </div>
</section>
</body>
</html>
