<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ ACL SpLU-RoboNLP 2024
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">Language-Guided World Models
        A Model-Based Approach to AI Control</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Alex Zhang, Khanh Nguyen, Jens Tuyls, Albert Lin, Karthik Narasimhan<br>
        <span style="opacity:0.8">Princeton University, UC Berkeley, USC</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How can we build world models that can be effectively controlled and adapted through natural language descriptions, enabling safer and more transparent AI agents that can plan and revise behaviors based on human verbal feedback?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•æ„å»ºèƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æè¿°è¿›è¡Œæœ‰æ•ˆæ§åˆ¶å’Œé€‚åº”çš„ä¸–ç•Œæ¨¡å‹ï¼Œå®ç°æ›´å®‰å…¨ã€æ›´é€æ˜çš„AIä»£ç†ï¼Œèƒ½å¤ŸåŸºäºäººç±»çš„è¯­è¨€åé¦ˆæ¥è§„åˆ’å’Œä¿®æ”¹è¡Œä¸ºï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Language-Guided World Models:</b> Introduced LWMs, a new class of world models that can be controlled through natural language descriptions, enabling more efficient and human-friendly adaptation of agent behaviors.</div>
            <div class="lang-zh" style="display:none"><b>è¯­è¨€å¼•å¯¼ä¸–ç•Œæ¨¡å‹ï¼š</b>å¼•å…¥äº†LWMsï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„ä¸–ç•Œæ¨¡å‹ç±»åˆ«ï¼Œèƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æè¿°è¿›è¡Œæ§åˆ¶ï¼Œå®ç°æ›´é«˜æ•ˆå’Œäººæ€§åŒ–çš„ä»£ç†è¡Œä¸ºé€‚åº”ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>MESSENGER Benchmark:</b> Developed a challenging benchmark based on the MESSENGER game with three levels of compositional generalization difficulty, testing the ability to simulate environments with novel combinations of entity attributes.</div>
            <div class="lang-zh" style="display:none"><b>MESSENGERåŸºå‡†ï¼š</b>åŸºäºMESSENGERæ¸¸æˆå¼€å‘äº†ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†ï¼Œå…·æœ‰ä¸‰ä¸ªçº§åˆ«çš„ç»„åˆæ³›åŒ–éš¾åº¦ï¼Œæµ‹è¯•æ¨¡æ‹Ÿå…·æœ‰å®ä½“å±æ€§æ–°ç»„åˆçš„ç¯å¢ƒçš„èƒ½åŠ›ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>EMMA Attention Mechanism:</b> Proposed EMMA-LWM, a model that fuses the EMMA attention mechanism with Transformers to effectively ground language descriptions to environmental dynamics, achieving strong compositional generalization.</div>
            <div class="lang-zh" style="display:none"><b>EMMAæ³¨æ„åŠ›æœºåˆ¶ï¼š</b>æå‡ºäº†EMMA-LWMæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†EMMAæ³¨æ„åŠ›æœºåˆ¶ä¸Transformerèåˆï¼Œä»¥æœ‰æ•ˆå°†è¯­è¨€æè¿° grounding åˆ°ç¯å¢ƒåŠ¨æ€ï¼Œå®ç°å¼ºå¤§çš„ç»„åˆæ³›åŒ–ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Plan Discussion Framework:</b> Demonstrated a practical application where LWMs enable agents to generate visual plans for human review and revision, improving AI safety and transparency through language-guided policy adaptation.</div>
            <div class="lang-zh" style="display:none"><b>è®¡åˆ’è®¨è®ºæ¡†æ¶ï¼š</b>å±•ç¤ºäº†å®é™…åº”ç”¨ï¼Œå…¶ä¸­LWMsä½¿ä»£ç†èƒ½å¤Ÿç”Ÿæˆå¯è§†åŒ–è®¡åˆ’ä¾›äººç±»å®¡æŸ¥å’Œä¿®æ”¹ï¼Œé€šè¿‡è¯­è¨€å¼•å¯¼çš„ç­–ç•¥é€‚åº”æ¥æé«˜AIå®‰å…¨æ€§å’Œé€æ˜åº¦ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Language Grounding to Dynamics:</b> Bridging the gap between rich, complex natural language descriptions and environmental transition functions requires sophisticated grounding mechanisms that can handle abstract concepts like entity identities, roles, and behaviors.</div>
            <div class="lang-zh" style="display:none"><b>è¯­è¨€åˆ°åŠ¨æ€çš„groundingï¼š</b>å¼¥åˆä¸°å¯Œã€å¤æ‚çš„è‡ªç„¶è¯­è¨€æè¿°ä¸ç¯å¢ƒè½¬ç§»å‡½æ•°ä¹‹é—´çš„å·®è·éœ€è¦å¤æ‚çš„groundingæœºåˆ¶ï¼Œèƒ½å¤Ÿå¤„ç†å®ä½“èº«ä»½ã€è§’è‰²å’Œè¡Œä¸ºç­‰æŠ½è±¡æ¦‚å¿µã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Compositional Generalization:</b> Building models that can generalize to compositionally novel combinations of seen concepts (e.g., "fleeing mage" when only "chasing mage" was seen in training) requires overcoming limitations of standard Transformer architectures.</div>
            <div class="lang-zh" style="display:none"><b>ç»„åˆæ³›åŒ–ï¼š</b>æ„å»ºèƒ½å¤Ÿæ³›åŒ–åˆ°æ‰€è§æ¦‚å¿µç»„åˆæ–°é¢–ç»„åˆçš„æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œå½“è®­ç»ƒä¸­åªè§è¿‡"chasing mage"æ—¶æ³›åŒ–åˆ°"fleeing mage"ï¼‰éœ€è¦å…‹æœæ ‡å‡†Transformeræ¶æ„çš„å±€é™æ€§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Model Interpretability:</b> Ensuring that language-guided adaptations lead to interpretable and predictable agent behaviors, avoiding unintended consequences when humans provide ambiguous or incomplete descriptions.</div>
            <div class="lang-zh" style="display:none"><b>æ¨¡å‹å¯è§£é‡Šæ€§ï¼š</b>ç¡®ä¿è¯­è¨€å¼•å¯¼çš„é€‚åº”å¯¼è‡´å¯è§£é‡Šå’Œå¯é¢„æµ‹çš„ä»£ç†è¡Œä¸ºï¼Œé¿å…å½“äººç±»æä¾›æ¨¡ç³Šæˆ–ä¸å®Œæ•´çš„æè¿°æ—¶äº§ç”Ÿæ„å¤–åæœã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Human-Agent Communication:</b> Developing effective protocols for agents to present plans to humans, receive feedback, and incorporate language-based corrections without requiring extensive interactive experience collection.</div>
            <div class="lang-zh" style="display:none"><b>äººæœºé€šä¿¡ï¼š</b>å¼€å‘æœ‰æ•ˆåè®®ï¼Œä½¿ä»£ç†èƒ½å¤Ÿå‘äººç±»å±•ç¤ºè®¡åˆ’ã€æ¥æ”¶åé¦ˆï¼Œå¹¶çº³å…¥åŸºäºè¯­è¨€çš„ä¿®æ­£ï¼Œè€Œæ— éœ€æ”¶é›†å¤§é‡çš„äº¤äº’ç»éªŒã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <div style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>LWMs extend traditional world models by incorporating language descriptions to guide environment simulation:</p>
            <ol style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>Language-Conditioned Environments:</b> Define environments E(v) parameterized by vectors v, where each parameter corresponds to attributes of entities, accompanied by natural language manuals â„“ describing these parameters.</li>
                <li style="margin-bottom:6px;"><b>MESSENGER Benchmark:</b> Create a grid-world game environment with entities having identities, roles, and movement patterns, testing three levels of compositional generalization difficulty (NewCombo, NewAttr, NewAll).</li>
                <li style="margin-bottom:6px;"><b>EMMA Attention Mechanism:</b> Implement a two-step reasoning process that first identifies entity identities in descriptions, then extracts relevant attribute words, fusing this with Transformer cross-attention for robust language grounding.</li>
                <li style="margin-bottom:6px;"><b>Plan Discussion Protocol:</b> Enable agents to generate execution trajectories, present them visually to humans, and incorporate language feedback to revise world models and policies without additional environment interactions.</li>
                <li style="margin-bottom:6px;"><b>Evaluation Framework:</b> Assess models on ground-truth trajectory prediction and imaginary trajectory generation, measuring both simulation accuracy and ability to generalize to compositionally novel scenarios.</li>
            </ol>
          </div>
          <div class="lang-zh" style="display: none;">
            <p>LWMsé€šè¿‡çº³å…¥è¯­è¨€æè¿°æ¥æŒ‡å¯¼ç¯å¢ƒæ¨¡æ‹Ÿï¼Œä»è€Œæ‰©å±•ä¼ ç»Ÿä¸–ç•Œæ¨¡å‹ï¼š</p>
            <ol style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>è¯­è¨€æ¡ä»¶ç¯å¢ƒï¼š</b>å®šä¹‰ç”±å‘é‡vå‚æ•°åŒ–çš„ç¯å¢ƒE(v)ï¼Œå…¶ä¸­æ¯ä¸ªå‚æ•°å¯¹åº”å®ä½“çš„å±æ€§ï¼Œå¹¶é™„å¸¦æè¿°è¿™äº›å‚æ•°çš„è‡ªç„¶è¯­è¨€æ‰‹å†Œâ„“ã€‚</li>
                <li style="margin-bottom:6px;"><b>MESSENGERåŸºå‡†ï¼š</b>åˆ›å»ºä¸€ä¸ªå…·æœ‰å®ä½“èº«ä»½ã€è§’è‰²å’Œç§»åŠ¨æ¨¡å¼çš„ç½‘æ ¼ä¸–ç•Œæ¸¸æˆç¯å¢ƒï¼Œæµ‹è¯•ä¸‰ä¸ªçº§åˆ«çš„ç»„åˆæ³›åŒ–éš¾åº¦ï¼ˆNewComboã€NewAttrã€NewAllï¼‰ã€‚</li>
                <li style="margin-bottom:6px;"><b>EMMAæ³¨æ„åŠ›æœºåˆ¶ï¼š</b>å®ç°ä¸¤æ­¥æ¨ç†è¿‡ç¨‹ï¼Œé¦–å…ˆè¯†åˆ«æè¿°ä¸­çš„å®ä½“èº«ä»½ï¼Œç„¶åæå–ç›¸å…³çš„å±æ€§è¯ï¼Œå°†æ­¤ä¸Transformeräº¤å‰æ³¨æ„åŠ›èåˆä»¥å®ç°å¼ºå¤§çš„è¯­è¨€groundingã€‚</li>
                <li style="margin-bottom:6px;"><b>è®¡åˆ’è®¨è®ºåè®®ï¼š</b>ä½¿ä»£ç†èƒ½å¤Ÿç”Ÿæˆæ‰§è¡Œè½¨è¿¹ï¼Œå°†å…¶å¯è§†åŒ–å‘ˆç°ç»™äººç±»ï¼Œå¹¶çº³å…¥è¯­è¨€åé¦ˆæ¥ä¿®æ”¹ä¸–ç•Œæ¨¡å‹å’Œç­–ç•¥ï¼Œè€Œæ— éœ€é¢å¤–çš„ç¯å¢ƒäº¤äº’ã€‚</li>
                <li style="margin-bottom:6px;"><b>è¯„ä¼°æ¡†æ¶ï¼š</b>è¯„ä¼°æ¨¡å‹åœ¨ground-truthè½¨è¿¹é¢„æµ‹å’Œè™šæ„è½¨è¿¹ç”Ÿæˆä¸Šçš„è¡¨ç°ï¼Œæµ‹é‡æ¨¡æ‹Ÿå‡†ç¡®æ€§å’Œæ³›åŒ–åˆ°ç»„åˆæ–°é¢–åœºæ™¯çš„èƒ½åŠ›ã€‚</li>
            </ol>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆå¼•è¨€å›¾ï¼‰</h2>
        <div style="border-radius:14px; overflow:hidden;">
            <img src="Figures/splurobonlp_2024_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px solid rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/splurobonlp_2024_overview00.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />
            <div style="height:1px; background:rgba(255,255,255,.10); margin:12px 0;"></div>
            <img src="Figures/splurobonlp_2024_overview01.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />
           
            <p>EMMA-LWM architecture fuses EMMA attention with Transformers for robust compositional generalization in language-guided world modeling.</p>
            <p>Note: The model achieves superior performance on MESSENGER benchmark, enabling agents to plan with humans and revise behaviors through natural language feedback, improving AI safety and transparency.</p>

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('acl_splurobonlp_2024.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('acl_splurobonlp_2024.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <h3 style="margin:12px 0 6px;font-size:14px;color:#8bffcf;">Why it Works?</h3>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>Language-Guided World Models succeed by bridging human language with machine learning through careful architectural design:</p>
            <ul style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>EMMA Reasoning Process:</b> The two-step attention mechanism mimics human-like reasoning by first identifying entities, then extracting their attributes, enabling more robust language grounding than standard cross-attention.</li>
                <li style="margin-bottom:6px;"><b>Compositional Structure:</b> By modeling environments as collections of independent yet interacting entities with orthogonal attributes, the framework can generalize to novel combinations not seen during training.</li>
                <li style="margin-bottom:6px;"><b>Human-in-the-Loop Planning:</b> The plan discussion protocol allows agents to leverage human expertise through natural language, reducing the need for extensive trial-and-error learning in the real world.</li>
                <li style="margin-bottom:6px;"><b>Modular Control:</b> Separating world model adaptation from policy optimization enables more efficient and targeted updates, where language feedback can directly modify environmental understanding.</li>
                <li style="margin-bottom:6px;"><b>Safety through Transparency:</b> By requiring agents to present plans visually and accept language-based revisions, the framework promotes safer AI deployment through increased human oversight and control.</li>
            </ul>
          </div>
          <div class="lang-zh" style="display:none">
            <p>è¯­è¨€å¼•å¯¼ä¸–ç•Œæ¨¡å‹é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æ¶æ„å°†äººç±»è¯­è¨€ä¸æœºå™¨å­¦ä¹ ç›¸ç»“åˆè€ŒæˆåŠŸï¼š</p>
            <ul style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>EMMAæ¨ç†è¿‡ç¨‹ï¼š</b>ä¸¤æ­¥æ³¨æ„åŠ›æœºåˆ¶æ¨¡ä»¿äººç±»æ¨ç†ï¼Œé¦–å…ˆè¯†åˆ«å®ä½“ï¼Œç„¶åæå–å®ƒä»¬çš„å±æ€§ï¼Œå®ç°æ¯”æ ‡å‡†äº¤å‰æ³¨æ„åŠ›æ›´å¼ºå¤§çš„è¯­è¨€groundingã€‚</li>
                <li style="margin-bottom:6px;"><b>ç»„åˆç»“æ„ï¼š</b>é€šè¿‡å°†ç¯å¢ƒå»ºæ¨¡ä¸ºç‹¬ç«‹ä½†ç›¸äº’ä½œç”¨çš„å®ä½“é›†åˆï¼Œå…·æœ‰æ­£äº¤å±æ€§ï¼Œè¯¥æ¡†æ¶å¯ä»¥æ³›åŒ–åˆ°è®­ç»ƒä¸­æœªè§çš„æ–°é¢–ç»„åˆã€‚</li>
                <li style="margin-bottom:6px;"><b>äººæœºååŒè§„åˆ’ï¼š</b>è®¡åˆ’è®¨è®ºåè®®å…è®¸ä»£ç†é€šè¿‡è‡ªç„¶è¯­è¨€åˆ©ç”¨äººç±»ä¸“ä¸šçŸ¥è¯†ï¼Œå‡å°‘åœ¨ç°å®ä¸–ç•Œä¸­è¿›è¡Œå¤§é‡è¯•é”™å­¦ä¹ çš„éœ€æ±‚ã€‚</li>
                <li style="margin-bottom:6px;"><b>æ¨¡å—åŒ–æ§åˆ¶ï¼š</b>å°†ä¸–ç•Œæ¨¡å‹é€‚åº”ä¸ç­–ç•¥ä¼˜åŒ–åˆ†ç¦»ï¼Œå®ç°æ›´é«˜æ•ˆå’Œæœ‰é’ˆå¯¹æ€§çš„æ›´æ–°ï¼Œå…¶ä¸­è¯­è¨€åé¦ˆå¯ä»¥ç›´æ¥ä¿®æ”¹ç¯å¢ƒç†è§£ã€‚</li>
                <li style="margin-bottom:6px;"><b>é€šè¿‡é€æ˜åº¦å®ç°å®‰å…¨ï¼š</b>é€šè¿‡è¦æ±‚ä»£ç†å¯è§†åŒ–å±•ç¤ºè®¡åˆ’å¹¶æ¥å—åŸºäºè¯­è¨€çš„ä¿®æ”¹ï¼Œè¯¥æ¡†æ¶é€šè¿‡å¢åŠ äººç±»ç›‘ç£å’Œæ§åˆ¶æ¥ä¿ƒè¿›æ›´å®‰å…¨çš„AIéƒ¨ç½²ã€‚</li>
            </ul>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>This groundbreaking work introduces Language-Guided World Models, a paradigm shift toward more controllable and human-aligned artificial agents. By enabling world models to be steered through natural language descriptions, the authors address fundamental limitations of traditional observational world models, which could only be adapted through costly data collection. The EMMA-LWM architecture demonstrates remarkable compositional generalization capabilities on the challenging MESSENGER benchmark, outperforming baseline approaches by substantial margins. The plan discussion framework showcases a practical pathway toward safer AI deployment, where agents can present execution trajectories to human supervisors for validation and refinement through verbal communication. This work establishes a new research direction at the intersection of language understanding, world modeling, and human-AI interaction, with profound implications for building AI systems that are not only capable but also transparent, controllable, and aligned with human values. The modular approach suggests that future AI architectures could benefit from designing components that are directly modifiable through natural language, potentially revolutionizing how humans interact with and control complex artificial systems.</p>
          </div>
          <div class="lang-zh" style="display:none">
            <p>è¿™é¡¹å¼€åˆ›æ€§å·¥ä½œå¼•å…¥äº†è¯­è¨€å¼•å¯¼ä¸–ç•Œæ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ªæœç€æ›´å¯æ§å’Œäººç±»å¯¹é½çš„äººå·¥ä»£ç†çš„èŒƒå¼è½¬å˜ã€‚é€šè¿‡ä½¿ä¸–ç•Œæ¨¡å‹èƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æè¿°è¿›è¡Œå¼•å¯¼ï¼Œä½œè€…è§£å†³äº†ä¼ ç»Ÿè§‚å¯Ÿä¸–ç•Œæ¨¡å‹çš„åŸºæœ¬é™åˆ¶ï¼Œè¿™äº›æ¨¡å‹åªèƒ½é€šè¿‡æ˜‚è´µçš„æ•°æ®æ”¶é›†è¿›è¡Œé€‚åº”ã€‚EMMA-LWMæ¶æ„åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„MESSENGERåŸºå‡†ä¸Šå±•ç¤ºäº†å“è¶Šçš„ç»„åˆæ³›åŒ–èƒ½åŠ›ï¼Œå¤§å¹…ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚è®¡åˆ’è®¨è®ºæ¡†æ¶å±•ç¤ºäº†ä¸€ä¸ªå®é™…é€”å¾„æ¥å®ç°æ›´å®‰å…¨çš„AIéƒ¨ç½²ï¼Œå…¶ä¸­ä»£ç†å¯ä»¥å‘äººç±»ç›‘ç£è€…å±•ç¤ºæ‰§è¡Œè½¨è¿¹ï¼Œé€šè¿‡å£å¤´æ²Ÿé€šè¿›è¡ŒéªŒè¯å’Œæ”¹è¿›ã€‚è¿™é¡¹å·¥ä½œåœ¨è¯­è¨€ç†è§£ã€ä¸–ç•Œå»ºæ¨¡å’Œäººæœºäº¤äº’çš„äº¤å‰ç‚¹å»ºç«‹äº†æ–°çš„ç ”ç©¶æ–¹å‘ï¼Œå¯¹æ„å»ºä¸ä»…æœ‰èƒ½åŠ›è€Œä¸”é€æ˜ã€å¯æ§å¹¶ä¸äººç±»ä»·å€¼è§‚å¯¹é½çš„AIç³»ç»Ÿå…·æœ‰æ·±è¿œå½±å“ã€‚æ¨¡å—åŒ–æ–¹æ³•è¡¨æ˜ï¼Œæœªæ¥çš„AIæ¶æ„å¯ä»¥é€šè¿‡è®¾è®¡èƒ½å¤Ÿç›´æ¥é€šè¿‡è‡ªç„¶è¯­è¨€ä¿®æ”¹çš„ç»„ä»¶è€Œå—ç›Šï¼Œè¿™å¯èƒ½å½»åº•æ”¹å˜äººç±»ä¸å¤æ‚äººå·¥ç³»ç»Ÿäº¤äº’å’Œæ§åˆ¶çš„æ–¹å¼ã€‚</p>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Official Code</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <p><b>ACL Anthology:</b> <a href="https://aclanthology.org/2024.splurobonlp-1.1.pdf" target="_blank" style="color:#8bffcf;">2024.splurobonlp-1.1</a></p>
          <p><b>Project Site:</b> <a href="https://language-guided-world-model.github.io" target="_blank" style="color:#8bffcf;">https://language-guided-world-model.github.io</a></p>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Core Code Implementationï¼ˆæ ¸å¿ƒä»£ç ï¼‰</h2>
        <div style="background:rgba(0,0,0,0.5); border:1px solid rgba(255,255,255,0.1); border-radius:8px; padding:12px; font-family:ui-monospace,Menlo,Consolas,monospace; font-size:12px; color:#8bffcf; margin:8px 0; overflow-x:auto;">
# Language-Guided World Models Implementation<br>
<br>
// EMMA Attention Mechanism for language grounding<br>
<span style="color:#569cd6;">class</span> <span style="color:#dcdcaa;">EMMA_Attention</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""EMMA attention for grounding language to entities"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">__init__</span>(self, hidden_dim):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.key_proj = nn.Linear(hidden_dim, 1)  <span style="color:#6a9955;"># For identity extraction</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.val_proj = nn.Linear(hidden_dim, 1)  <span style="color:#6a9955;"># For attribute extraction</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">forward</span>(self, entity_tokens, description_embeddings):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entity_tokens: [batch, seq_len, hidden_dim]<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description_embeddings: [batch, num_descriptions, desc_len, hidden_dim]<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Step 1: Extract identity-aware keys and attribute-aware values</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mkey = []<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mval = []<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> desc_emb <span style="color:#569cd6;">in</span> description_embeddings:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key_weights = F.softmax(self.key_proj(desc_emb), dim=-1)  <span style="color:#6a9955;"># [desc_len, 1]</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mkey_emb = torch.sum(key_weights * desc_emb, dim=-2)  <span style="color:#6a9955;"># [hidden_dim]</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val_weights = F.softmax(self.val_proj(desc_emb), dim=-1)  <span style="color:#6a9955;"># [desc_len, 1]</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mval_emb = torch.sum(val_weights * desc_emb, dim=-2)  <span style="color:#6a9955;"># [hidden_dim]</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mkey.append(mkey_emb)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mval.append(mval_emb)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mkey = torch.stack(mkey, dim=0)  <span style="color:#6a9955;"># [num_descriptions, hidden_dim]</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mval = torch.stack(mval, dim=0)  <span style="color:#6a9955;"># [num_descriptions, hidden_dim]</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Step 2: Cross-attend entity tokens with description representations</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attn_scores = torch.matmul(entity_tokens, mkey.transpose(-2, -1))  <span style="color:#6a9955;"># [batch, seq_len, num_descriptions]</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attn_weights = F.softmax(attn_scores, dim=-1)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grounded_features = torch.matmul(attn_weights, mval)  <span style="color:#6a9955;"># [batch, seq_len, hidden_dim]</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> grounded_features<br>
<br>
// Language-Guided World Model<br>
<span style="color:#569cd6;">class</span> <span style="color:#dcdcaa;">LanguageGuidedWorldModel</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""World model that conditions on language descriptions"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">__init__</span>(self, vocab_size, hidden_dim, num_entities):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.description_encoder = BertModel.from_pretrained(<span style="color:#ce9178;">'bert-base-uncased'</span>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.emma_attention = EMMA_Attention(hidden_dim)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.transformer = TransformerDecoder(hidden_dim, num_layers=4)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.output_head = nn.Linear(hidden_dim, vocab_size)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.num_entities = num_entities<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">forward</span>(self, trajectory_prefix, language_descriptions):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;trajectory_prefix: tokenized partial trajectory<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;language_descriptions: list of text descriptions<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Encode language descriptions</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;desc_embeddings = []<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> desc <span style="color:#569cd6;">in</span> language_descriptions:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;emb = self.description_encoder(desc)[<span style="color:#b5cea8;">'last_hidden_state'</span>]  <span style="color:#6a9955;"># [desc_len, hidden_dim]</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;desc_embeddings.append(emb)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;desc_embeddings = torch.stack(desc_embeddings, dim=0)  <span style="color:#6a9955;"># [num_entities, desc_len, hidden_dim]</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Apply EMMA attention to ground language to trajectory</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grounded_trajectory = self.emma_attention(trajectory_prefix, desc_embeddings)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Generate next trajectory tokens</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;decoder_output = self.transformer(grounded_trajectory)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;next_token_logits = self.output_head(decoder_output[:, -1, :])  <span style="color:#6a9955;"># Predict next token</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> next_token_logits<br>
        </div>
      </div>
    </div>
</section>
</body>
</html>
