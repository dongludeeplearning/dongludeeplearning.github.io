<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  // ç›´æ¥æ‰“å¼€PDFæ–‡ä»¶
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ arXiv 2024
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">GaussianTalker: Real-Time High-Fidelity Talking Head Synthesis with Audio-Driven 3D Gaussian Splatting</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Kyusun Cho, Joungbin Lee, Heeji Yoon, Yeobin Hong, Jaehoon Ko, Sangjun Ahn, Seungryong Kim<br>
        <span style="opacity:0.8">Korea University, NCSOFT</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to achieve real-time, high-fidelity talking head synthesis that maintains photorealistic quality and accurate lip synchronization while enabling pose control, overcoming the limitations of slow NeRF-based approaches?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•å®ç°å®æ—¶ã€é«˜ä¿çœŸçš„è¯´è¯å¤´éƒ¨åˆæˆï¼ŒåŒæ—¶ä¿æŒé€¼çœŸè´¨é‡å’Œå‡†ç¡®çš„å”‡åŒæ­¥ï¼Œå¹¶å®ç°å§¿åŠ¿æ§åˆ¶ï¼Œå…‹æœæ…¢é€ŸNeRFæ–¹æ³•çš„å±€é™æ€§ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Real-Time 3DGS Talking Head Synthesis:</b> Introduced GaussianTalker, the first real-time high-fidelity talking head synthesis framework leveraging 3D Gaussian Splatting for audio-driven facial animation, achieving up to 120 FPS rendering speed while maintaining photorealistic quality.</div>
            <div class="lang-zh" style="display:none"><b>å®æ—¶3DGSè¯´è¯å¤´éƒ¨åˆæˆï¼š</b>å¼•å…¥äº†GaussianTalkerï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåˆ©ç”¨3Dé«˜æ–¯ç‚¹äº‘è¿›è¡ŒéŸ³é¢‘é©±åŠ¨é¢éƒ¨åŠ¨ç”»çš„å®æ—¶é«˜ä¿çœŸè¯´è¯å¤´éƒ¨åˆæˆæ¡†æ¶ï¼Œå®ç°é«˜è¾¾120 FPSçš„æ¸²æŸ“é€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒé€¼çœŸè´¨é‡ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Implicit Feature Volume Representation:</b> Pioneered encoding 3D Gaussian attributes into a shared implicit feature representation using multi-resolution triplanes, enabling spatial-aware deformation and enforcing interactions between neighboring Gaussians for coherent facial motion.</div>
            <div class="lang-zh" style="display:none"><b>éšå¼ç‰¹å¾ä½“ç§¯è¡¨ç¤ºï¼š</b>å¼€åˆ›æ€§åœ°ä½¿ç”¨å¤šåˆ†è¾¨ç‡ä¸‰å¹³é¢å°†3Dé«˜æ–¯å±æ€§ç¼–ç åˆ°å…±äº«éšå¼ç‰¹å¾è¡¨ç¤ºä¸­ï¼Œå®ç°ç©ºé—´æ„ŸçŸ¥å˜å½¢å¹¶å¼ºåˆ¶é‚»è¿‘é«˜æ–¯ä¹‹é—´çš„äº¤äº’ä»¥å®ç°è¿è´¯çš„é¢éƒ¨è¿åŠ¨ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Spatial-Audio Cross-Attention:</b> Developed a spatial-audio attention mechanism that fuses 3D Gaussian features with audio features through cross-attention, enabling stable and region-specific deformation across numerous Gaussian primitives while disentangling speech-related motions from non-verbal scene variations.</div>
            <div class="lang-zh" style="display:none"><b>ç©ºé—´-éŸ³é¢‘äº¤å‰æ³¨æ„åŠ›ï¼š</b>å¼€å‘äº†ä¸€ç§ç©ºé—´-éŸ³é¢‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ›èåˆ3Dé«˜æ–¯ç‰¹å¾ä¸éŸ³é¢‘ç‰¹å¾ï¼Œåœ¨ä¼—å¤šé«˜æ–¯åŸºå…ƒä¸Šå®ç°ç¨³å®šä¸”åŒºåŸŸç‰¹å®šçš„å˜å½¢ï¼ŒåŒæ—¶åˆ†ç¦»è¯­éŸ³ç›¸å…³è¿åŠ¨ä¸éè¯­è¨€åœºæ™¯å˜åŒ–ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Superior Performance:</b> Achieved state-of-the-art results in facial fidelity, lip synchronization accuracy, and rendering speed, surpassing NeRF-based methods while maintaining compatibility with novel audio inputs and pose variations.</div>
            <div class="lang-zh" style="display:none"><b>å“è¶Šæ€§èƒ½ï¼š</b>åœ¨é¢éƒ¨ä¿çœŸåº¦ã€å”‡åŒæ­¥å‡†ç¡®æ€§å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œè¶…è¶Šäº†åŸºäºNeRFçš„æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒä¸æ–°é¢–éŸ³é¢‘è¾“å…¥å’Œå§¿åŠ¿å˜åŒ–çš„å…¼å®¹æ€§ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆå¼•è¨€ç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/gaussiantalker_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('gaussiantalker_arxiv2024.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('gaussiantalker_arxiv2024.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/gaussiantalker_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('gaussiantalker_arxiv2024.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('gaussiantalker_arxiv2024.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Real-Time Rendering Constraints:</b> Achieving high-fidelity talking head synthesis with photorealistic quality and accurate lip synchronization while maintaining real-time rendering speeds, overcoming the slow inference bottleneck of NeRF-based approaches.</div>
            <div class="lang-zh" style="display:none"><b>å®æ—¶æ¸²æŸ“çº¦æŸï¼š</b>åœ¨ä¿æŒé€¼çœŸè´¨é‡å’Œå‡†ç¡®å”‡åŒæ­¥çš„åŒæ—¶å®ç°é«˜ä¿çœŸè¯´è¯å¤´éƒ¨åˆæˆï¼Œå¹¶ç»´æŒå®æ—¶æ¸²æŸ“é€Ÿåº¦ï¼Œå…‹æœåŸºäºNeRFæ–¹æ³•çš„æ…¢é€Ÿæ¨ç†ç“¶é¢ˆã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>3DGS Parameter Manipulation:</b> Developing effective mechanisms to control and deform the extensive parameter space of 3D Gaussian primitives (position, rotation, scale, appearance) in response to audio inputs, ensuring stable and coherent facial animations.</div>
            <div class="lang-zh" style="display:none"><b>3DGSå‚æ•°æ“çºµï¼š</b>å¼€å‘æœ‰æ•ˆæœºåˆ¶æ¥æ§åˆ¶å’Œå˜å½¢3Dé«˜æ–¯åŸºå…ƒï¼ˆä½ç½®ã€æ—‹è½¬ã€ç¼©æ”¾ã€å¤–è§‚ï¼‰çš„å¹¿æ³›å‚æ•°ç©ºé—´ä»¥å“åº”éŸ³é¢‘è¾“å…¥ï¼Œç¡®ä¿ç¨³å®šå’Œè¿è´¯çš„é¢éƒ¨åŠ¨ç”»ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Spatial-Audio Feature Integration:</b> Effectively fusing spatial 3D information with temporal audio features to enable region-specific deformations, where different facial regions respond appropriately to speech audio while maintaining spatial coherence.</div>
            <div class="lang-zh" style="display:none"><b>ç©ºé—´-éŸ³é¢‘ç‰¹å¾é›†æˆï¼š</b>æœ‰æ•ˆåœ°èåˆç©ºé—´3Dä¿¡æ¯ä¸æ—¶é—´éŸ³é¢‘ç‰¹å¾ä»¥å®ç°åŒºåŸŸç‰¹å®šå˜å½¢ï¼Œå…¶ä¸­ä¸åŒé¢éƒ¨åŒºåŸŸé€‚å½“åœ°å“åº”è¯­éŸ³éŸ³é¢‘ï¼ŒåŒæ—¶ä¿æŒç©ºé—´è¿è´¯æ€§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Motion Disentanglement:</b> Separating speech-related facial motions (lip movements) from non-verbal scene variations (eye blinks, head movements, lighting changes) to enable accurate audio-driven animation without unwanted artifacts.</div>
            <div class="lang-zh" style="display:none"><b>è¿åŠ¨åˆ†ç¦»ï¼š</b>åˆ†ç¦»è¯­éŸ³ç›¸å…³é¢éƒ¨è¿åŠ¨ï¼ˆå”‡éƒ¨è¿åŠ¨ï¼‰ä¸éè¯­è¨€åœºæ™¯å˜åŒ–ï¼ˆçœ¨çœ¼ã€å¤´éƒ¨è¿åŠ¨ã€å…‰ç…§å˜åŒ–ï¼‰ï¼Œä»¥å®ç°å‡†ç¡®çš„éŸ³é¢‘é©±åŠ¨åŠ¨ç”»è€Œä¸äº§ç”Ÿä¸éœ€è¦çš„ä¼ªå½±ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Canonical to Deformed Mapping:</b> Establishing a robust mapping from canonical 3D head representation to deformed states while preserving facial identity and ensuring that deformation offsets are applied consistently across different viewing angles.</div>
            <div class="lang-zh" style="display:none"><b>è§„èŒƒåˆ°å˜å½¢æ˜ å°„ï¼š</b>å»ºç«‹ä»è§„èŒƒ3Då¤´éƒ¨è¡¨ç¤ºåˆ°å˜å½¢çŠ¶æ€çš„é²æ£’æ˜ å°„ï¼ŒåŒæ—¶ä¿ç•™é¢éƒ¨èº«ä»½å¹¶ç¡®ä¿å˜å½¢åç§»åœ¨ä¸åŒè§‚çœ‹è§’åº¦ä¸‹çš„ä¸€è‡´åº”ç”¨ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multi-Resolution Triplane Representation:</b> Employed a triplane feature volume to encode 3D Gaussian attributes into implicit spatial features, enabling interpolation-based attribute prediction that enforces spatial relationships between neighboring Gaussians for coherent deformation.</div>
            <div class="lang-zh" style="display:none"><b>å¤šåˆ†è¾¨ç‡ä¸‰å¹³é¢è¡¨ç¤ºï¼š</b>ä½¿ç”¨ä¸‰å¹³é¢ç‰¹å¾ä½“ç§¯å°†3Dé«˜æ–¯å±æ€§ç¼–ç åˆ°éšå¼ç©ºé—´ç‰¹å¾ä¸­ï¼Œå®ç°åŸºäºæ’å€¼çš„å±æ€§é¢„æµ‹ï¼Œå¼ºåˆ¶é‚»è¿‘é«˜æ–¯ä¹‹é—´çš„ç©ºé—´å…³ç³»ä»¥å®ç°è¿è´¯å˜å½¢ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Spatial-Audio Cross-Attention:</b> Implemented a cross-attention mechanism between spatial 3D features and audio features, allowing dynamic fusion that models how different facial regions should respond to speech audio while maintaining stability across numerous Gaussian parameters.</div>
            <div class="lang-zh" style="display:none"><b>ç©ºé—´-éŸ³é¢‘äº¤å‰æ³¨æ„åŠ›ï¼š</b>å®ç°äº†ç©ºé—´3Dç‰¹å¾ä¸éŸ³é¢‘ç‰¹å¾ä¹‹é—´çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œå…è®¸åŠ¨æ€èåˆï¼Œå»ºæ¨¡ä¸åŒé¢éƒ¨åŒºåŸŸåº”å¦‚ä½•å“åº”è¯­éŸ³éŸ³é¢‘ï¼ŒåŒæ—¶åœ¨ä¼—å¤šé«˜æ–¯å‚æ•°ä¸Šä¿æŒç¨³å®šæ€§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Motion Disentanglement via Auxiliary Inputs:</b> Incorporated eye blink features, viewpoint embeddings, and null vectors as additional conditioning inputs to separate speech-related motions from non-verbal scene variations, enabling precise control over different facial motion components.</div>
            <div class="lang-zh" style="display:none"><b>é€šè¿‡è¾…åŠ©è¾“å…¥è¿›è¡Œè¿åŠ¨åˆ†ç¦»ï¼š</b>çº³å…¥çœ¨çœ¼ç‰¹å¾ã€è§†ç‚¹åµŒå…¥å’Œç©ºå‘é‡ä½œä¸ºé¢å¤–çš„æ¡ä»¶è¾“å…¥ï¼Œä»¥åˆ†ç¦»è¯­éŸ³ç›¸å…³è¿åŠ¨ä¸éè¯­è¨€åœºæ™¯å˜åŒ–ï¼Œå®ç°å¯¹ä¸åŒé¢éƒ¨è¿åŠ¨æˆåˆ†çš„ç²¾ç¡®æ§åˆ¶ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Frame-wise Gaussian Deformation:</b> Predicted per-frame offsets for all Gaussian attributes (position, rotation, scale, appearance) conditioned on the fused spatial-audio features, enabling direct manipulation of the explicit 3D representation for accurate audio-driven facial animation.</div>
            <div class="lang-zh" style="display:none"><b>é€å¸§é«˜æ–¯å˜å½¢ï¼š</b>åŸºäºèåˆçš„ç©ºé—´-éŸ³é¢‘ç‰¹å¾é¢„æµ‹æ‰€æœ‰é«˜æ–¯å±æ€§ï¼ˆä½ç½®ã€æ—‹è½¬ã€ç¼©æ”¾ã€å¤–è§‚ï¼‰çš„é€å¸§åç§»ï¼Œå®ç°æ˜¾å¼3Dè¡¨ç¤ºçš„ç›´æ¥æ“çºµä»¥å®ç°å‡†ç¡®çš„éŸ³é¢‘é©±åŠ¨é¢éƒ¨åŠ¨ç”»ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Two-Stage Training Strategy:</b> Employed stage-wise optimization first learning canonical 3D Gaussians with triplane features, then training deformation networks with audio conditioning, ensuring stable convergence and high-quality reconstruction.</div>
            <div class="lang-zh" style="display:none"><b>ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼š</b>é‡‡ç”¨åˆ†é˜¶æ®µä¼˜åŒ–ï¼Œé¦–å…ˆä½¿ç”¨ä¸‰å¹³é¢ç‰¹å¾å­¦ä¹ è§„èŒƒ3Dé«˜æ–¯ï¼Œç„¶åä½¿ç”¨éŸ³é¢‘æ¡ä»¶è®­ç»ƒå˜å½¢ç½‘ç»œï¼Œç¡®ä¿ç¨³å®šæ”¶æ•›å’Œé«˜å“è´¨é‡å»ºã€‚</div>
          </li>
        </ol>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>3DGS vs NeRF for Dynamic Scenes:</b> The explicit geometric representation of 3DGS enables direct manipulation of facial primitives for audio-driven animation, providing superior rendering speed and editability compared to implicit NeRF representations while maintaining photorealistic quality.
            </div>
            <div class="lang-zh" style="display:none">
                <b>3DGS vs NeRF for Dynamic Scenes:</b>3DGSçš„æ˜¾å¼å‡ ä½•è¡¨ç¤ºå…è®¸ç›´æ¥æ“çºµé¢éƒ¨åŸºå…ƒè¿›è¡ŒéŸ³é¢‘é©±åŠ¨åŠ¨ç”»ï¼Œä¸éšå¼NeRFè¡¨ç¤ºç›¸æ¯”æä¾›äº†å“è¶Šçš„æ¸²æŸ“é€Ÿåº¦å’Œå¯ç¼–è¾‘æ€§ï¼ŒåŒæ—¶ä¿æŒé€¼çœŸè´¨é‡ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Spatial-Aware Feature Fusion:</b> The triplane-based feature encoding ensures spatial coherence across facial regions, enabling more natural and anatomically-plausible deformations compared to methods that treat Gaussians independently.
            </div>
            <div class="lang-zh" style="display:none">
                <b>ç©ºé—´æ„ŸçŸ¥ç‰¹å¾èåˆï¼š</b>åŸºäºä¸‰å¹³é¢çš„ç‰¹å¾ç¼–ç ç¡®ä¿é¢éƒ¨åŒºåŸŸé—´çš„ç©ºé—´è¿è´¯æ€§ï¼Œä¸ç‹¬ç«‹å¤„ç†é«˜æ–¯çš„æ–¹æ³•ç›¸æ¯”å®ç°äº†æ›´è‡ªç„¶å’Œè§£å‰–å­¦ä¸Šåˆç†çš„å˜å½¢ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Attention-Based Audio Integration:</b> Cross-attention mechanisms provide a more sophisticated approach to audio-visual fusion than simple concatenation or multiplication, enabling region-specific responses to speech while maintaining temporal stability.
            </div>
            <div class="lang-zh" style="display:none">
                <b>åŸºäºæ³¨æ„åŠ›çš„éŸ³é¢‘é›†æˆï¼š</b>äº¤å‰æ³¨æ„åŠ›æœºåˆ¶æä¾›äº†æ¯”ç®€å•è¿æ¥æˆ–ä¹˜æ³•æ›´å¤æ‚çš„éŸ³é¢‘-è§†è§‰èåˆæ–¹æ³•ï¼Œåœ¨ä¿æŒæ—¶é—´ç¨³å®šæ€§çš„åŒæ—¶å®ç°å¯¹è¯­éŸ³çš„åŒºåŸŸç‰¹å®šå“åº”ã€‚
            </div>
          </li>
        </ul>

        <div style="margin-top:16px; padding-top:12px; border-top:1px dashed rgba(255,255,255,.15);">
             <h3 style="margin:0 0 6px; font-size:14px; color:#8bffcf;">
               <span class="lang-en">High-Level Insights: Why it Works?</span>
               <span class="lang-zh" style="display:none">é«˜å±‚æ´å¯Ÿï¼šä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ</span>
             </h3>
             <div class="lang-en" style="color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                It works because GaussianTalker bridges the gap between explicit geometric modeling and implicit feature learning, enabling real-time manipulation of 3D Gaussians through spatially-aware attention mechanisms. The triplane representation ensures facial coherence while cross-attention provides precise audio-driven control, resulting in photorealistic talking heads with unprecedented speed and quality.
             </div>
             <div class="lang-zh" style="display:none; color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºGaussianTalkerå¼¥åˆäº†æ˜¾å¼å‡ ä½•å»ºæ¨¡ä¸éšå¼ç‰¹å¾å­¦ä¹ ä¹‹é—´çš„å·®è·ï¼Œé€šè¿‡ç©ºé—´æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶å®ç°3Dé«˜æ–¯çš„å®æ—¶æ“çºµã€‚ä¸‰å¹³é¢è¡¨ç¤ºç¡®ä¿é¢éƒ¨è¿è´¯æ€§ï¼Œè€Œäº¤å‰æ³¨æ„åŠ›æä¾›ç²¾ç¡®çš„éŸ³é¢‘é©±åŠ¨æ§åˆ¶ï¼Œä»è€Œäº§ç”Ÿå…·æœ‰å‰æ‰€æœªæœ‰é€Ÿåº¦å’Œè´¨é‡çš„é€¼çœŸè¯´è¯å¤´éƒ¨ã€‚
             </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            This paper introduces GaussianTalker, a novel real-time high-fidelity talking head synthesis framework that leverages 3D Gaussian Splatting for audio-driven facial animation. By encoding Gaussian attributes into implicit spatial features and using cross-attention for audio integration, the method achieves superior performance in facial fidelity and lip synchronization while reaching rendering speeds up to 120 FPS. The framework successfully addresses the challenges of controlling explicit 3D representations through audio inputs, demonstrating significant improvements over NeRF-based approaches in both quality and efficiency. Experimental results show GaussianTalker outperforms state-of-the-art methods across multiple benchmarks, establishing it as a new paradigm for real-time audio-driven talking head synthesis.
          </div>
          <div class="lang-zh" style="display:none">
            æœ¬æ–‡ä»‹ç»äº†GaussianTalkerï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„å®æ—¶é«˜ä¿çœŸè¯´è¯å¤´éƒ¨åˆæˆæ¡†æ¶ï¼Œåˆ©ç”¨3Dé«˜æ–¯ç‚¹äº‘è¿›è¡ŒéŸ³é¢‘é©±åŠ¨é¢éƒ¨åŠ¨ç”»ã€‚é€šè¿‡å°†é«˜æ–¯å±æ€§ç¼–ç åˆ°éšå¼ç©ºé—´ç‰¹å¾ä¸­å¹¶ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›è¿›è¡ŒéŸ³é¢‘é›†æˆï¼Œè¯¥æ–¹æ³•åœ¨é¢éƒ¨ä¿çœŸåº¦å’Œå”‡åŒæ­¥æ–¹é¢å®ç°äº†å“è¶Šæ€§èƒ½ï¼ŒåŒæ—¶è¾¾åˆ°é«˜è¾¾120 FPSçš„æ¸²æŸ“é€Ÿåº¦ã€‚è¯¥æ¡†æ¶æˆåŠŸè§£å†³äº†é€šè¿‡éŸ³é¢‘è¾“å…¥æ§åˆ¶æ˜¾å¼3Dè¡¨ç¤ºçš„æŒ‘æˆ˜ï¼Œåœ¨è´¨é‡å’Œæ•ˆç‡æ–¹é¢éƒ½æ˜¾ç¤ºå‡ºå¯¹åŸºäºNeRFæ–¹æ³•çš„æ˜¾è‘—æ”¹è¿›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGaussianTalkeråœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå°†å…¶ç¡®ç«‹ä¸ºå®æ—¶éŸ³é¢‘é©±åŠ¨è¯´è¯å¤´éƒ¨åˆæˆçš„æ–°èŒƒå¼ã€‚
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Links:</h2>
        <a href="https://github.com/cvlab-kaist/GaussianTalker" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          Project Page
        </a>
      </div>
    </div>
</section>
</body>
</html>
