<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius: 16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ CVPR 2022
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">Learning to Listen: Modeling Non-Deterministic Dyadic Facial Motion</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Evonne Ng, Hanbyul Joo, Liwen Hu, Hao Li, Trevor Darrell, Angjoo Kanazawa, Shiry Ginosar <br>
        <span style="opacity:0.8">UC Berkeley, Facebook Reality Labs, USC Institute for Creative Technologies</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to generate realistic and synchronous 3D listener facial motion based on a speaker's multimodal inputs (motion and audio) in dyadic conversations?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•åœ¨åŒäººå¯¹è¯ä¸­ï¼ŒåŸºäºè¯´è¯è€…çš„å¤šæ¨¡æ€è¾“å…¥ï¼ˆåŠ¨ä½œå’ŒéŸ³é¢‘ï¼‰ï¼Œç”Ÿæˆé€¼çœŸä¸”åŒæ­¥çš„ 3D å€¾å¬è€…é¢éƒ¨åŠ¨ä½œï¼Ÿ
        </div>
      </div>
    </div>
  
    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Unified Framework:</b> A novel framework for modeling non-deterministic listener motion in dyadic conversations using autoregressive prediction.</div>
            <div class="lang-zh" style="display:none"><b>ç»Ÿä¸€æ¡†æ¶ï¼š</b>ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œç”¨äºä½¿ç”¨è‡ªå›å½’é¢„æµ‹å¯¹åŒäººå¯¹è¯ä¸­çš„éç¡®å®šæ€§å€¾å¬è€…åŠ¨ä½œè¿›è¡Œå»ºæ¨¡ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>VQ-VAE Representation:</b> Introduces a motion-encoding VQ-VAE to learn a discrete latent representation of realistic facial motion, enabling non-deterministic prediction.</div>
            <div class="lang-zh" style="display:none"><b>VQ-VAE è¡¨ç¤ºï¼š</b>å¼•å…¥äº†åŠ¨ä½œç¼–ç  VQ-VAE æ¥å­¦ä¹ é€¼çœŸé¢éƒ¨åŠ¨ä½œçš„ç¦»æ•£æ½œåœ¨è¡¨ç¤ºï¼Œä»è€Œå®ç°éç¡®å®šæ€§é¢„æµ‹ã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Large-Scale Dataset:</b> Presents a new, large in-the-wild dataset of dyadic conversations to facilitate research in interactional communication.</div>
            <div class="lang-zh" style="display:none"><b>å¤§è§„æ¨¡æ•°æ®é›†ï¼š</b>æä¾›äº†ä¸€ä¸ªæ–°çš„ã€å¤§è§„æ¨¡çš„é‡å¤–åŒäººå¯¹è¯æ•°æ®é›†ï¼Œä»¥ä¿ƒè¿›äº’åŠ¨äº¤æµçš„ç ”ç©¶ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆç¤ºä¾‹ï¼‰</h2>
        <div style="border-radius:14px; overflow:hidden;">
             <img src="Figures/learning2listen_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />
        </div>
      </div>
  
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Non-Determinism:</b> Listener responses are inherently non-deterministic; the same speaker input can elicit various valid listener reactions.</div>
            <div class="lang-zh" style="display:none"><b>éç¡®å®šæ€§ï¼š</b>å€¾å¬è€…çš„ååº”æœ¬è´¨ä¸Šæ˜¯ä¸ç¡®å®šçš„ï¼›ç›¸åŒçš„è¯´è¯è€…è¾“å…¥å¯ä»¥å¼•å‘å„ç§æœ‰æ•ˆçš„å€¾å¬è€…ååº”ã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Multimodal Interaction:</b> Capturing the subtle interplay between the speaker's speech (audio) and their facial/body motion is crucial for realistic synthesis.</div>
            <div class="lang-zh" style="display:none"><b>å¤šæ¨¡æ€äº¤äº’ï¼š</b>æ•æ‰è¯´è¯è€…çš„è¯­éŸ³ï¼ˆéŸ³é¢‘ï¼‰ä¸å…¶é¢éƒ¨/èº«ä½“åŠ¨ä½œä¹‹é—´å¾®å¦™çš„ç›¸äº’ä½œç”¨å¯¹äºé€¼çœŸçš„åˆæˆè‡³å…³é‡è¦ã€‚</div>
          </li>
        </ul>
      </div>
  
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Cross-Modal Attention:</b> Utilizes a transformer with cross-attention to fuse speaker audio and motion features effectively.</div>
            <div class="lang-zh" style="display:none"><b>è·¨æ¨¡æ€æ³¨æ„åŠ›ï¼š</b>åˆ©ç”¨å…·æœ‰è·¨æ³¨æ„åŠ›çš„ Transformer æ¥æœ‰æ•ˆèåˆè¯´è¯è€…éŸ³é¢‘å’ŒåŠ¨ä½œç‰¹å¾ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>VQ-VAE Discretization:</b> Learns a codebook of facial motions using VQ-VAE, allowing the model to predict discrete tokens rather than continuous values, facilitating diversity.</div>
            <div class="lang-zh" style="display:none"><b>VQ-VAE ç¦»æ•£åŒ–ï¼š</b>ä½¿ç”¨ VQ-VAE å­¦ä¹ é¢éƒ¨åŠ¨ä½œçš„ç æœ¬ï¼Œå…è®¸æ¨¡å‹é¢„æµ‹ç¦»æ•£æ ‡è®°è€Œä¸æ˜¯è¿ç»­å€¼ï¼Œä»è€Œä¿ƒè¿›å¤šæ ·æ€§ã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Autoregressive Generation:</b> Predicts future listener motion tokens autoregressively based on past context and current speaker input.</div>
            <div class="lang-zh" style="display:none"><b>è‡ªå›å½’ç”Ÿæˆï¼š</b>åŸºäºè¿‡å»çš„ä¸Šä¸‹æ–‡å’Œå½“å‰çš„è¯´è¯è€…è¾“å…¥ï¼Œè‡ªå›å½’åœ°é¢„æµ‹æœªæ¥çš„å€¾å¬è€…åŠ¨ä½œæ ‡è®°ã€‚</div>
          </li>
        </ol>
      </div>
  
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/learning2listen_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />
            
            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('2204.08451.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('2204.08451.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                The proposed framework successfully models the non-deterministic nature of listener responses, generating diverse and appropriate facial reactions.
            </div>
            <div class="lang-zh" style="display:none">
                æ‰€æå‡ºçš„æ¡†æ¶æˆåŠŸåœ°å»ºæ¨¡äº†å€¾å¬è€…ååº”çš„éç¡®å®šæ€§æœ¬è´¨ï¼Œç”Ÿæˆäº†å¤šæ ·åŒ–ä¸”é€‚å½“çš„é¢éƒ¨ååº”ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                The introduction of a large-scale in-the-wild dataset significantly advances the potential for data-driven research in dyadic interaction modeling.
            </div>
            <div class="lang-zh" style="display:none">
                å¤§è§„æ¨¡é‡å¤–æ•°æ®é›†çš„å¼•å…¥æ˜¾è‘—æ¨è¿›äº†åŒäººäº¤äº’å»ºæ¨¡ä¸­æ•°æ®é©±åŠ¨ç ”ç©¶çš„æ½œåŠ›ã€‚
            </div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Code:</h2>
        <a href="https://github.com/evonneng/learning2listen" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          <svg height="16" viewBox="0 0 16 16" width="16" style="fill:currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg>
          GitHub Repo
        </a>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Core Code Logicï¼ˆæ ¸å¿ƒä»£ç é€»è¾‘ï¼‰</h2>
        <div class="lang-en" style="font-family:ui-monospace,Menlo,Consolas,monospace; font-size:12px; line-height:1.6; color:rgba(232,236,255,.85);">
            <div style="margin-bottom:12px;">
                // 1. Motion VQ-VAE: Discretizes facial motion into codebook indices
                <br><span style="color:#c792ea">class</span> <span style="color:#ffcb6b">MotionVQVAE</span>(nn.Module):
                <br>&nbsp;&nbsp;<span style="color:#c792ea">def</span> <span style="color:#82aaff">forward</span>(self, motion_seq):
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# Encode motion to continuous latent
                <br>&nbsp;&nbsp;&nbsp;&nbsp;z_e = self.encoder(motion_seq)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# Quantize: map to nearest codebook vectors
                <br>&nbsp;&nbsp;&nbsp;&nbsp;z_q, indices = self.quantizer(z_e)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# Decode back to motion space
                <br>&nbsp;&nbsp;&nbsp;&nbsp;recon_motion = self.decoder(z_q)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#c792ea">return</span> recon_motion, indices
            </div>

            <div style="margin-bottom:12px;">
                // 2. Cross-Modal Transformer: Autoregressive prediction
                <br><span style="color:#c792ea">class</span> <span style="color:#ffcb6b">ListenerTransformer</span>(nn.Module):
                <br>&nbsp;&nbsp;<span style="color:#c792ea">def</span> <span style="color:#82aaff">forward</span>(self, spk_audio, spk_motion, past_listener_tokens):
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# Encode speaker context
                <br>&nbsp;&nbsp;&nbsp;&nbsp;spk_feat = self.cross_modal_encoder(spk_audio, spk_motion)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# Decode listener response autoregressively
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# Causal masking ensures we only attend to past
                <br>&nbsp;&nbsp;&nbsp;&nbsp;logits = self.transformer_decoder(past_listener_tokens, spk_feat)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#c792ea">return</span> logits
            </div>

            <div>
                // 3. Inference: Non-deterministic sampling
                <br><span style="color:#c792ea">def</span> <span style="color:#82aaff">generate_listener</span>(spk_audio, spk_motion):
                <br>&nbsp;&nbsp;spk_feat = cross_modal_encoder(spk_audio, spk_motion)
                <br>&nbsp;&nbsp;tokens = [SOS]
                <br>&nbsp;&nbsp;
                <br>&nbsp;&nbsp;<span style="color:#c792ea">for</span> t <span style="color:#c792ea">in</span> range(seq_len):
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# Predict distribution for next token
                <br>&nbsp;&nbsp;&nbsp;&nbsp;logits = transformer_decoder(tokens, spk_feat)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# Sample from distribution (allows diversity)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;next_token = Categorical(logits[-1]).sample()
                <br>&nbsp;&nbsp;&nbsp;&nbsp;tokens.append(next_token)
                <br>&nbsp;&nbsp;
                <br>&nbsp;&nbsp;# Decode tokens to 3D motion
                <br>&nbsp;&nbsp;listener_motion = vq_vae.decoder(tokens)
                <br>&nbsp;&nbsp;<span style="color:#c792ea">return</span> listener_motion
            </div>
        </div>

        <div class="lang-zh" style="display:none; font-family:ui-monospace,Menlo,Consolas,monospace; font-size:12px; line-height:1.6; color:rgba(232,236,255,.85);">
            <div style="margin-bottom:12px;">
                // 1. åŠ¨ä½œ VQ-VAEï¼šå°†é¢éƒ¨åŠ¨ä½œç¦»æ•£åŒ–ä¸ºç æœ¬ç´¢å¼•
                <br><span style="color:#c792ea">class</span> <span style="color:#ffcb6b">MotionVQVAE</span>(nn.Module):
                <br>&nbsp;&nbsp;<span style="color:#c792ea">def</span> <span style="color:#82aaff">forward</span>(self, motion_seq):
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# å°†åŠ¨ä½œç¼–ç ä¸ºè¿ç»­æ½œåœ¨å˜é‡
                <br>&nbsp;&nbsp;&nbsp;&nbsp;z_e = self.encoder(motion_seq)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# é‡åŒ–ï¼šæ˜ å°„åˆ°æœ€è¿‘çš„ç æœ¬å‘é‡
                <br>&nbsp;&nbsp;&nbsp;&nbsp;z_q, indices = self.quantizer(z_e)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# è§£ç å›åŠ¨ä½œç©ºé—´
                <br>&nbsp;&nbsp;&nbsp;&nbsp;recon_motion = self.decoder(z_q)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#c792ea">return</span> recon_motion, indices
            </div>

            <div style="margin-bottom:12px;">
                // 2. è·¨æ¨¡æ€ Transformerï¼šè‡ªå›å½’é¢„æµ‹
                <br><span style="color:#c792ea">class</span> <span style="color:#ffcb6b">ListenerTransformer</span>(nn.Module):
                <br>&nbsp;&nbsp;<span style="color:#c792ea">def</span> <span style="color:#82aaff">forward</span>(self, spk_audio, spk_motion, past_listener_tokens):
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# ç¼–ç è¯´è¯è€…ä¸Šä¸‹æ–‡
                <br>&nbsp;&nbsp;&nbsp;&nbsp;spk_feat = self.cross_modal_encoder(spk_audio, spk_motion)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# è‡ªå›å½’è§£ç å€¾å¬è€…ååº”
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# å› æœæ©ç ç¡®ä¿åªå…³æ³¨è¿‡å»
                <br>&nbsp;&nbsp;&nbsp;&nbsp;logits = self.transformer_decoder(past_listener_tokens, spk_feat)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#c792ea">return</span> logits
            </div>

            <div>
                // 3. æ¨ç†ï¼šéç¡®å®šæ€§é‡‡æ ·
                <br><span style="color:#c792ea">def</span> <span style="color:#82aaff">generate_listener</span>(spk_audio, spk_motion):
                <br>&nbsp;&nbsp;spk_feat = cross_modal_encoder(spk_audio, spk_motion)
                <br>&nbsp;&nbsp;tokens = [SOS]
                <br>&nbsp;&nbsp;
                <br>&nbsp;&nbsp;<span style="color:#c792ea">for</span> t <span style="color:#c792ea">in</span> range(seq_len):
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# é¢„æµ‹ä¸‹ä¸€ä¸ª token çš„åˆ†å¸ƒ
                <br>&nbsp;&nbsp;&nbsp;&nbsp;logits = transformer_decoder(tokens, spk_feat)
                <br>&nbsp;&nbsp;&nbsp;&nbsp;# ä»åˆ†å¸ƒä¸­é‡‡æ ·ï¼ˆå®ç°å¤šæ ·æ€§ï¼‰
                <br>&nbsp;&nbsp;&nbsp;&nbsp;next_token = Categorical(logits[-1]).sample()
                <br>&nbsp;&nbsp;&nbsp;&nbsp;tokens.append(next_token)
                <br>&nbsp;&nbsp;
                <br>&nbsp;&nbsp;# å°† tokens è§£ç ä¸º 3D åŠ¨ä½œ
                <br>&nbsp;&nbsp;listener_motion = vq_vae.decoder(tokens)
                <br>&nbsp;&nbsp;<span style="color:#c792ea">return</span> listener_motion
            </div>
        </div>
      </div>
    
    </div>
  </section>
  <script>
    function toggleLang(btn) {
      const container = btn.closest('div');
      const enElements = container.querySelectorAll('.lang-en');
      const zhElements = container.querySelectorAll('.lang-zh');
      
      enElements.forEach(el => {
        el.style.display = (el.style.display === 'none') ? 'block' : 'none';
      });
      
      zhElements.forEach(el => {
        el.style.display = (el.style.display === 'none') ? 'block' : 'none';
      });
    }

    function openLocalPdf(filename) {
      window.open('pdfs/' + filename, '_blank');
    }

    function delLocalPdf(filename) {
      // User will implement this themselves
      alert("Please implement the delete logic or delete the file manually: pdfs/" + filename);
    }
  </script>
</body>
</html>
