<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  // ç›´æ¥æ‰“å¼€PDFæ–‡ä»¶
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ arXiv 2025
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">DIPSER: A Dataset for In-Person Student Engagement Recognition in the Wild</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Luis Marquez-Carpintero, Sergio Suescun-Ferrandiz, Carolina Lorenzo Ãlvarez, Jorge Fernandez-Herrero, Diego Viejo, Rosabel Roig-Vila, Miguel Cazorla<br>
        <span style="opacity:0.8">University of Alicante, Spain</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to create a comprehensive multimodal dataset that captures authentic in-person student engagement in real classroom environments, combining RGB cameras, smartwatch sensors, and expert annotations to enable accurate attention and emotion recognition?</div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•åˆ›å»ºä¸€ä¸ªå…¨é¢çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼Œåœ¨çœŸå®è¯¾å ‚ç¯å¢ƒä¸­æ•æ‰çœŸå®çš„é¢å¯¹é¢å­¦ç”Ÿå‚ä¸åº¦ï¼Œç»“åˆRGBæ‘„åƒå¤´ã€æ™ºèƒ½æ‰‹è¡¨ä¼ æ„Ÿå™¨å’Œä¸“å®¶æ ‡æ³¨ï¼Œä»¥å®ç°å‡†ç¡®çš„æ³¨æ„åŠ›å’Œæƒ…ç»ªè¯†åˆ«ï¼Ÿ</div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Comprehensive Multimodal Dataset:</b> Introduced DIPSER, the most comprehensive dataset for in-person student engagement recognition, combining RGB camera data (facial expressions and posture), smartwatch IMU sensors (heart rate, accelerometer, gyroscope), and environmental context cameras across nine diverse educational scenarios.</div>
            <div class="lang-zh" style="display:none"><b>å…¨é¢å¤šæ¨¡æ€æ•°æ®é›†ï¼š</b>å¼•å…¥äº†DIPSERï¼Œè¿™æ˜¯ç›®å‰æœ€å…¨é¢çš„é¢å¯¹é¢å­¦ç”Ÿå‚ä¸åº¦è¯†åˆ«æ•°æ®é›†ï¼Œç»“åˆRGBæ‘„åƒå¤´æ•°æ®ï¼ˆé¢éƒ¨è¡¨æƒ…å’Œå§¿åŠ¿ï¼‰ã€æ™ºèƒ½æ‰‹è¡¨IMUä¼ æ„Ÿå™¨ï¼ˆå¿ƒç‡ã€åŠ é€Ÿåº¦è®¡ã€é™€èºä»ªï¼‰å’Œç¯å¢ƒä¸Šä¸‹æ–‡æ‘„åƒå¤´ï¼Œæ¶µç›–ä¹ç§ä¸åŒçš„æ•™è‚²åœºæ™¯ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Real-World In-Person Setting:</b> Collected data in authentic classroom environments at the University of Alicante with 54 Caucasian students across three groups (undergraduate and master's levels), providing ecologically valid engagement data that overcomes limitations of online-only datasets and laboratory settings.</div>
            <div class="lang-zh" style="display:none"><b>çœŸå®ä¸–ç•Œé¢å¯¹é¢ç¯å¢ƒï¼š</b>åœ¨é˜¿åˆ©åç‰¹å¤§å­¦çœŸå®è¯¾å ‚ç¯å¢ƒä¸­æ”¶é›†æ•°æ®ï¼Œæ¶µç›–ä¸‰ä¸ªç¾¤ä½“ï¼ˆæœ¬ç§‘å’Œç¡•å£«æ°´å¹³ï¼‰çš„54åé«˜åŠ ç´¢å­¦ç”Ÿï¼Œæä¾›ç”Ÿæ€æœ‰æ•ˆçš„å‚ä¸åº¦æ•°æ®ï¼Œå…‹æœäº†ä»…åœ¨çº¿æ•°æ®é›†å’Œå®éªŒå®¤è®¾ç½®çš„å±€é™æ€§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Comprehensive Labeling Strategy:</b> Implemented rigorous labeling with five evaluators per student (four experts + self-report) providing attention labels (5-level scale) and emotion labels (9 categories), ensuring reliable ground truth for training and validating engagement recognition models.</div>
            <div class="lang-zh" style="display:none"><b>å…¨é¢æ ‡æ³¨ç­–ç•¥ï¼š</b>å®æ–½ä¸¥æ ¼çš„æ ‡æ³¨ï¼Œæ¯åå­¦ç”Ÿäº”åè¯„ä¼°è€…ï¼ˆå››åä¸“å®¶+è‡ªæˆ‘æŠ¥å‘Šï¼‰æä¾›æ³¨æ„åŠ›æ ‡ç­¾ï¼ˆ5çº§å°ºåº¦ï¼‰å’Œæƒ…ç»ªæ ‡ç­¾ï¼ˆ9ä¸ªç±»åˆ«ï¼‰ï¼Œç¡®ä¿è®­ç»ƒå’ŒéªŒè¯å‚ä¸åº¦è¯†åˆ«æ¨¡å‹çš„å¯é åœ°é¢çœŸç›¸ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Advanced Data Processing:</b> Provided pre-processed data including bounding boxes, facial landmarks, pose estimation, and demographic information using state-of-the-art tools (MediaPipe, MiVOLO, DeepFace), facilitating advanced multimodal analysis for researchers in affective computing and educational technology.</div>
            <div class="lang-zh" style="display:none"><b>å…ˆè¿›æ•°æ®å¤„ç†ï¼š</b>ä½¿ç”¨æœ€å…ˆè¿›çš„å·¥å…·ï¼ˆMediaPipeã€MiVOLOã€DeepFaceï¼‰æä¾›é¢„å¤„ç†æ•°æ®ï¼ŒåŒ…æ‹¬è¾¹ç•Œæ¡†ã€é¢éƒ¨åœ°æ ‡ã€å§¿æ€ä¼°è®¡å’Œäººå£ç»Ÿè®¡ä¿¡æ¯ï¼Œä¿ƒè¿›æƒ…æ„Ÿè®¡ç®—å’Œæ•™è‚²æŠ€æœ¯é¢†åŸŸç ”ç©¶è€…çš„å…ˆè¿›å¤šæ¨¡æ€åˆ†æã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <p>Figure shows examples of individual and contextual camera captures from the DIPSER dataset, demonstrating the multimodal nature of the data collection including RGB images and sensor data.</p>
            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('dipser_arxiv2025.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('dipser_arxiv2025.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multimodal Data Synchronization:</b> Coordinating multiple data streams (RGB cameras, smartwatch sensors, contextual cameras) with precise temporal alignment across distributed embedded devices in dynamic classroom environments.</div>
            <div class="lang-zh" style="display:none"><b>å¤šæ¨¡æ€æ•°æ®åŒæ­¥ï¼š</b>åœ¨åŠ¨æ€è¯¾å ‚ç¯å¢ƒä¸­ï¼Œé€šè¿‡åˆ†å¸ƒå¼åµŒå…¥å¼è®¾å¤‡ç²¾ç¡®åè°ƒå¤šä¸ªæ•°æ®æµï¼ˆRGBæ‘„åƒå¤´ã€æ™ºèƒ½æ‰‹è¡¨ä¼ æ„Ÿå™¨ã€ä¸Šä¸‹æ–‡æ‘„åƒå¤´ï¼‰çš„æ—¶åºå¯¹é½ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Ecological Validity in Data Collection:</b> Capturing authentic student behaviors in real classroom settings while ensuring participant privacy, obtaining informed consent, and maintaining naturalistic interactions without disrupting the educational process.</div>
            <div class="lang-zh" style="display:none"><b>æ•°æ®æ”¶é›†çš„ç”Ÿæ€æœ‰æ•ˆæ€§ï¼š</b>åœ¨çœŸå®è¯¾å ‚ç¯å¢ƒä¸­æ•æ‰çœŸå®çš„å­¦ç”Ÿè¡Œä¸ºï¼ŒåŒæ—¶ç¡®ä¿å‚ä¸è€…éšç§ã€è·å¾—çŸ¥æƒ…åŒæ„ï¼Œå¹¶åœ¨ä¸ä¸­æ–­æ•™è‚²è¿‡ç¨‹çš„æƒ…å†µä¸‹ä¿æŒè‡ªç„¶äº’åŠ¨ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Subjective Labeling Reliability:</b> Establishing consistent and reliable annotation protocols for subjective constructs like engagement and emotion, combining expert evaluations with self-reports while minimizing inter-rater variability.</div>
            <div class="lang-zh" style="display:none"><b>ä¸»è§‚æ ‡æ³¨å¯é æ€§ï¼š</b>ä¸ºå‚ä¸åº¦å’Œæƒ…ç»ªç­‰ä¸»è§‚ç»“æ„å»ºç«‹ä¸€è‡´ä¸”å¯é çš„æ ‡æ³¨åè®®ï¼Œç»“åˆä¸“å®¶è¯„ä¼°å’Œè‡ªæˆ‘æŠ¥å‘Šï¼ŒåŒæ—¶æœ€å°åŒ–è¯„ä¼°è€…é—´å˜å¼‚æ€§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Diverse Scenario Coverage:</b> Designing educational activities that elicit varied engagement states across different teaching methodologies while ensuring sufficient data balance for training robust machine learning models.</div>
            <div class="lang-zh" style="display:none"><b>å¤šæ ·åŒ–åœºæ™¯è¦†ç›–ï¼š</b>è®¾è®¡æ•™è‚²æ´»åŠ¨ï¼Œåœ¨ä¸åŒæ•™å­¦æ–¹æ³•ä¸­å¼•å‘å„ç§å‚ä¸çŠ¶æ€ï¼ŒåŒæ—¶ç¡®ä¿è®­ç»ƒç¨³å¥æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¶³å¤Ÿæ•°æ®å¹³è¡¡ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Privacy-Preserving Multimodal Analysis:</b> Balancing the need for comprehensive behavioral data with ethical considerations, implementing anonymization techniques while preserving analytical utility for attention and emotion research.</div>
            <div class="lang-zh" style="display:none"><b>éšç§ä¿æŠ¤å¤šæ¨¡æ€åˆ†æï¼š</b>å¹³è¡¡å¯¹å…¨é¢è¡Œä¸ºæ•°æ®çš„éœ€è¦ä¸ä¼¦ç†è€ƒè™‘ï¼Œå®ç°åŒ¿ååŒ–æŠ€æœ¯ï¼ŒåŒæ—¶ä¿æŒæ³¨æ„åŠ›å’Œæƒ…ç»ªç ”ç©¶çš„åˆ†ææ•ˆç”¨ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Distributed Capture Infrastructure:</b> Deployed Raspberry Pi-based system with 20 Logitech cameras and Samsung Galaxy Watch 5 smartwatches, utilizing Wi-Fi synchronization and centralized server control for coordinated multimodal data collection across classroom environments.</div>
            <div class="lang-zh" style="display:none"><b>åˆ†å¸ƒå¼æ•è·åŸºç¡€è®¾æ–½ï¼š</b>éƒ¨ç½²åŸºäºRaspberry Piçš„ç³»ç»Ÿï¼Œé…å¤‡20ä¸ªLogitechæ‘„åƒå¤´å’ŒSamsung Galaxy Watch 5æ™ºèƒ½æ‰‹è¡¨ï¼Œåˆ©ç”¨Wi-FiåŒæ­¥å’Œé›†ä¸­å¼æœåŠ¡å™¨æ§åˆ¶ï¼Œåœ¨è¯¾å ‚ç¯å¢ƒä¸­è¿›è¡Œåè°ƒçš„å¤šæ¨¡æ€æ•°æ®æ”¶é›†ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Nine Educational Scenarios:</b> Designed structured experiments including news reading, brainstorming, lectures, information organization, assessments, presentations, and robotics activities to elicit diverse engagement and emotional states across undergraduate and master's students.</div>
            <div class="lang-zh" style="display:none"><b>ä¹ç§æ•™è‚²åœºæ™¯ï¼š</b>è®¾è®¡ç»“æ„åŒ–å®éªŒï¼ŒåŒ…æ‹¬æ–°é—»é˜…è¯»ã€å¤´è„‘é£æš´ã€è®²åº§ã€ä¿¡æ¯ç»„ç»‡ã€è¯„ä¼°ã€æ¼”ç¤ºå’Œæœºå™¨äººæ´»åŠ¨ï¼Œä»¥åœ¨æœ¬ç§‘ç”Ÿå’Œç¡•å£«ç”Ÿä¸­å¼•å‘å¤šæ ·åŒ–çš„å‚ä¸åº¦å’Œæƒ…ç»ªçŠ¶æ€ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multimodal Data Streams:</b> Captured 1,311,761 high-resolution images with individual facial cameras (640Ã—480px) and contextual cameras (1280Ã—720px), combined with smartwatch sensor data including heart rate, accelerometer, gyroscope, and light sensors sampled at 1-100 Hz.</div>
            <div class="lang-zh" style="display:none"><b>å¤šæ¨¡æ€æ•°æ®æµï¼š</b>æ•è·1,311,761å¼ é«˜åˆ†è¾¨ç‡å›¾åƒï¼ŒåŒ…æ‹¬ä¸ªä½“é¢éƒ¨æ‘„åƒå¤´ï¼ˆ640Ã—480åƒç´ ï¼‰å’Œä¸Šä¸‹æ–‡æ‘„åƒå¤´ï¼ˆ1280Ã—720åƒç´ ï¼‰ï¼Œç»“åˆæ™ºèƒ½æ‰‹è¡¨ä¼ æ„Ÿå™¨æ•°æ®ï¼ŒåŒ…æ‹¬ä»¥1-100 Hzé‡‡æ ·çš„å¿ƒç‡ã€åŠ é€Ÿåº¦è®¡ã€é™€èºä»ªå’Œå…‰ä¼ æ„Ÿå™¨ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><div class="lang-en"><b>Comprehensive Annotation Pipeline:</b> Implemented five-labeler system (four experts + self-report) providing attention ratings (1-5 scale) and emotion classifications (9 categories: enjoyment, hope, pride, relief, anger, anxiety, shame, despair, boredom) with temporal resolution at one-second intervals.</div>
            <div class="lang-zh" style="display:none"><b>å…¨é¢æ ‡æ³¨ç®¡é“ï¼š</b>å®æ–½äº”æ ‡æ³¨è€…ç³»ç»Ÿï¼ˆå››åä¸“å®¶+è‡ªæˆ‘æŠ¥å‘Šï¼‰ï¼Œæä¾›æ³¨æ„åŠ›è¯„åˆ†ï¼ˆ1-5å°ºåº¦ï¼‰å’Œæƒ…ç»ªåˆ†ç±»ï¼ˆ9ä¸ªç±»åˆ«ï¼šäº«å—ã€å¸Œæœ›ã€è‡ªè±ªã€å®½æ…°ã€ç”Ÿæ°”ã€ç„¦è™‘ã€ç¾æ„§ã€ç»æœ›ã€æ— èŠï¼‰ï¼Œä»¥ä¸€ç§’é—´éš”çš„æ—¶åºåˆ†è¾¨ç‡ã€‚</div>
          </li>
        </ol>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Bridging Online and In-Person Learning Analytics:</b> DIPSER addresses the critical gap between online learning datasets and authentic classroom environments, providing multimodal data that enables more accurate and ecologically valid student engagement analysis for real-world educational applications.
            </div>
            <div class="lang-zh" style="display:none">
                <b>å¼¥åˆåœ¨çº¿å’Œé¢å¯¹é¢å­¦ä¹ åˆ†æï¼š</b>DIPSERè§£å†³äº†åœ¨çº¿å­¦ä¹ æ•°æ®é›†ä¸çœŸå®è¯¾å ‚ç¯å¢ƒä¹‹é—´çš„å…³é”®å·®è·ï¼Œæä¾›å¤šæ¨¡æ€æ•°æ®ï¼Œä½¿çœŸå®ä¸–ç•Œæ•™è‚²åº”ç”¨èƒ½å¤Ÿè¿›è¡Œæ›´å‡†ç¡®å’Œç”Ÿæ€æœ‰æ•ˆçš„å­¦ç”Ÿå‚ä¸åº¦åˆ†æã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Multimodal Sensor Integration:</b> The combination of visual, physiological, and contextual data provides a holistic view of student engagement, enabling correlations between observable behaviors, internal physiological states, and environmental factors that single-modality approaches cannot capture.
            </div>
            <div class="lang-zh" style="display:none">
                <b>å¤šæ¨¡æ€ä¼ æ„Ÿå™¨é›†æˆï¼š</b>è§†è§‰ã€ç”Ÿç†å’Œä¸Šä¸‹æ–‡æ•°æ®çš„ç»“åˆæä¾›äº†å­¦ç”Ÿå‚ä¸åº¦çš„æ•´ä½“è§†å›¾ï¼Œèƒ½å¤Ÿå…³è”å•æ¨¡æ€æ–¹æ³•æ— æ³•æ•æ‰çš„å¯è§‚å¯Ÿè¡Œä¸ºã€å†…éƒ¨ç”Ÿç†çŠ¶æ€å’Œç¯å¢ƒå› ç´ ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Ethical and Privacy-First Design:</b> The dataset demonstrates how comprehensive educational data collection can be conducted ethically, with robust anonymization, informed consent protocols, and adherence to international research standards while maximizing research utility.
            </div>
            <div class="lang-zh" style="display:none">
                <b>ä¼¦ç†å’Œéšç§ä¼˜å…ˆè®¾è®¡ï¼š</b>è¯¥æ•°æ®é›†å±•ç¤ºäº†å¦‚ä½•åœ¨ä¼¦ç†ä¸Šè¿›è¡Œå…¨é¢çš„æ•™è‚²æ•°æ®æ”¶é›†ï¼ŒåŒ…æ‹¬å¼ºå¤§çš„åŒ¿ååŒ–ã€çŸ¥æƒ…åŒæ„åè®®å’Œéµå®ˆå›½é™…ç ”ç©¶æ ‡å‡†ï¼ŒåŒæ—¶æœ€å¤§åŒ–ç ”ç©¶æ•ˆç”¨ã€‚
            </div>
          </li>
        </ul>

        <div style="margin-top:16px; padding-top:12px; border-top:1px dashed rgba(255,255,255,.15);">
             <h3 style="margin:0 0 6px; font-size:14px; color:#8bffcf;">
               <span class="lang-en">High-Level Insights: Why it Works?</span>
               <span class="lang-zh" style="display:none">é«˜å±‚æ´å¯Ÿï¼šä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ</span>
             </h3>
             <div class="lang-en" style="color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                It works because DIPSER combines authentic real-world data collection with rigorous multimodal annotation and processing, creating a comprehensive resource that bridges the gap between controlled research settings and actual classroom dynamics for more accurate and actionable student engagement analysis.
             </div>
             <div class="lang-zh" style="display:none; color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºDIPSERå°†çœŸå®ä¸–ç•Œæ•°æ®æ”¶é›†ä¸ä¸¥æ ¼çš„å¤šæ¨¡æ€æ ‡æ³¨å’Œå¤„ç†ç›¸ç»“åˆï¼Œåˆ›å»ºä¸€ä¸ªå…¨é¢çš„èµ„æºï¼Œå¼¥åˆå—æ§ç ”ç©¶è®¾ç½®ä¸å®é™…è¯¾å ‚åŠ¨æ€ä¹‹é—´çš„å·®è·ï¼Œå®ç°æ›´å‡†ç¡®å’Œå¯æ“ä½œçš„å­¦ç”Ÿå‚ä¸åº¦åˆ†æã€‚
             </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            This paper introduces DIPSER, a comprehensive multimodal dataset for in-person student engagement recognition in authentic classroom settings. The dataset encompasses 1,311,761 images from RGB cameras, smartwatch sensor data from 54 students across nine educational scenarios, and comprehensive attention/emotion labels from expert and self-report annotations. DIPSER uniquely combines facial, postural, physiological, and contextual data in real-world settings, providing the most extensive resource currently available for advancing research in affective computing and educational technology. The dataset is publicly available under ethical guidelines to catalyze development of more accurate and ecologically valid student engagement analysis systems.
          </div>
          <div class="lang-zh" style="display:none">
            æœ¬æ–‡ä»‹ç»äº†DIPSERï¼Œä¸€ä¸ªç”¨äºçœŸå®è¯¾å ‚ç¯å¢ƒä¸­é¢å¯¹é¢å­¦ç”Ÿå‚ä¸åº¦è¯†åˆ«çš„å…¨é¢å¤šæ¨¡æ€æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªRGBæ‘„åƒå¤´çš„1,311,761å¼ å›¾åƒã€æ¥è‡ªä¹ç§æ•™è‚²åœºæ™¯ä¸­54åå­¦ç”Ÿçš„æ™ºèƒ½æ‰‹è¡¨ä¼ æ„Ÿå™¨æ•°æ®ï¼Œä»¥åŠæ¥è‡ªä¸“å®¶å’Œè‡ªæˆ‘æŠ¥å‘Šæ ‡æ³¨çš„å…¨é¢æ³¨æ„åŠ›å’Œæƒ…ç»ªæ ‡ç­¾ã€‚DIPSERç‹¬ç‰¹åœ°ç»“åˆäº†çœŸå®ç¯å¢ƒä¸­çš„é¢éƒ¨ã€å§¿æ€ã€ç”Ÿç†å’Œä¸Šä¸‹æ–‡æ•°æ®ï¼Œæ˜¯ç›®å‰å¯ç”¨çš„æœ€å¹¿æ³›èµ„æºï¼Œç”¨äºæ¨è¿›æƒ…æ„Ÿè®¡ç®—å’Œæ•™è‚²æŠ€æœ¯é¢†åŸŸçš„ç ”ç©¶ã€‚è¯¥æ•°æ®é›†åœ¨ä¼¦ç†å‡†åˆ™ä¸‹å…¬å¼€å¯ç”¨ï¼Œä»¥å‚¬åŒ–å¼€å‘æ›´å‡†ç¡®å’Œç”Ÿæ€æœ‰æ•ˆçš„å­¦ç”Ÿå‚ä¸åº¦åˆ†æç³»ç»Ÿã€‚
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Links:</h2>
        <a href="https://arxiv.org/abs/2502.20209" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          arXiv
        </a>
        <a href="https://bitbucket.org/rovitlib/dipser/" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          Code Repository
        </a>
      </div>
    </div>
</section>
</body>
</html>
