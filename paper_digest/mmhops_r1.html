<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  // ç›´æ¥æ‰“å¼€PDFæ–‡ä»¶
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ AAAI 2026
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">MMhops-R1: Multimodal Multi-hop Reasoning</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Tao Zhang, Ziqi Zhang, Zongyang Ma, Yuxin Chen, Bing Li, Chunfeng Yuan, Guangting Wang, Fengyun Rao, Ying Shan, Weiming Hu<br>
        <span style="opacity:0.8">Chinese Academy of Sciences, Tencent Inc., PeopleAI Inc., ShanghaiTech University</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How can multimodal large language models perform complex multi-hop reasoning that requires dynamically integrating information across visual and textual modalities through external knowledge retrieval?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•è®©å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹é€šè¿‡å¤–éƒ¨çŸ¥è¯†æ£€ç´¢åŠ¨æ€æ•´åˆè§†è§‰å’Œæ–‡æœ¬æ¨¡æ€çš„ä¿¡æ¯æ¥è¿›è¡Œå¤æ‚çš„å¤šè·³æ¨ç†ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>MMhops Benchmark:</b> First large-scale multimodal multi-hop reasoning dataset with 31K samples, featuring Bridging (single-image sequential reasoning) and Comparison (cross-image comparative analysis) tasks requiring 3-4 reasoning hops spanning visual and textual modalities.</div>
            <div class="lang-zh" style="display:none"><b>MMhopsåŸºå‡†ï¼š</b>é¦–ä¸ªå¤§è§„æ¨¡å¤šæ¨¡æ€å¤šè·³æ¨ç†æ•°æ®é›†ï¼ŒåŒ…å«31Kä¸ªæ ·æœ¬ï¼Œç‰¹è‰²åŒ…æ‹¬Bridgingï¼ˆå•å›¾åƒé¡ºåºæ¨ç†ï¼‰å’ŒComparisonï¼ˆè·¨å›¾åƒæ¯”è¾ƒåˆ†æï¼‰ä»»åŠ¡ï¼Œéœ€è¦3-4ä¸ªæ¨ç†è·³è·ƒè·¨è¶Šè§†è§‰å’Œæ–‡æœ¬æ¨¡æ€ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Reinforcement Learning Framework:</b> MMhops-R1 framework using RL to optimize multimodal retrieval-augmented generation, enabling dynamic reasoning path planning with actions for image retrieval, text retrieval, and answer generation.</div>
            <div class="lang-zh" style="display:none"><b>å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼š</b>MMhops-R1æ¡†æ¶ä½¿ç”¨RLä¼˜åŒ–å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œå®ç°åŠ¨æ€æ¨ç†è·¯å¾„è§„åˆ’ï¼Œå…·æœ‰å›¾åƒæ£€ç´¢ã€æ–‡æœ¬æ£€ç´¢å’Œç­”æ¡ˆç”ŸæˆåŠ¨ä½œã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Composite Reward Mechanism:</b> Multi-component reward system combining outcome accuracy, format adherence, and action effectiveness, gated by successful trajectories to encourage proper tool usage and reasoning strategies.</div>
            <div class="lang-zh" style="display:none"><b>å¤åˆå¥–åŠ±æœºåˆ¶ï¼š</b>å¤šç»„ä»¶å¥–åŠ±ç³»ç»Ÿç»“åˆç»“æœå‡†ç¡®æ€§ã€æ ¼å¼éµå¾ªå’ŒåŠ¨ä½œæœ‰æ•ˆæ€§ï¼Œç”±æˆåŠŸè½¨è¿¹æ§åˆ¶ä»¥é¼“åŠ±é€‚å½“çš„å·¥å…·ä½¿ç”¨å’Œæ¨ç†ç­–ç•¥ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>State-of-the-Art Performance:</b> Significant improvements over baselines (up to 51.35% overall accuracy), demonstrating superiority of dynamic mRAG over fixed-process methods and strong generalization to fixed-hop reasoning tasks.</div>
            <div class="lang-zh" style="display:none"><b>æœ€å…ˆè¿›æ€§èƒ½ï¼š</b>å¯¹åŸºçº¿æ˜¾è‘—æ”¹è¿›ï¼ˆæ€»ä½“å‡†ç¡®ç‡é«˜è¾¾51.35%ï¼‰ï¼Œè¯æ˜åŠ¨æ€mRAGä¼˜äºå›ºå®šè¿‡ç¨‹æ–¹æ³•ï¼Œå¹¶åœ¨å›ºå®šè·³è·ƒæ¨ç†ä»»åŠ¡ä¸Šå…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Limited Multi-hop Reasoning:</b> Existing MLLMs excel at single-step visual understanding but lack capability for complex reasoning chains requiring iterative multimodal information integration across multiple retrieval steps.</div>
            <div class="lang-zh" style="display:none"><b>æœ‰é™çš„å¤šè·³æ¨ç†ï¼š</b>ç°æœ‰MLLMæ“…é•¿å•æ­¥è§†è§‰ç†è§£ï¼Œä½†ç¼ºä¹éœ€è¦è·¨å¤šä¸ªæ£€ç´¢æ­¥éª¤è¿­ä»£å¤šæ¨¡æ€ä¿¡æ¯æ•´åˆçš„å¤æ‚æ¨ç†é“¾èƒ½åŠ›ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Insufficient Benchmarks:</b> Current VQA datasets focus on shallow reasoning (1-2 hops) with limited multimodal integration, lacking challenging tasks that require dynamic planning of complex reasoning paths.</div>
            <div class="lang-zh" style="display:none"><b>ä¸è¶³çš„åŸºå‡†ï¼š</b>å½“å‰VQAæ•°æ®é›†ä¸“æ³¨äºæµ…å±‚æ¨ç†ï¼ˆ1-2è·³ï¼‰ï¼Œå¤šæ¨¡æ€æ•´åˆæœ‰é™ï¼Œç¼ºä¹éœ€è¦åŠ¨æ€è§„åˆ’å¤æ‚æ¨ç†è·¯å¾„çš„æŒ‘æˆ˜æ€§ä»»åŠ¡ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Static Retrieval Processes:</b> Conventional mRAG frameworks use fixed pipelines unsuitable for queries of varying complexity, lacking flexibility to adapt reasoning depth and strategy based on question difficulty.</div>
            <div class="lang-zh" style="display:none"><b>é™æ€æ£€ç´¢è¿‡ç¨‹ï¼š</b>ä¼ ç»ŸmRAGæ¡†æ¶ä½¿ç”¨å›ºå®šç®¡é“ï¼Œä¸é€‚åˆå¤æ‚åº¦ä¸åŒçš„æŸ¥è¯¢ï¼Œç¼ºä¹æ ¹æ®é—®é¢˜éš¾åº¦è°ƒæ•´æ¨ç†æ·±åº¦å’Œç­–ç•¥çš„çµæ´»æ€§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Cross-modal Integration:</b> Complex real-world problems require seamless integration of visual understanding with external textual knowledge through multi-turn interactions, challenging current model architectures.</div>
            <div class="lang-zh" style="display:none"><b>è·¨æ¨¡æ€æ•´åˆï¼š</b>å¤æ‚ç°å®é—®é¢˜éœ€è¦é€šè¿‡å¤šè½®äº¤äº’æ— ç¼æ•´åˆè§†è§‰ç†è§£ä¸å¤–éƒ¨æ–‡æœ¬çŸ¥è¯†ï¼Œå¯¹å½“å‰æ¨¡å‹æ¶æ„æ„æˆæŒ‘æˆ˜ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <div style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>MMhops-R1 introduces a reinforcement learning framework for dynamic multimodal multi-hop reasoning:</p>
            <ol style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>MMhops Dataset Construction:</b> Large-scale benchmark with Bridging tasks (single-image sequential reasoning) and Comparison tasks (cross-image comparative analysis), requiring 3-4 reasoning hops integrating visual and textual modalities through automated pipeline using GPT-4o.</li>
                <li style="margin-bottom:6px;"><b>Dynamic mRAG Framework:</b> Policy model with action space {image retrieval, text retrieval, answer generation}, using RL to learn adaptive reasoning strategies that dynamically adjust path complexity based on question requirements.</li>
                <li style="margin-bottom:6px;"><b>Multi-step Retrieval Process:</b> Agent interacts with image retriever (CLIP-ViT-L/14) and text retriever (E5 model) through structured queries, building reasoning trajectories with external knowledge integration across multiple turns.</li>
                <li style="margin-bottom:6px;"><b>Composite Reward Optimization:</b> Weighted reward combining outcome accuracy, format adherence, and action effectiveness, optimized using PPO with dynamic sampling to ensure procedural correctness and tool usage learning.</li>
                <li style="margin-bottom:6px;"><b>Loss Masking Strategy:</b> External retrieval observations masked during policy optimization, ensuring model learns from its own generated reasoning and action tokens rather than retrieved content.</li>
            </ol>
          </div>
          <div class="lang-zh" style="display: none;">
            <p>MMhops-R1å¼•å…¥äº†ä¸€ä¸ªç”¨äºåŠ¨æ€å¤šæ¨¡æ€å¤šè·³æ¨ç†çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼š</p>
            <ol style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>MMhopsæ•°æ®é›†æ„å»ºï¼š</b>å¤§è§„æ¨¡åŸºå‡†ï¼ŒåŒ…æ‹¬Bridgingä»»åŠ¡ï¼ˆå•å›¾åƒé¡ºåºæ¨ç†ï¼‰å’ŒComparisonä»»åŠ¡ï¼ˆè·¨å›¾åƒæ¯”è¾ƒåˆ†æï¼‰ï¼Œéœ€è¦3-4ä¸ªæ¨ç†è·³è·ƒï¼Œé€šè¿‡ä½¿ç”¨GPT-4oçš„è‡ªåŠ¨åŒ–ç®¡é“æ•´åˆè§†è§‰å’Œæ–‡æœ¬æ¨¡æ€ã€‚</li>
                <li style="margin-bottom:6px;"><b>åŠ¨æ€mRAGæ¡†æ¶ï¼š</b>å…·æœ‰åŠ¨ä½œç©ºé—´{å›¾åƒæ£€ç´¢ã€æ–‡æœ¬æ£€ç´¢ã€ç­”æ¡ˆç”Ÿæˆ}çš„ç­–ç•¥æ¨¡å‹ï¼Œä½¿ç”¨RLå­¦ä¹ è‡ªé€‚åº”æ¨ç†ç­–ç•¥ï¼Œæ ¹æ®é—®é¢˜è¦æ±‚åŠ¨æ€è°ƒæ•´è·¯å¾„å¤æ‚åº¦ã€‚</li>
                <li style="margin-bottom:6px;"><b>å¤šæ­¥æ£€ç´¢è¿‡ç¨‹ï¼š</b>ä»£ç†é€šè¿‡ç»“æ„åŒ–æŸ¥è¯¢ä¸å›¾åƒæ£€ç´¢å™¨ï¼ˆCLIP-ViT-L/14ï¼‰å’Œæ–‡æœ¬æ£€ç´¢å™¨ï¼ˆE5æ¨¡å‹ï¼‰äº¤äº’ï¼Œåœ¨å¤šä¸ªå›åˆä¸­æ„å»ºåŒ…å«å¤–éƒ¨çŸ¥è¯†æ•´åˆçš„æ¨ç†è½¨è¿¹ã€‚</li>
                <li style="margin-bottom:6px;"><b>å¤åˆå¥–åŠ±ä¼˜åŒ–ï¼š</b>åŠ æƒå¥–åŠ±ç»“åˆç»“æœå‡†ç¡®æ€§ã€æ ¼å¼éµå¾ªå’ŒåŠ¨ä½œæœ‰æ•ˆæ€§ï¼Œä½¿ç”¨PPOå’ŒåŠ¨æ€é‡‡æ ·è¿›è¡Œä¼˜åŒ–ï¼Œä»¥ç¡®ä¿ç¨‹åºæ­£ç¡®æ€§å’Œå·¥å…·ä½¿ç”¨å­¦ä¹ ã€‚</li>
                <li style="margin-bottom:6px;"><b>æŸå¤±å±è”½ç­–ç•¥ï¼š</b>ç­–ç•¥ä¼˜åŒ–æœŸé—´å±è”½å¤–éƒ¨æ£€ç´¢è§‚å¯Ÿï¼Œç¡®ä¿æ¨¡å‹ä»å…¶è‡ªèº«ç”Ÿæˆçš„æ¨ç†å’ŒåŠ¨ä½œæ ‡è®°ä¸­å­¦ä¹ ï¼Œè€Œä¸æ˜¯æ£€ç´¢å†…å®¹ã€‚</li>
            </ol>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/mmhops_r1_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
              <button onclick="openLocalPdf('arxiv_mmhops_r1.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
              <button onclick="delLocalPdf('arxiv_mmhops_r1.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
         </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/mmhops_r1_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('arxiv_mmhops_r1.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('arxiv_mmhops_r1.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <h3 style="margin:12px 0 6px;font-size:14px;color:#8bffcf;">Why it Works?</h3>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>The effectiveness of MMhops-R1 stems from its RL-driven dynamic reasoning approach:</p>
            <ul style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>Adaptive Reasoning Depth:</b> RL optimization enables the model to dynamically adjust reasoning complexity based on question difficulty, avoiding over-retrieval in simple cases and ensuring sufficient depth for complex queries.</li>
                <li style="margin-bottom:6px;"><b>Multimodal Knowledge Integration:</b> Structured action space combining image and text retrieval allows seamless cross-modal reasoning, with the model learning when to leverage visual vs. textual knowledge sources for optimal information gathering.</li>
                <li style="margin-bottom:6px;"><b>Procedural Learning:</b> Composite reward mechanism with process-based rewards enables learning of correct reasoning procedures even when final outcomes are correct, leading to more robust and interpretable decision-making.</li>
                <li style="margin-bottom:6px;"><b>External Knowledge Orchestration:</b> Dynamic interaction with retrievers overcomes limitations of fixed pipelines, allowing the model to explore multiple reasoning paths and backtrack when suboptimal strategies are identified.</li>
                <li style="margin-bottom:6px;"><b>Scalable Training Paradigm:</b> RL framework provides a generalizable approach for complex reasoning tasks, with the ability to incorporate new retrievers and action types as multimodal capabilities expand.</li>
            </ul>
          </div>
          <div class="lang-zh" style="display:none">
            <p>MMhops-R1çš„æœ‰æ•ˆæ€§æºäºå…¶RLé©±åŠ¨çš„åŠ¨æ€æ¨ç†æ–¹æ³•ï¼š</p>
            <ul style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>è‡ªé€‚åº”æ¨ç†æ·±åº¦ï¼š</b>RLä¼˜åŒ–ä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®é—®é¢˜éš¾åº¦åŠ¨æ€è°ƒæ•´æ¨ç†å¤æ‚åº¦ï¼Œé¿å…åœ¨ç®€å•æƒ…å†µä¸‹è¿‡åº¦æ£€ç´¢ï¼Œå¹¶åœ¨å¤æ‚æŸ¥è¯¢ä¸­ç¡®ä¿è¶³å¤Ÿçš„æ·±åº¦ã€‚</li>
                <li style="margin-bottom:6px;"><b>å¤šæ¨¡æ€çŸ¥è¯†æ•´åˆï¼š</b>ç»“åˆå›¾åƒå’Œæ–‡æœ¬æ£€ç´¢çš„ç»“æ„åŒ–åŠ¨ä½œç©ºé—´å…è®¸æ— ç¼è·¨æ¨¡æ€æ¨ç†ï¼Œæ¨¡å‹å­¦ä¹ ä½•æ—¶åˆ©ç”¨è§†è§‰ä¸æ–‡æœ¬çŸ¥è¯†æºä»¥å®ç°æœ€ä¼˜ä¿¡æ¯æ”¶é›†ã€‚</li>
                <li style="margin-bottom:6px;"><b>ç¨‹åºæ€§å­¦ä¹ ï¼š</b>å…·æœ‰åŸºäºè¿‡ç¨‹å¥–åŠ±çš„å¤åˆå¥–åŠ±æœºåˆ¶ï¼Œå³ä½¿åœ¨æœ€ç»ˆç»“æœæ­£ç¡®çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å­¦ä¹ æ­£ç¡®çš„æ¨ç†ç¨‹åºï¼Œå¯¼è‡´æ›´ç¨³å¥å’Œå¯è§£é‡Šçš„å†³ç­–åˆ¶å®šã€‚</li>
                <li style="margin-bottom:6px;"><b>å¤–éƒ¨çŸ¥è¯†ç¼–æ’ï¼š</b>ä¸æ£€ç´¢å™¨çš„åŠ¨æ€äº¤äº’å…‹æœäº†å›ºå®šç®¡é“çš„å±€é™æ€§ï¼Œå…è®¸æ¨¡å‹æ¢ç´¢å¤šä¸ªæ¨ç†è·¯å¾„ï¼Œå¹¶åœ¨è¯†åˆ«å‡ºæ¬¡ä¼˜ç­–ç•¥æ—¶è¿›è¡Œå›æº¯ã€‚</li>
                <li style="margin-bottom:6px;"><b>å¯æ‰©å±•è®­ç»ƒèŒƒå¼ï¼š</b>RLæ¡†æ¶ä¸ºå¤æ‚æ¨ç†ä»»åŠ¡æä¾›äº†å¯æ³›åŒ–çš„æ–¹æ³•ï¼Œéšç€å¤šæ¨¡æ€èƒ½åŠ›çš„æ‰©å±•ï¼Œèƒ½å¤Ÿçº³å…¥æ–°çš„æ£€ç´¢å™¨å’ŒåŠ¨ä½œç±»å‹ã€‚</li>
            </ul>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>This work addresses the critical challenge of multimodal multi-hop reasoning by introducing MMhops, the first large-scale benchmark requiring systematic integration of visual and textual information across variable reasoning depths, and MMhops-R1, a novel reinforcement learning framework for dynamic multimodal retrieval-augmented generation. The framework's RL-driven approach enables adaptive reasoning path planning that overcomes the limitations of static retrieval processes, demonstrating significant performance improvements over strong baselines including proprietary MLLMs. Through comprehensive evaluation on MMhops and generalization tests on fixed-hop reasoning tasks, the work establishes that dynamic planning and multi-modal knowledge integration are essential for complex reasoning capabilities. The composite reward mechanism and procedural learning paradigm provide a foundation for developing more sophisticated multimodal reasoning systems, with the RL framework offering a scalable approach to incorporate emerging retrieval modalities and reasoning strategies.</p>
          </div>
          <div class="lang-zh" style="display:none">
            <p>è¿™é¡¹å·¥ä½œé€šè¿‡å¼•å…¥MMhopsï¼ˆé¦–ä¸ªå¤§è§„æ¨¡åŸºå‡†ï¼Œéœ€è¦ç³»ç»Ÿæ•´åˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯è·¨è¶Šå¯å˜æ¨ç†æ·±åº¦ï¼‰å’ŒMMhops-R1ï¼ˆç”¨äºåŠ¨æ€å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆçš„æ–°å‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼‰æ¥è§£å†³å¤šæ¨¡æ€å¤šè·³æ¨ç†çš„å…³é”®æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶çš„RLé©±åŠ¨æ–¹æ³•å®ç°äº†å…‹æœé™æ€æ£€ç´¢è¿‡ç¨‹å±€é™çš„è‡ªé€‚åº”æ¨ç†è·¯å¾„è§„åˆ’ï¼Œåœ¨åŒ…æ‹¬ä¸“æœ‰MLLMåœ¨å†…çš„å¼ºå¤§åŸºçº¿ä¸Šå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚é€šè¿‡å¯¹MMhopsçš„å…¨é¢è¯„ä¼°å’Œå¯¹å›ºå®šè·³è·ƒæ¨ç†ä»»åŠ¡çš„æ³›åŒ–æµ‹è¯•ï¼Œè¯¥å·¥ä½œç¡®ç«‹äº†åŠ¨æ€è§„åˆ’å’Œå¤šæ¨¡æ€çŸ¥è¯†æ•´åˆå¯¹å¤æ‚æ¨ç†èƒ½åŠ›è‡³å…³é‡è¦ã€‚å¤åˆå¥–åŠ±æœºåˆ¶å’Œç¨‹åºæ€§å­¦ä¹ èŒƒå¼ä¸ºå¼€å‘æ›´å¤æ‚çš„å¤šæ¨¡æ€æ¨ç†ç³»ç»Ÿæä¾›äº†åŸºç¡€ï¼ŒRLæ¡†æ¶æä¾›äº†çº³å…¥æ–°å…´æ£€ç´¢æ¨¡æ€å’Œæ¨ç†ç­–ç•¥çš„å¯æ‰©å±•æ–¹æ³•ã€‚</p>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Official Code</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <p><b>ArXiv:</b> <a href="https://arxiv.org/pdf/2512.13573" target="_blank" style="color:#8bffcf;">2512.13573</a></p>
          <p><b>GitHub:</b> <a href="https://github.com/taoszhang/MMhops-R1" target="_blank" style="color:#8bffcf;">https://github.com/taoszhang/MMhops-R1</a></p>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Core Code Implementationï¼ˆæ ¸å¿ƒä»£ç å®ç°ï¼‰</h2>
        <div style="background:rgba(0,0,0,0.5); border:1px solid rgba(255,255,255,0.1); border-radius:8px; padding:12px; font-family:ui-monospace,Menlo,Consolas,monospace; font-size:12px; color:#8bffcf; margin:8px 0; overflow-x:auto;">
import torch<br>
import torch.nn as nn<br>
from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer<br>
from typing import List, Dict, Any<br>
import numpy as np<br>
<br>
// MMhops-R1: Multimodal Multi-hop Reasoning with RL<br>
class MMhopsR1:<br>
&nbsp;&nbsp;&nbsp;&nbsp;def __init__(self, model_name="Qwen/Qwen2-VL-7B-Instruct"):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.model = Qwen2VLForConditionalGeneration.from_pretrained(model_name)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.tokenizer = AutoTokenizer.from_pretrained(model_name)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.image_retriever = CLIPImageRetriever()  # CLIP-ViT-L/14@336px<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.text_retriever = TextRetriever()  # E5 model<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.max_steps = 4<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Action space: {think, image_search, text_search, answer}<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.actions = ["think", "image_search", "text_search", "answer"]<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def rollout_trajectory(self, question: str, images: List[np.ndarray]) -> Dict[str, Any]:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Generate reasoning trajectory with multi-step retrieval"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;trajectory = []<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state = {"question": question, "images": images, "history": []}<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for step in range(self.max_steps):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Generate next action and reasoning<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;action_output = self._generate_action(state)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;action, reasoning = self._parse_action(action_output)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if action == "answer":<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Execute action and get observation<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;observation = self._execute_action(action, reasoning, state)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Update state<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state["history"].append({"action": action, "reasoning": reasoning, "observation": observation})<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;trajectory.append((state.copy(), action, observation))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return {"trajectory": trajectory, "final_answer": reasoning if action == "answer" else None}<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def _generate_action(self, state: Dict) -> str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Generate next action using the policy model"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Format prompt with current state<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt = self._format_state_prompt(state)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Generate response<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;inputs = self.tokenizer(prompt, return_tensors="pt")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Add image inputs if needed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if state["images"]:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;inputs["images"] = state["images"]<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputs = self.model.generate(**inputs, max_new_tokens=512)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return self.tokenizer.decode(outputs[0], skip_special_tokens=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def _parse_action(self, output: str) -> tuple:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Parse action and content from model output"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if "&lt;answer&gt;" in output:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return "answer", self._extract_content(output, "answer")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elif "&lt;image_search&gt;" in output:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return "image_search", self._extract_content(output, "image_search")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elif "&lt;text_search&gt;" in output:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return "text_search", self._extract_content(output, "text_search")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return "think", output  # Default to thinking<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def _execute_action(self, action: str, content: str, state: Dict) -> str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Execute the selected action and return observation"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if action == "image_search":<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Extract image index from content<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;image_idx = self._extract_image_index(content)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return self.image_retriever.retrieve(state["images"][image_idx])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elif action == "text_search":<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return self.text_retriever.retrieve(content)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return "Action executed successfully"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def compute_reward(self, trajectory: List, ground_truth: str) -> float:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Compute composite reward for trajectory"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;final_answer = trajectory[-1][1] if trajectory and trajectory[-1][0] == "answer" else None<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Outcome reward<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r_outcome = 1.0 if self._check_answer_correct(final_answer, ground_truth) else 0.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Format reward<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r_format = self._check_format_correct(trajectory)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Action reward (gated by success)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r_action = r_outcome * r_format * self._count_valid_actions(trajectory)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return 1.0 * r_outcome + 1.0 * r_format + 0.25 * r_action<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def _format_state_prompt(self, state: Dict) -> str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Format state into prompt for model input"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt = f"Question: {state['question']}\n\n"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if state['images']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt += f"Images: {len(state['images'])} images provided\n\n"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt += "History:\n"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for entry in state['history']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt += f"- {entry['action']}: {entry['reasoning']}\n"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt += f"  Observation: {entry['observation']}\n"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt += "\nChoose your next action: think, image_search, text_search, or answer\n"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return prompt<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def _extract_content(self, text: str, tag: str) -> str:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Extract content between XML-like tags"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;start_tag = f"&lt;{tag}&gt;"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;end_tag = f"&lt;/{tag}&gt;"<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;start = text.find(start_tag)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;end = text.find(end_tag)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if start != -1 and end != -1:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return text[start + len(start_tag):end].strip()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return text<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def _extract_image_index(self, content: str) -> int:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Extract image index from content (simplified)"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return 0  # Default to first image<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def _check_answer_correct(self, answer: str, ground_truth: str) -> bool:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Check if answer matches ground truth (simplified)"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return answer and ground_truth in answer<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def _check_format_correct(self, trajectory: List) -> float:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Check if trajectory follows correct format"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return 1.0 if all(self._is_valid_action_format(step) for step in trajectory) else 0.0<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def _count_valid_actions(self, trajectory: List) -> float:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Count syntactically correct tool invocations"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return sum(1 for step in trajectory if step[0] in ["image_search", "text_search"])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;def _is_valid_action_format(self, step) -> bool:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"""Check if action follows required format"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return True  # Simplified<br>
<br>
// Example usage<br>
# mmhops_r1 = MMhopsR1()<br>
# trajectory = mmhops_r1.rollout_trajectory("What is the elevation gap between the mountain summits in the two images?", [image1, image2])<br>
# reward = mmhops_r1.compute_reward(trajectory["trajectory"], "511m")<br>
        </div>
      </div>
    </div>
</section>
</body>
</html>
