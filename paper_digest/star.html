<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ NeurIPS 2022
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">STaR: Bootstrapping Reasoning With Reasoning</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Eric Zelikman, Yuhuai Wu, Jesse Mu, Noah Goodman<br>
        <span style="opacity:0.8">Stanford University</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How can we create a scalable method to improve language models' reasoning capabilities by iteratively generating and filtering rationales that lead to correct answers, without requiring expensive human annotations?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•åˆ›å»ºä¸€ä¸ªå¯æ‰©å±•çš„æ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£ç”Ÿæˆå’Œç­›é€‰å¯¼è‡´æ­£ç¡®ç­”æ¡ˆçš„æ¨ç†æ¥æ”¹è¿›è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œè€Œæ— éœ€æ˜‚è´µçš„æ ‡æ³¨ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Self-Taught Reasoner (STaR):</b> Introduced STaR, a bootstrapping method that iteratively improves language models by generating rationales for problems, filtering those that lead to correct answers, and fine-tuning on the successful rationales.</div>
            <div class="lang-zh" style="display:none"><b>Self-Taught Reasoner (STaR)ï¼š</b>å¼•å…¥äº†STaRï¼Œè¿™æ˜¯ä¸€ç§å¼•å¯¼æ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£ç”Ÿæˆé—®é¢˜çš„æ¨ç†ã€ç­›é€‰å¯¼è‡´æ­£ç¡®ç­”æ¡ˆçš„æ¨ç†ï¼Œå¹¶åŸºäºæˆåŠŸçš„æ¨ç†è¿›è¡Œå¾®è°ƒæ¥æ”¹è¿›è¯­è¨€æ¨¡å‹ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Rationalization Technique:</b> Proposed rationalization, where the model is provided with the correct answer as a hint to generate rationales for problems it initially failed, enabling the model to reason backward and learn from difficult examples.</div>
            <div class="lang-zh" style="display:none"><b>åˆç†åŒ–æŠ€æœ¯ï¼š</b>æå‡ºäº†åˆç†åŒ–ï¼Œå…¶ä¸­ä¸ºæ¨¡å‹æä¾›æ­£ç¡®ç­”æ¡ˆä½œä¸ºæç¤ºæ¥ç”Ÿæˆå…¶æœ€åˆå¤±è´¥çš„é—®é¢˜çš„æ¨ç†ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå‘åæ¨ç†å¹¶ä»å›°éš¾ç¤ºä¾‹ä¸­å­¦ä¹ ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Scalable Rationale Generation:</b> Transformed few-shot prompts into large rationale datasets without manual annotation, achieving significant performance improvements on arithmetic, commonsense reasoning, and math word problems.</div>
            <div class="lang-zh" style="display:none"><b>å¯æ‰©å±•æ¨ç†ç”Ÿæˆï¼š</b>å°†å°‘æ ·æœ¬æç¤ºè½¬æ¢ä¸ºå¤§å‹æ¨ç†æ•°æ®é›†è€Œæ— éœ€æ‰‹åŠ¨æ ‡æ³¨ï¼Œåœ¨ç®—æœ¯ã€å¸¸è¯†æ¨ç†å’Œæ•°å­¦è¯é—®é¢˜ä¸Šå®ç°äº†æ˜¾è‘—æ€§èƒ½æ”¹è¿›ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Superior Performance:</b> Demonstrated that STaR outperforms few-shot baselines and direct fine-tuning, achieving 72.5% accuracy on CommonsenseQA (comparable to a 30Ã— larger GPT-3 model) and strong results on arithmetic and GSM8K.</div>
            <div class="lang-zh" style="display:none"><b>å“è¶Šæ€§èƒ½ï¼š</b>è¯æ˜äº†STaRä¼˜äºå°‘æ ·æœ¬åŸºçº¿å’Œç›´æ¥å¾®è°ƒï¼Œåœ¨CommonsenseQAä¸Šè¾¾åˆ°72.5%çš„å‡†ç¡®ç‡ï¼ˆä¸30å€å¤§çš„GPT-3æ¨¡å‹ç›¸å½“ï¼‰ï¼Œåœ¨ç®—æœ¯å’ŒGSM8Kä¸Šä¹Ÿå–å¾—äº†å¼ºåŠ²ç»“æœã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Limited Rationale Quality:</b> Few-shot prompting with rationales underperforms models fine-tuned to directly predict answers, indicating that initial rationale quality is insufficient for optimal performance.</div>
            <div class="lang-zh" style="display:none"><b>æ¨ç†è´¨é‡æœ‰é™ï¼š</b>å¸¦æœ‰æ¨ç†çš„å°‘æ ·æœ¬æç¤ºçš„æ€§èƒ½ä¸å¦‚ç›´æ¥é¢„æµ‹ç­”æ¡ˆçš„å¾®è°ƒæ¨¡å‹ï¼Œè¡¨æ˜åˆå§‹æ¨ç†è´¨é‡ä¸è¶³ä»¥å®ç°æœ€ä½³æ€§èƒ½ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Bootstrapping Plateau:</b> The bootstrapping process eventually plateaus because the model receives no training signal for problems it cannot solve, limiting the scope of learnable improvements.</div>
            <div class="lang-zh" style="display:none"><b>å¼•å¯¼åœæ»ï¼š</b>å¼•å¯¼è¿‡ç¨‹æœ€ç»ˆä¼šåœæ»ï¼Œå› ä¸ºæ¨¡å‹æ— æ³•è§£å†³çš„é—®é¢˜æ²¡æœ‰è®­ç»ƒä¿¡å·ï¼Œé™åˆ¶äº†å¯å­¦ä¹ æ”¹è¿›çš„èŒƒå›´ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Scalability Constraints:</b> Current methods for inducing rationale generation (manual annotation, template-based approaches) are expensive and not scalable to diverse domains and tasks.</div>
            <div class="lang-zh" style="display:none"><b>å¯æ‰©å±•æ€§çº¦æŸï¼š</b>å½“å‰è¯±å¯¼æ¨ç†ç”Ÿæˆçš„æ–¹æ³•ï¼ˆæ‰‹åŠ¨æ ‡æ³¨ã€åŸºäºæ¨¡æ¿çš„æ–¹æ³•ï¼‰æ˜‚è´µä¸”æ— æ³•æ‰©å±•åˆ°å¤šæ ·åŒ–çš„é¢†åŸŸå’Œä»»åŠ¡ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Faithfulness and Bias:</b> Generated rationales may not faithfully represent the model's internal reasoning process, and the method can amplify dataset biases when they correlate with correct answers.</div>
            <div class="lang-zh" style="display:none"><b>å¿ å®åº¦å’Œåè§ï¼š</b>ç”Ÿæˆçš„æ¨ç†å¯èƒ½æ— æ³•å¿ å®ä»£è¡¨æ¨¡å‹çš„å†…éƒ¨æ¨ç†è¿‡ç¨‹ï¼Œå¹¶ä¸”å½“åè§ä¸æ­£ç¡®ç­”æ¡ˆç›¸å…³æ—¶ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šæ”¾å¤§æ•°æ®é›†åè§ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <div style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>STaR bootstraps reasoning capabilities through iterative rationale generation and fine-tuning:</p>
            <ol style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>Rationale Generation:</b> Start with few-shot prompts containing example rationales, use the model to generate rationales for training problems, and filter to keep only those leading to correct answers.</li>
                <li style="margin-bottom:6px;"><b>Iterative Fine-tuning:</b> Fine-tune the model on the filtered rationales, then repeat the process with the improved model to generate better rationales, creating a bootstrapping loop that improves reasoning quality over iterations.</li>
                <li style="margin-bottom:6px;"><b>Rationalization:</b> For problems the model fails to solve, provide the correct answer as a hint to help the model generate rationales backward from the answer, expanding the training signal to difficult examples.</li>
                <li style="margin-bottom:6px;"><b>Self-Improvement Cycle:</b> Combine rationale generation with rationalization, fine-tune on both successful rationales and rationalized explanations, enabling the model to improve itself by learning from its own generated reasoning.</li>
                <li style="margin-bottom:6px;"><b>Scalable Rationale Dataset:</b> Transform a small set of initial few-shot prompts into a large, high-quality rationale dataset through the bootstrapping process, without requiring extensive manual annotation.</li>
            </ol>
          </div>
          <div class="lang-zh" style="display: none;">
            <p>STaRé€šè¿‡è¿­ä»£æ¨ç†ç”Ÿæˆå’Œå¾®è°ƒæ¥å¼•å¯¼æ¨ç†èƒ½åŠ›ï¼š</p>
            <ol style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>æ¨ç†ç”Ÿæˆï¼š</b>ä»åŒ…å«ç¤ºä¾‹æ¨ç†çš„å°‘æ ·æœ¬æç¤ºå¼€å§‹ï¼Œä½¿ç”¨æ¨¡å‹ä¸ºè®­ç»ƒé—®é¢˜ç”Ÿæˆæ¨ç†ï¼Œå¹¶ç­›é€‰ä»…ä¿ç•™å¯¼è‡´æ­£ç¡®ç­”æ¡ˆçš„æ¨ç†ã€‚</li>
                <li style="margin-bottom:6px;"><b>è¿­ä»£å¾®è°ƒï¼š</b>åœ¨ç­›é€‰çš„æ¨ç†ä¸Šå¾®è°ƒæ¨¡å‹ï¼Œç„¶åä½¿ç”¨æ”¹è¿›çš„æ¨¡å‹é‡å¤è¯¥è¿‡ç¨‹ä»¥ç”Ÿæˆæ›´å¥½çš„æ¨ç†ï¼Œåˆ›å»ºä¸€ä¸ªéšç€è¿­ä»£è€Œæ”¹è¿›æ¨ç†è´¨é‡çš„å¼•å¯¼å¾ªç¯ã€‚</li>
                <li style="margin-bottom:6px;"><b>åˆç†åŒ–ï¼š</b>å¯¹äºæ¨¡å‹æ— æ³•è§£å†³çš„é—®é¢˜ï¼Œæä¾›æ­£ç¡®ç­”æ¡ˆä½œä¸ºæç¤ºä»¥å¸®åŠ©æ¨¡å‹ä»ç­”æ¡ˆå‘åç”Ÿæˆæ¨ç†ï¼Œå°†è®­ç»ƒä¿¡å·æ‰©å±•åˆ°å›°éš¾ç¤ºä¾‹ã€‚</li>
                <li style="margin-bottom:6px;"><b>è‡ªæˆ‘æ”¹è¿›å¾ªç¯ï¼š</b>å°†æ¨ç†ç”Ÿæˆä¸åˆç†åŒ–ç›¸ç»“åˆï¼Œåœ¨æˆåŠŸçš„æ¨ç†å’Œåˆç†åŒ–çš„è§£é‡Šä¸Šå¾®è°ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé€šè¿‡å­¦ä¹ è‡ªå·±ç”Ÿæˆçš„æ¨ç†æ¥æ”¹è¿›è‡ªå·±ã€‚</li>
                <li style="margin-bottom:6px;"><b>å¯æ‰©å±•æ¨ç†æ•°æ®é›†ï¼š</b>é€šè¿‡å¼•å¯¼è¿‡ç¨‹å°†ä¸€å°ç»„åˆå§‹å°‘æ ·æœ¬æç¤ºè½¬æ¢ä¸ºå¤§å‹ã€é«˜è´¨é‡æ¨ç†æ•°æ®é›†ï¼Œè€Œæ— éœ€å¤§é‡æ‰‹åŠ¨æ ‡æ³¨ã€‚</li>
            </ol>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆå¼•è¨€å›¾ï¼‰</h2>
        <div style="border-radius:14px; overflow:hidden;">
            <img src="Figures/star_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px solid rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/star_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />
            <p>STaR iteratively improves reasoning by generating rationales, filtering correct ones, and fine-tuning the model, with rationalization helping on difficult problems.</p>
            <p>Note: The method achieves significant improvements on arithmetic (89.5% accuracy), CommonsenseQA (72.5% accuracy), and GSM8K (10.7% accuracy) by bootstrapping high-quality rationales from few initial examples.</p>

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('arxiv_star.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('arxiv_star.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <h3 style="margin:12px 0 6px;font-size:14px;color:#8bffcf;">Why it Works?</h3>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>STaR succeeds by creating a virtuous cycle of self-improvement through iterative rationale refinement:</p>
            <ul style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>Bootstrapping Quality:</b> Each iteration filters and retains only rationales that lead to correct answers, progressively improving the quality of the training data and the model's reasoning capabilities.</li>
                <li style="margin-bottom:6px;"><b>Rationalization for Coverage:</b> By providing correct answers as hints for failed problems, rationalization ensures the model can learn from all training examples, preventing the bootstrapping plateau and expanding the model's problem-solving scope.</li>
                <li style="margin-bottom:6px;"><b>Iterative Self-Improvement:</b> The method leverages the model's existing reasoning capabilities to generate better rationales, which in turn improve the model through fine-tuning, creating a self-reinforcing learning loop.</li>
                <li style="margin-bottom:6px;"><b>Scalable Rationale Generation:</b> Starting from just a few manually crafted rationales, STaR scales to generate thousands of high-quality rationales automatically, making reasoning training accessible without extensive human annotation.</li>
                <li style="margin-bottom:6px;"><b>Intermediate Supervision:</b> Providing explicit rationales as intermediate steps offers better learning signals than end-to-end answer prediction, enabling the model to learn more robust and generalizable reasoning patterns.</li>
            </ul>
          </div>
          <div class="lang-zh" style="display:none">
            <p>STaRé€šè¿‡è¿­ä»£æ¨ç†ç»†åŒ–çš„è‡ªæˆ‘æ”¹è¿›è‰¯æ€§å¾ªç¯è€ŒæˆåŠŸï¼š</p>
            <ul style="margin:8px 0;">
                <li style="margin-bottom:6px;"><b>å¼•å¯¼è´¨é‡ï¼š</b>æ¯æ¬¡è¿­ä»£ç­›é€‰å¹¶ä»…ä¿ç•™å¯¼è‡´æ­£ç¡®ç­”æ¡ˆçš„æ¨ç†ï¼Œé€æ­¥æé«˜è®­ç»ƒæ•°æ®çš„è´¨é‡å’Œæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚</li>
                <li style="margin-bottom:6px;"><b>åˆç†åŒ–è¦†ç›–ï¼š</b>é€šè¿‡ä¸ºå¤±è´¥é—®é¢˜æä¾›æ­£ç¡®ç­”æ¡ˆä½œä¸ºæç¤ºï¼Œåˆç†åŒ–ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿä»æ‰€æœ‰è®­ç»ƒç¤ºä¾‹ä¸­å­¦ä¹ ï¼Œé˜²æ­¢å¼•å¯¼åœæ»å¹¶æ‰©å±•æ¨¡å‹çš„é—®é¢˜è§£å†³èŒƒå›´ã€‚</li>
                <li style="margin-bottom:6px;"><b>è¿­ä»£è‡ªæˆ‘æ”¹è¿›ï¼š</b>è¯¥æ–¹æ³•åˆ©ç”¨æ¨¡å‹ç°æœ‰çš„æ¨ç†èƒ½åŠ›æ¥ç”Ÿæˆæ›´å¥½çš„æ¨ç†ï¼Œåè¿‡æ¥é€šè¿‡å¾®è°ƒæ”¹è¿›æ¨¡å‹ï¼Œåˆ›å»ºä¸€ä¸ªè‡ªæˆ‘å¼ºåŒ–å­¦ä¹ å¾ªç¯ã€‚</li>
                <li style="margin-bottom:6px;"><b>å¯æ‰©å±•æ¨ç†ç”Ÿæˆï¼š</b>ä»ä»…å‡ ä¸ªæ‰‹åŠ¨åˆ¶ä½œçš„æ¨ç†å¼€å§‹ï¼ŒSTaRè‡ªåŠ¨æ‰©å±•åˆ°ç”Ÿæˆæ•°åƒä¸ªé«˜è´¨é‡æ¨ç†ï¼Œä½¿æ¨ç†è®­ç»ƒæ— éœ€å¤§é‡äººå·¥æ ‡æ³¨å³å¯è·å¾—ã€‚</li>
                <li style="margin-bottom:6px;"><b>ä¸­é—´ç›‘ç£ï¼š</b>å°†æ˜¾å¼æ¨ç†ä½œä¸ºä¸­é—´æ­¥éª¤æä¾›æ¯”ç«¯åˆ°ç«¯ç­”æ¡ˆé¢„æµ‹æ›´å¥½çš„å­¦ä¹ ä¿¡å·ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ›´ç¨³å¥å’Œæ›´å…·æ³›åŒ–æ€§çš„æ¨ç†æ¨¡å¼ã€‚</li>
            </ul>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            <p>This pioneering work introduces STaR (Self-Taught Reasoner), a groundbreaking bootstrapping approach that enables language models to iteratively improve their own reasoning capabilities without requiring extensive human annotation. By leveraging the model's existing reasoning skills to generate rationales, filtering those that lead to correct answers, and fine-tuning on the successful examples, STaR creates a self-improving loop that transforms a small number of initial rationales into a comprehensive reasoning training set. The addition of rationalizationâ€”providing correct answers as hints for failed problemsâ€”breaks through the bootstrapping plateau, ensuring the model can learn from all training examples and tackle increasingly difficult reasoning tasks. Experimental results demonstrate STaR's remarkable effectiveness across diverse domains: achieving 89.5% accuracy on arithmetic problems, 72.5% accuracy on CommonsenseQA (matching a 30Ã— larger GPT-3 model), and significant improvements on GSM8K math word problems. The method represents a fundamental shift in how we approach reasoning training for language models, moving from expensive human annotation to scalable self-supervised learning. By showing that models can teach themselves to reason more effectively, STaR opens new possibilities for building more capable and autonomous AI systems that can continuously improve their reasoning abilities through self-generated learning signals.</p>
          </div>
          <div class="lang-zh" style="display:none">
            <p>è¿™é¡¹å¼€åˆ›æ€§å·¥ä½œå¼•å…¥äº†STaRï¼ˆSelf-Taught Reasonerï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¼€åˆ›æ€§çš„å¼•å¯¼æ–¹æ³•ï¼Œä½¿è¯­è¨€æ¨¡å‹èƒ½å¤Ÿè¿­ä»£æ”¹è¿›è‡ªå·±çš„æ¨ç†èƒ½åŠ›ï¼Œè€Œæ— éœ€å¤§é‡äººå·¥æ ‡æ³¨ã€‚é€šè¿‡åˆ©ç”¨æ¨¡å‹ç°æœ‰çš„æ¨ç†æŠ€èƒ½æ¥ç”Ÿæˆæ¨ç†ã€ç­›é€‰å¯¼è‡´æ­£ç¡®ç­”æ¡ˆçš„æ¨ç†ï¼Œå¹¶åŸºäºæˆåŠŸç¤ºä¾‹è¿›è¡Œå¾®è°ƒï¼ŒSTaRåˆ›å»ºäº†ä¸€ä¸ªè‡ªæˆ‘æ”¹è¿›å¾ªç¯ï¼Œå°†å°‘é‡åˆå§‹æ¨ç†è½¬æ¢ä¸ºå…¨é¢çš„æ¨ç†è®­ç»ƒé›†ã€‚åˆç†åŒ–çš„æ·»åŠ â€”â€”ä¸ºå¤±è´¥é—®é¢˜æä¾›æ­£ç¡®ç­”æ¡ˆä½œä¸ºæç¤ºâ€”â€”çªç ´äº†å¼•å¯¼åœæ»ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿä»æ‰€æœ‰è®­ç»ƒç¤ºä¾‹ä¸­å­¦ä¹ å¹¶å¤„ç†è¶Šæ¥è¶Šå›°éš¾çš„æ¨ç†ä»»åŠ¡ã€‚å®éªŒç»“æœè¯æ˜äº†STaRåœ¨ä¸åŒé¢†åŸŸä¸­çš„å“è¶Šæœ‰æ•ˆæ€§ï¼šåœ¨ç®—æœ¯é—®é¢˜ä¸Šè¾¾åˆ°89.5%çš„å‡†ç¡®ç‡ï¼Œåœ¨CommonsenseQAä¸Šè¾¾åˆ°72.5%çš„å‡†ç¡®ç‡ï¼ˆä¸30å€å¤§çš„GPT-3æ¨¡å‹ç›¸å½“ï¼‰ï¼Œåœ¨GSM8Kæ•°å­¦è¯é—®é¢˜ä¸Šä¹Ÿå–å¾—äº†æ˜¾è‘—æ”¹è¿›ã€‚è¯¥æ–¹æ³•ä»£è¡¨äº†è¯­è¨€æ¨¡å‹æ¨ç†è®­ç»ƒæ–¹å¼çš„æ ¹æœ¬è½¬å˜ï¼Œä»æ˜‚è´µçš„äººå·¥æ ‡æ³¨è½¬å‘å¯æ‰©å±•çš„è‡ªæˆ‘ç›‘ç£å­¦ä¹ ã€‚é€šè¿‡è¡¨æ˜æ¨¡å‹å¯ä»¥æ•™ä¼šè‡ªå·±æ›´æœ‰æ•ˆåœ°æ¨ç†ï¼ŒSTaRä¸ºæ„å»ºæ›´å¼ºå¤§å’Œè‡ªä¸»çš„AIç³»ç»Ÿå¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ï¼Œè¿™äº›ç³»ç»Ÿèƒ½å¤Ÿé€šè¿‡è‡ªæˆ‘ç”Ÿæˆçš„ä¿¡å·ä¸æ–­æ”¹è¿›å…¶æ¨ç†èƒ½åŠ›ã€‚</p>
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Official Code</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <p><b>ArXiv:</b> <a href="https://arxiv.org/abs/2203.14465" target="_blank" style="color:#8bffcf;">2203.14465</a></p>
          <p><b>GitHub:</b> <a href="https://github.com/ezelikman/STaR" target="_blank" style="color:#8bffcf;">https://github.com/ezelikman/STaR</a></p>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Core Code Implementationï¼ˆæ ¸å¿ƒä»£ç ï¼‰</h2>
        <div style="background:rgba(0,0,0,0.5); border:1px solid rgba(255,255,255,0.1); border-radius:8px; padding:12px; font-family:ui-monospace,Menlo,Consolas,monospace; font-size:12px; color:#8bffcf; margin:8px 0; overflow-x:auto;">
# STaR Implementation<br>
<br>
// STaR bootstrapping algorithm<br>
<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">star_bootstrapping</span>(model, dataset, few_shot_prompts, max_iterations=10):<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""Self-Taught Reasoner bootstrapping"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;current_model = model<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> iteration <span style="color:#569cd6;">in</span> range(max_iterations):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(f"Iteration {iteration + 1}")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Step 1: Rationale generation</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rationales_correct = []<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rationales_failed = []<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> problem, answer <span style="color:#569cd6;">in</span> dataset:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt = few_shot_prompts + format_problem(problem)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rationale, predicted_answer = current_model.generate(prompt)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">if</span> predicted_answer == answer:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rationales_correct.append((problem, rationale, answer))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">else</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rationales_failed.append((problem, answer))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Step 2: Rationalization for failed problems</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rationalized_rationales = []<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">for</span> problem, answer <span style="color:#569cd6;">in</span> rationales_failed:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prompt_with_hint = few_shot_prompts + format_problem(problem) + f" The answer is {answer}."<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rationale, _ = current_model.generate(prompt_with_hint)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rationalized_rationales.append((problem, rationale, answer))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Step 3: Fine-tune on combined rationales</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training_data = rationales_correct + rationalized_rationales<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current_model = fine_tune_model(model, training_data)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Evaluate performance</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accuracy = evaluate_model(current_model, dataset)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(f"Accuracy after iteration {iteration + 1}: {accuracy}")<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> current_model<br>
<br>
// Rationale generation with few-shot prompting<br>
<span style="color:#569cd6;">def</span> <span style="color:#dcdcaa;">generate_rationale</span>(model, problem, few_shot_examples):<br>
&nbsp;&nbsp;&nbsp;&nbsp;"""Generate rationale for a problem using few-shot examples"""<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompt = few_shot_examples<br>
&nbsp;&nbsp;&nbsp;&nbsp;prompt += f"\n\nQuestion: {problem}\nAnswer:"<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;response = model.generate(prompt, max_tokens=256)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6a9955;"># Parse rationale and final answer</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;rationale, final_answer = parse_response(response)<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#569cd6;">return</span> rationale, final_answer<br>
        </div>
      </div>
    </div>
</section>
</body>
</html>
