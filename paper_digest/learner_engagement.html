<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  // ç›´æ¥æ‰“å¼€PDFæ–‡ä»¶
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ arXiv 2024
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">A General Model for Detecting Learner Engagement: Implementation and Evaluation</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Somayeh Malekshahi, Javad M. Kheyridoost, Omid Fatemi<br>
        <span style="opacity:0.8">University of Tehran, Iran</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to develop a lightweight, general model that preserves temporal relationships in video sequences to detect learner engagement levels from facial expressions in e-learning environments?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•å¼€å‘ä¸€ä¸ªè½»é‡çº§ã€é€šç”¨çš„æ¨¡å‹ï¼Œåœ¨è§†é¢‘åºåˆ—ä¸­ä¿æŒæ—¶é—´å…³ç³»ï¼Œä»é¢éƒ¨è¡¨æƒ…åœ¨ç”µå­å­¦ä¹ ç¯å¢ƒä¸­æ£€æµ‹å­¦ä¹ è€…å‚ä¸åº¦æ°´å¹³ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>General Engagement Detection Framework:</b> Proposed a general, lightweight model for selecting and processing facial expression features to detect learner engagement levels while preserving sequential temporal relationships over time, handling variable-length video inputs effectively.</div>
            <div class="lang-zh" style="display:none"><b>é€šç”¨å‚ä¸åº¦æ£€æµ‹æ¡†æ¶ï¼š</b>æå‡ºä¸€ä¸ªé€šç”¨ã€è½»é‡çº§çš„æ¨¡å‹ï¼Œç”¨äºé€‰æ‹©å’Œå¤„ç†é¢éƒ¨è¡¨æƒ…ç‰¹å¾æ¥æ£€æµ‹å­¦ä¹ è€…å‚ä¸åº¦æ°´å¹³ï¼ŒåŒæ—¶ä¿æŒæ—¶é—´ä¸Šçš„é¡ºåºæ—¶é—´å…³ç³»ï¼Œæœ‰æ•ˆå¤„ç†å¯å˜é•¿åº¦çš„è§†é¢‘è¾“å…¥ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Adaptation Policy for Educational Context:</b> Developed an adaptation policy that utilizes affective states from the DAiSEE dataset to create new engagement labels, combining 'Engagement' and 'Confusion' states to improve model judgment specifically for educational scenarios.</div>
            <div class="lang-zh" style="display:none"><b>æ•™è‚²ä¸Šä¸‹æ–‡çš„é€‚åº”ç­–ç•¥ï¼š</b>å¼€å‘äº†ä¸€ä¸ªé€‚åº”ç­–ç•¥ï¼Œåˆ©ç”¨DAiSEEæ•°æ®é›†ä¸­çš„æƒ…æ„ŸçŠ¶æ€åˆ›å»ºæ–°çš„å‚ä¸åº¦æ ‡ç­¾ï¼Œç»“åˆ"å‚ä¸"å’Œ"å›°æƒ‘"çŠ¶æ€æ¥æ”¹å–„é’ˆå¯¹æ•™è‚²åœºæ™¯çš„æ¨¡å‹åˆ¤æ–­ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Competitive Performance with Statistical Models:</b> Achieved 68.57% accuracy using KNN classifier on balanced data, outperforming state-of-the-art models while using lightweight statistical approaches instead of complex deep learning architectures, demonstrating efficiency in resource-constrained e-learning environments.</div>
            <div class="lang-zh" style="display:none"><b>ç»Ÿè®¡æ¨¡å‹çš„ç«äº‰åŠ›ï¼š</b>ä½¿ç”¨KNNåˆ†ç±»å™¨åœ¨å¹³è¡¡æ•°æ®ä¸Šå®ç°äº†68.57%çš„å‡†ç¡®ç‡ï¼Œåœ¨ä½¿ç”¨è½»é‡çº§ç»Ÿè®¡æ–¹æ³•è€Œä¸æ˜¯å¤æ‚æ·±åº¦å­¦ä¹ æ¶æ„çš„åŒæ—¶è¶…è¶Šäº†æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œè¯æ˜äº†åœ¨èµ„æºå—é™çš„ç”µå­å­¦ä¹ ç¯å¢ƒä¸­çš„æ•ˆç‡ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Comprehensive Evaluation Framework:</b> Provided extensive evaluation on the DAiSEE dataset with multiple machine learning classifiers (KNN, XGBoost, MLP, SVM, Logistic Regression) and different affective state combinations, establishing a robust benchmark for learner engagement detection research.</div>
            <div class="lang-zh" style="display:none"><b>ç»¼åˆè¯„ä¼°æ¡†æ¶ï¼š</b>åœ¨DAiSEEæ•°æ®é›†ä¸Šä½¿ç”¨å¤šç§æœºå™¨å­¦ä¹ åˆ†ç±»å™¨(KNNã€XGBoostã€MLPã€SVMã€Logistic Regression)å’Œä¸åŒçš„æƒ…æ„ŸçŠ¶æ€ç»„åˆæä¾›äº†å¹¿æ³›çš„è¯„ä¼°ï¼Œä¸ºå­¦ä¹ è€…å‚ä¸åº¦æ£€æµ‹ç ”ç©¶å»ºç«‹äº†å¼ºå¤§çš„åŸºå‡†ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/learner_engagement_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('learner_engagement_arxiv2024.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('learner_engagement_arxiv2024.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Variable-Length Temporal Sequences:</b> Processing video sequences with varying frame counts while preserving sequential temporal dependencies, requiring methods to handle missing features and standardize input dimensions without losing critical temporal information.</div>
            <div class="lang-zh" style="display:none"><b>å¯å˜é•¿åº¦æ—¶é—´åºåˆ—ï¼š</b>åœ¨ä¿æŒé¡ºåºæ—¶é—´ä¾èµ–å…³ç³»çš„åŒæ—¶å¤„ç†å…·æœ‰ä¸åŒå¸§æ•°çš„è§†é¢‘åºåˆ—ï¼Œéœ€è¦æ–¹æ³•å¤„ç†ç¼ºå¤±ç‰¹å¾å¹¶æ ‡å‡†åŒ–è¾“å…¥ç»´åº¦è€Œä¸ä¸¢å¤±å…³é”®æ—¶é—´ä¿¡æ¯ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Imbalanced Dataset Adaptation:</b> Addressing class imbalance in affective state datasets like DAiSEE, where engagement levels are unevenly distributed, requiring adaptation policies that combine multiple affective states to create meaningful engagement labels for educational contexts.</div>
            <div class="lang-zh" style="display:none"><b>ä¸å¹³è¡¡æ•°æ®é›†é€‚åº”ï¼š</b>è§£å†³DAiSEEç­‰æƒ…æ„ŸçŠ¶æ€æ•°æ®é›†ä¸­çš„ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œå…¶ä¸­å‚ä¸åº¦æ°´å¹³åˆ†å¸ƒä¸å‡åŒ€ï¼Œéœ€è¦é€‚åº”ç­–ç•¥æ¥ç»“åˆå¤šç§æƒ…æ„ŸçŠ¶æ€ä¸ºæ•™è‚²ä¸Šä¸‹æ–‡åˆ›å»ºæœ‰æ„ä¹‰çš„å‚ä¸åº¦æ ‡ç­¾ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Real-Time Processing Requirements:</b> Developing lightweight models suitable for real-time engagement monitoring in synchronous e-learning environments, balancing accuracy with computational efficiency for practical deployment in educational settings.</div>
            <div class="lang-zh" style="display:none"><b>å®æ—¶å¤„ç†è¦æ±‚ï¼š</b>å¼€å‘é€‚åˆåŒæ­¥ç”µå­å­¦ä¹ ç¯å¢ƒä¸­å®æ—¶å‚ä¸åº¦ç›‘æ§çš„è½»é‡çº§æ¨¡å‹ï¼Œåœ¨å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œä»¥åœ¨æ•™è‚²ç¯å¢ƒä¸­è¿›è¡Œå®é™…éƒ¨ç½²ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Educational Context Relevance:</b> Creating engagement detection models that go beyond generic affective state recognition to incorporate educational psychology principles, considering how confusion and frustration can indicate engagement rather than disengagement in learning contexts.</div>
            <div class="lang-zh" style="display:none"><b>æ•™è‚²ä¸Šä¸‹æ–‡ç›¸å…³æ€§ï¼š</b>åˆ›å»ºè¶…è¶Šé€šç”¨æƒ…æ„ŸçŠ¶æ€è¯†åˆ«çš„å‚ä¸åº¦æ£€æµ‹æ¨¡å‹ï¼Œçº³å…¥æ•™è‚²å¿ƒç†å­¦åŸåˆ™ï¼Œè€ƒè™‘å›°æƒ‘å’ŒæŒ«è´¥å¦‚ä½•åœ¨å­¦ä¹ ä¸Šä¸‹æ–‡ä¸­è¡¨ç¤ºå‚ä¸åº¦è€Œä¸æ˜¯è„±ç¦»ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Feature Selection and Importance:</b> Identifying and weighting facial expression features that are most relevant to learner engagement, considering that not all emotional states contribute equally to engagement assessment in educational scenarios.</div>
            <div class="lang-zh" style="display:none"><b>ç‰¹å¾é€‰æ‹©å’Œé‡è¦æ€§ï¼š</b>è¯†åˆ«å’ŒåŠ æƒæœ€ç›¸å…³å­¦ä¹ è€…å‚ä¸åº¦çš„é¢éƒ¨è¡¨æƒ…ç‰¹å¾ï¼Œè€ƒè™‘å¹¶éæ‰€æœ‰æƒ…æ„ŸçŠ¶æ€åœ¨æ•™è‚²åœºæ™¯ä¸­çš„å‚ä¸åº¦è¯„ä¼°ä¸­è´¡çŒ®ç›¸ç­‰ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Sequential Feature Processing:</b> Implemented a general framework that processes variable-length video sequences by selecting representative frames and extracting 7-dimensional emotion vectors (happy, neutral, surprised, disgusted, angry, fearful, sad) using a pre-trained CNN emotion detector.</div>
            <div class="lang-zh" style="display:none"><b>é¡ºåºç‰¹å¾å¤„ç†ï¼š</b>å®ç°äº†ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œé€šè¿‡é€‰æ‹©ä»£è¡¨æ€§å¸§å¹¶ä½¿ç”¨é¢„è®­ç»ƒCNNæƒ…æ„Ÿæ£€æµ‹å™¨æå–7ç»´æƒ…æ„Ÿå‘é‡ï¼ˆå¿«ä¹ã€ä¸­æ€§ã€æƒŠè®¶ã€åŒæ¶ã€ç”Ÿæ°”ã€ææƒ§ã€æ‚²ä¼¤ï¼‰æ¥å¤„ç†å¯å˜é•¿åº¦è§†é¢‘åºåˆ—ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Emotion Weighting and Encoding:</b> Applied weighted encoding to emotion features based on their true positive rates (happy: 0.9, neutral: 0.8, surprised: 0.77, disgusted: 0.62, angry: 0.5, fearful: 0.37, sad: 0.28) to prioritize more reliable emotion detections in engagement assessment.</div>
            <div class="lang-zh" style="display:none"><b>æƒ…æ„ŸåŠ æƒå’Œç¼–ç ï¼š</b>æ ¹æ®çœŸå®é˜³æ€§ç‡å¯¹æƒ…æ„Ÿç‰¹å¾åº”ç”¨åŠ æƒç¼–ç ï¼ˆå¿«ä¹ï¼š0.9ï¼Œä¸­æ€§ï¼š0.8ï¼ŒæƒŠè®¶ï¼š0.77ï¼ŒåŒæ¶ï¼š0.62ï¼Œç”Ÿæ°”ï¼š0.5ï¼Œææƒ§ï¼š0.37ï¼Œæ‚²ä¼¤ï¼š0.28ï¼‰ï¼Œä»¥åœ¨å‚ä¸åº¦è¯„ä¼°ä¸­ä¼˜å…ˆè€ƒè™‘æ›´å¯é çš„æƒ…æ„Ÿæ£€æµ‹ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Educational Adaptation Policy:</b> Developed adaptation policies that combine multiple affective states from DAiSEE dataset (Engagement + Confusion, Engagement + Frustration, etc.) to create more educationally relevant engagement labels, recognizing that confusion can indicate engaged learning states.</div>
            <div class="lang-zh" style="display:none"><b>æ•™è‚²é€‚åº”ç­–ç•¥ï¼š</b>å¼€å‘é€‚åº”ç­–ç•¥ï¼Œç»“åˆDAiSEEæ•°æ®é›†ä¸­çš„å¤šç§æƒ…æ„ŸçŠ¶æ€ï¼ˆå‚ä¸+å›°æƒ‘ï¼Œå‚ä¸+æŒ«è´¥ç­‰ï¼‰æ¥åˆ›å»ºæ›´å…·æ•™è‚²ç›¸å…³æ€§çš„å‚ä¸åº¦æ ‡ç­¾ï¼Œè®¤è¯†åˆ°å›°æƒ‘å¯ä»¥è¡¨ç¤ºå‚ä¸çš„å­¦ä¹ çŠ¶æ€ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Statistical Classification Models:</b> Employed multiple machine learning classifiers (KNN, XGBoost, MLP, SVM, Logistic Regression) for engagement detection, with KNN achieving the best performance of 68.57% accuracy using the Engagement+Confusion adaptation policy.</div>
            <div class="lang-zh" style="display:none"><b>ç»Ÿè®¡åˆ†ç±»æ¨¡å‹ï¼š</b>ä½¿ç”¨å¤šç§æœºå™¨å­¦ä¹ åˆ†ç±»å™¨(KNNã€XGBoostã€MLPã€SVMã€Logistic Regression)è¿›è¡Œå‚ä¸åº¦æ£€æµ‹ï¼Œå…¶ä¸­KNNä½¿ç”¨å‚ä¸+å›°æƒ‘é€‚åº”ç­–ç•¥å®ç°äº†68.57%çš„æœ€ä½³æ€§èƒ½ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><div class="lang-en"><b>Data Balancing and Standardization:</b> Applied random under-sampling to balance imbalanced classes and standardization to normalize feature scales, ensuring robust performance across different affective state combinations and video lengths.</div>
            <div class="lang-zh" style="display:none"><b>æ•°æ®å¹³è¡¡å’Œæ ‡å‡†åŒ–ï¼š</b>åº”ç”¨éšæœºæ¬ é‡‡æ ·æ¥å¹³è¡¡ä¸å¹³è¡¡çš„ç±»åˆ«ï¼Œå¹¶åº”ç”¨æ ‡å‡†åŒ–æ¥è§„èŒƒåŒ–ç‰¹å¾å°ºåº¦ï¼Œç¡®ä¿åœ¨ä¸åŒçš„æƒ…æ„ŸçŠ¶æ€ç»„åˆå’Œè§†é¢‘é•¿åº¦ä¸­å®ç°ç¨³å¥æ€§èƒ½ã€‚</div>
          </li>
        </ol>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Educational Psychology Integration:</b> The work successfully bridges computer vision with educational psychology by recognizing that affective states like confusion and frustration can indicate engaged learning rather than disengagement, providing more nuanced engagement assessment for e-learning platforms.
            </div>
            <div class="lang-zh" style="display:none">
                <b>Educational Psychology Integration:</b>è¿™é¡¹å·¥ä½œé€šè¿‡è®¤è¯†åˆ°æƒ…æ„ŸçŠ¶æ€å¦‚å›°æƒ‘å’ŒæŒ«è´¥å¯ä»¥è¡¨ç¤ºå‚ä¸çš„å­¦ä¹ è€Œä¸æ˜¯è„±ç¦»ï¼ŒæˆåŠŸåœ°å°†è®¡ç®—æœºè§†è§‰ä¸æ•™è‚²å¿ƒç†å­¦ç›¸ç»“åˆï¼Œä¸ºç”µå­å­¦ä¹ å¹³å°æä¾›äº†æ›´ç»†è‡´çš„å‚ä¸åº¦è¯„ä¼°ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Lightweight vs. Deep Learning Trade-off:</b> Demonstrates that statistical machine learning approaches can achieve competitive performance compared to complex deep architectures, offering practical advantages for deployment in resource-constrained educational environments.
            </div>
            <div class="lang-zh" style="display:none">
                <b>Lightweight vs. Deep Learning Trade-off:</b>è¯æ˜ç»Ÿè®¡æœºå™¨å­¦ä¹ æ–¹æ³•å¯ä»¥æ¯”å¤æ‚æ·±åº¦æ¶æ„å®ç°ç«äº‰åŠ›ï¼Œä¸ºåœ¨èµ„æºå—é™çš„æ•™è‚²ç¯å¢ƒä¸­éƒ¨ç½²æä¾›äº†å®é™…ä¼˜åŠ¿ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Temporal Processing Importance:</b> Emphasizes the critical role of preserving temporal relationships in video sequences, showing that frame-level averaging alone is insufficient for capturing the dynamic nature of learner engagement over time.
            </div>
            <div class="lang-zh" style="display:none">
                <b>Temporal Processing Importance:</b>å¼ºè°ƒåœ¨è§†é¢‘åºåˆ—ä¸­ä¿æŒæ—¶é—´å…³ç³»çš„å…³é”®ä½œç”¨ï¼Œè¡¨æ˜ä»…å¸§çº§å¹³å‡ä¸è¶³ä»¥æ•æ‰å­¦ä¹ è€…å‚ä¸åº¦éšæ—¶é—´å˜åŒ–çš„åŠ¨æ€æ€§è´¨ã€‚
            </div>
          </li>
        </ul>

        <div style="margin-top:16px; padding-top:12px; border-top:1px dashed rgba(255,255,255,.15);">
             <h3 style="margin:0 0 6px; font-size:14px; color:#8bffcf;">
               <span class="lang-en">High-Level Insights: Why it Works?</span>
               <span class="lang-zh" style="display:none">é«˜å±‚æ´å¯Ÿï¼šä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ</span>
             </h3>
             <div class="lang-en" style="color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                It works because the model combines computer vision feature extraction with educational psychology principles, recognizing that engagement is a complex temporal phenomenon that requires both technical processing and domain knowledge to interpret affective states correctly in learning contexts.
             </div>
             <div class="lang-zh" style="display:none; color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºè¯¥æ¨¡å‹å°†è®¡ç®—æœºè§†è§‰ç‰¹å¾æå–ä¸æ•™è‚²å¿ƒç†å­¦åŸç†ç›¸ç»“åˆï¼Œè®¤è¯†åˆ°å‚ä¸åº¦æ˜¯ä¸€ä¸ªå¤æ‚çš„æ—¶é—´ç°è±¡ï¼Œéœ€è¦æŠ€æœ¯å’Œé¢†åŸŸçŸ¥è¯†æ¥åœ¨å­¦ä¹ ä¸Šä¸‹æ–‡ä¸­æ­£ç¡®è§£é‡Šæƒ…æ„ŸçŠ¶æ€ã€‚
             </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            This paper presents a general, lightweight model for detecting learner engagement levels from facial expressions in e-learning videos. By preserving temporal relationships and implementing an adaptation policy that combines affective states relevant to education, the model achieves 68.57% accuracy using KNN classification. The approach demonstrates that statistical machine learning methods can compete with complex deep learning architectures while offering practical advantages for real-time deployment in educational environments.
          </div>
          <div class="lang-zh" style="display:none">
            æœ¬æ–‡æå‡ºä¸€ä¸ªé€šç”¨ã€è½»é‡çº§çš„æ¨¡å‹ï¼Œç”¨äºä»ç”µå­å­¦ä¹ è§†é¢‘ä¸­çš„é¢éƒ¨è¡¨æƒ…æ£€æµ‹å­¦ä¹ è€…å‚ä¸åº¦æ°´å¹³ã€‚é€šè¿‡ä¿æŒæ—¶é—´å…³ç³»å¹¶å®æ–½ç»“åˆæ•™è‚²ç›¸å…³æƒ…æ„ŸçŠ¶æ€çš„é€‚åº”ç­–ç•¥ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨KNNåˆ†ç±»å®ç°äº†68.57%çš„å‡†ç¡®ç‡ã€‚è¯¥æ–¹æ³•è¯æ˜ç»Ÿè®¡æœºå™¨å­¦ä¹ æ–¹æ³•å¯ä»¥ä¸å¤æ‚æ·±åº¦å­¦ä¹ æ¶æ„ç«äº‰ï¼ŒåŒæ—¶ä¸ºæ•™è‚²ç¯å¢ƒä¸­çš„å®æ—¶éƒ¨ç½²æä¾›å®é™…ä¼˜åŠ¿ã€‚
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Links:</h2>
        <a href="https://arxiv.org/abs/2405.04251" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          arXiv
        </a>
      </div>
    </div>
</section>
</body>
</html>
