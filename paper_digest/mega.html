<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  // ç›´æ¥æ‰“å¼€PDFæ–‡ä»¶
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ CVPR 2025
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">MEGA: Masked Generative Autoencoder for Human Mesh Recovery</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        GuÃ©nolÃ© Fiche, Simon Leglaive, Xavier Alameda-Pineda, Francesc Moreno-Noguer<br>
        <span style="opacity:0.8">CentraleSupÃ©lec, Naver Labs Europe, Inria, Univ. Grenoble Alpes, CNRS, LJK, Amazon</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to develop a flexible human mesh recovery framework that addresses the inherent ambiguity of single-image HMR by supporting both deterministic single-output predictions and stochastic multi-output generation while achieving state-of-the-art performance in both modes?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•å¼€å‘ä¸€ä¸ªçµæ´»çš„äººç±»ç½‘æ ¼æ¢å¤æ¡†æ¶ï¼Œé€šè¿‡æ”¯æŒç¡®å®šæ€§å•è¾“å‡ºé¢„æµ‹å’Œéšæœºå¤šè¾“å‡ºç”Ÿæˆæ¥è§£å†³å•å›¾åƒHMRçš„å›ºæœ‰æ¨¡ç³Šæ€§ï¼ŒåŒæ—¶åœ¨ä¸¤ç§æ¨¡å¼ä¸‹éƒ½å®ç°æœ€å…ˆè¿›æ€§èƒ½ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Masked Generative Autoencoder:</b> Introduced MEGA, the first masked generative autoencoder for human mesh recovery that leverages self-supervised learning on motion capture data to learn prior knowledge about 3D humans without requiring paired image data.</div>
            <div class="lang-zh" style="display:none"><b>æ©ç ç”Ÿæˆè‡ªç¼–ç å™¨ï¼š</b>å¼•å…¥äº†MEGAï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºäººç±»ç½‘æ ¼æ¢å¤çš„æ©ç ç”Ÿæˆè‡ªç¼–ç å™¨ï¼Œåˆ©ç”¨è¿åŠ¨æ•æ‰æ•°æ®ä¸Šçš„è‡ªç›‘ç£å­¦ä¹ æ¥å­¦ä¹ å…³äº3Däººç±»çš„å…ˆéªŒçŸ¥è¯†ï¼Œè€Œæ— éœ€é…å¯¹å›¾åƒæ•°æ®ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Flexible Inference Modes:</b> Developed dual inference paradigms - deterministic mode for fast single-output predictions and stochastic mode for generating multiple diverse human mesh predictions, addressing the ill-posed nature of single-image HMR.</div>
            <div class="lang-zh" style="display:none"><b>çµæ´»æ¨ç†æ¨¡å¼ï¼š</b>å¼€å‘äº†åŒé‡æ¨ç†èŒƒå¼ - ç¡®å®šæ€§æ¨¡å¼ç”¨äºå¿«é€Ÿå•è¾“å‡ºé¢„æµ‹ï¼Œéšæœºæ¨¡å¼ç”¨äºç”Ÿæˆå¤šä¸ªå¤šæ ·åŒ–çš„äººä½“ç½‘æ ¼é¢„æµ‹ï¼Œè§£å†³äº†å•å›¾åƒHMRçš„ä¸é€‚å®šæ€§è´¨ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Human Mesh Tokenization:</b> Pioneered the use of tokenized human mesh representations (via Mesh-VQ-VAE) for masked generative modeling, enabling straightforward masking and iterative generation of anthropomorphic meshes.</div>
            <div class="lang-zh" style="display:none"><b>äººç±»ç½‘æ ¼tokenåŒ–ï¼š</b>å¼€åˆ›æ€§åœ°ä½¿ç”¨tokenåŒ–äººç±»ç½‘æ ¼è¡¨ç¤ºï¼ˆé€šè¿‡Mesh-VQ-VAEï¼‰è¿›è¡Œæ©ç ç”Ÿæˆå»ºæ¨¡ï¼Œå®ç°å¯¹æ‹Ÿäººç½‘æ ¼çš„ç›´æ¥æ©ç å’Œè¿­ä»£ç”Ÿæˆã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>State-of-the-Art Performance:</b> Achieved superior results in both deterministic and stochastic modes, outperforming single-output methods with single predictions and significantly improving performance with multiple samples on in-the-wild benchmarks.</div>
            <div class="lang-zh" style="display:none"><b>æœ€å…ˆè¿›æ€§èƒ½ï¼š</b>åœ¨ç¡®å®šæ€§å’Œéšæœºæ¨¡å¼ä¸‹éƒ½å®ç°äº†å“è¶Šç»“æœï¼Œåœ¨å•é¢„æµ‹çš„æƒ…å†µä¸‹è¶…è¶Šå•è¾“å‡ºæ–¹æ³•ï¼Œå¹¶åœ¨å¤šæ ·æœ¬æƒ…å†µä¸‹æ˜¾è‘—æå‡æ€§èƒ½ï¼Œåœ¨é‡å¤–åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆå¼•è¨€ç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/mega_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('mega_cvpr2025.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('mega_cvpr2025.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/mega_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('mega_cvpr2025.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('mega_cvpr2025.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Inherent Ambiguity of Single-Image HMR:</b> A single 2D image cannot provide sufficient information to uniquely determine a 3D human mesh due to depth ambiguity, especially with occlusions, causing single-output models to produce biased predictions toward common poses and shapes.</div>
            <div class="lang-zh" style="display:none"><b>å•å›¾åƒHMRçš„å›ºæœ‰æ¨¡ç³Šæ€§ï¼š</b>å•ä¸ª2Då›¾åƒæ— æ³•æä¾›è¶³å¤Ÿçš„ä¿¡æ¯æ¥å”¯ä¸€ç¡®å®š3Däººä½“ç½‘æ ¼ï¼Œç”±äºæ·±åº¦æ¨¡ç³Šæ€§ï¼Œç‰¹åˆ«æ˜¯é®æŒ¡ï¼Œå¯¼è‡´å•è¾“å‡ºæ¨¡å‹äº§ç”Ÿåå‘å¸¸è§å§¿åŠ¿å’Œå½¢çŠ¶çš„é¢„æµ‹ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Accuracy vs. Diversity Trade-off:</b> Existing probabilistic approaches achieve diversity at the cost of accuracy, while deterministic methods provide high accuracy but lack the ability to represent multiple plausible interpretations of the same image.</div>
            <div class="lang-zh" style="display:none"><b>å‡†ç¡®æ€§ä¸å¤šæ ·æ€§æƒè¡¡ï¼š</b>ç°æœ‰çš„æ¦‚ç‡æ–¹æ³•ä»¥å‡†ç¡®æ€§ä¸ºä»£ä»·å®ç°å¤šæ ·æ€§ï¼Œè€Œç¡®å®šæ€§æ–¹æ³•æä¾›é«˜å‡†ç¡®æ€§ä½†ç¼ºä¹è¡¨ç¤ºåŒä¸€å›¾åƒå¤šä¸ªåˆç†è§£é‡Šçš„èƒ½åŠ›ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Limited Training Data:</b> HMR models typically require paired image-mesh data, but obtaining high-quality 3D annotations is expensive and time-consuming, limiting the model's ability to learn comprehensive human pose and shape priors.</div>
            <div class="lang-zh" style="display:none"><b>è®­ç»ƒæ•°æ®æœ‰é™ï¼š</b>HMRæ¨¡å‹é€šå¸¸éœ€è¦é…å¯¹çš„å›¾åƒ-ç½‘æ ¼æ•°æ®ï¼Œä½†è·å¾—é«˜è´¨é‡3Dæ ‡æ³¨æ˜¯æ˜‚è´µä¸”è€—æ—¶çš„ï¼Œé™åˆ¶äº†æ¨¡å‹å­¦ä¹ å…¨é¢äººä½“å§¿åŠ¿å’Œå½¢çŠ¶å…ˆéªŒçš„èƒ½åŠ›ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Discrete Representation Challenges:</b> Tokenizing continuous human meshes into discrete representations while preserving anthropomorphic properties and enabling generative modeling is non-trivial and requires sophisticated architectures.</div>
            <div class="lang-zh" style="display:none"><b>ç¦»æ•£è¡¨ç¤ºæŒ‘æˆ˜ï¼š</b>å°†è¿ç»­äººä½“ç½‘æ ¼tokenåŒ–ä¸ºç¦»æ•£è¡¨ç¤ºï¼ŒåŒæ—¶ä¿ç•™æ‹Ÿäººç‰¹æ€§å¹¶å®ç°ç”Ÿæˆå»ºæ¨¡æ˜¯å¤æ‚çš„ï¼Œéœ€è¦å¤æ‚çš„æ¶æ„ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Computational Efficiency:</b> Generating multiple predictions should not significantly increase inference time, requiring efficient sampling strategies and model architectures that balance computational cost with prediction quality.</div>
            <div class="lang-zh" style="display:none"><b>è®¡ç®—æ•ˆç‡ï¼š</b>ç”Ÿæˆå¤šä¸ªé¢„æµ‹ä¸åº”æ˜¾è‘—å¢åŠ æ¨ç†æ—¶é—´ï¼Œéœ€è¦é«˜æ•ˆçš„é‡‡æ ·ç­–ç•¥å’Œå¹³è¡¡è®¡ç®—æˆæœ¬ä¸é¢„æµ‹è´¨é‡çš„æ¨¡å‹æ¶æ„ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Human Mesh Tokenization:</b> Leveraged Mesh-VQ-VAE to encode/decode 3D human meshes into/from discrete token sequences, enabling generative modeling while constraining predictions to anthropomorphic meshes.</div>
            <div class="lang-zh" style="display:none"><b>äººç±»ç½‘æ ¼tokenåŒ–ï¼š</b>åˆ©ç”¨Mesh-VQ-VAEå°†3Däººä½“ç½‘æ ¼ç¼–ç /è§£ç ä¸ºç¦»æ•£tokenåºåˆ—ï¼Œå®ç°ç”Ÿæˆå»ºæ¨¡ï¼ŒåŒæ—¶å°†é¢„æµ‹é™åˆ¶ä¸ºæ‹Ÿäººç½‘æ ¼ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Self-Supervised Pre-training:</b> Pre-trained MEGA on motion capture data using masked autoencoder strategy to reconstruct partially visible mesh tokens, learning comprehensive 3D human priors without paired image data.</div>
            <div class="lang-zh" style="display:none"><b>è‡ªç›‘ç£é¢„è®­ç»ƒï¼š</b>ä½¿ç”¨æ©ç è‡ªç¼–ç å™¨ç­–ç•¥åœ¨è¿åŠ¨æ•æ‰æ•°æ®ä¸Šé¢„è®­ç»ƒMEGAä»¥é‡å»ºéƒ¨åˆ†å¯è§çš„ç½‘æ ¼tokenï¼Œåœ¨æ²¡æœ‰é…å¯¹å›¾åƒæ•°æ®çš„æƒ…å†µä¸‹å­¦ä¹ å…¨é¢çš„3Däººç±»å…ˆéªŒã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Masked Generative Modeling:</b> Formulated HMR as generating discrete mesh token sequences conditioned on image embeddings, using a Transformer encoder-decoder architecture with progressive masking strategies.</div>
            <div class="lang-zh" style="display:none"><b>æ©ç ç”Ÿæˆå»ºæ¨¡ï¼š</b>å°†HMRè¡¨è¿°ä¸ºåœ¨å›¾åƒåµŒå…¥æ¡ä»¶ä¸‹ç”Ÿæˆç¦»æ•£ç½‘æ ¼tokenåºåˆ—ï¼Œä½¿ç”¨å…·æœ‰æ¸è¿›æ©ç ç­–ç•¥çš„Transformerç¼–ç å™¨-è§£ç å™¨æ¶æ„ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Dual Inference Modes:</b> Implemented deterministic mode for single forward-pass predictions and stochastic mode with iterative token sampling for generating multiple diverse mesh interpretations from the same image.</div>
            <div class="lang-zh" style="display:none"><b>åŒé‡æ¨ç†æ¨¡å¼ï¼š</b>å®ç°äº†ç¡®å®šæ€§æ¨¡å¼ç”¨äºå•æ¬¡å‰å‘ä¼ é€’é¢„æµ‹ï¼Œä»¥åŠéšæœºæ¨¡å¼ä¸è¿­ä»£tokené‡‡æ ·ï¼Œç”¨äºä»åŒä¸€å›¾åƒç”Ÿæˆå¤šä¸ªå¤šæ ·åŒ–ç½‘æ ¼è§£é‡Šã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Unified Training Strategy:</b> Used cross-entropy loss for both pre-training and supervised training stages, supplemented with rotation and camera parameter prediction for complete 3D pose estimation.</div>
            <div class="lang-zh" style="display:none"><b>ç»Ÿä¸€è®­ç»ƒç­–ç•¥ï¼š</b>å¯¹é¢„è®­ç»ƒå’Œç›‘ç£è®­ç»ƒé˜¶æ®µéƒ½ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼Œå¹¶è¡¥å……æ—‹è½¬å’Œç›¸æœºå‚æ•°é¢„æµ‹ä»¥è¿›è¡Œå®Œæ•´çš„3Då§¿åŠ¿ä¼°è®¡ã€‚</div>
          </li>
        </ol>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Tokenization as a Bridge:</b> The use of discrete mesh tokens provides a powerful interface between continuous 3D geometry and sequence-based generative models, enabling the application of advanced language modeling techniques to geometric reconstruction tasks.
            </div>
            <div class="lang-zh" style="display:none">
                <b>TokenåŒ–ä½œä¸ºæ¡¥æ¢ï¼š</b>ç¦»æ•£ç½‘æ ¼tokençš„ä½¿ç”¨æä¾›äº†è¿ç»­3Då‡ ä½•ä¸åŸºäºåºåˆ—çš„ç”Ÿæˆæ¨¡å‹ä¹‹é—´çš„å¼ºå¤§æ¥å£ï¼Œä½¿é«˜çº§è¯­è¨€å»ºæ¨¡æŠ€æœ¯èƒ½å¤Ÿåº”ç”¨äºå‡ ä½•é‡å»ºä»»åŠ¡ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Self-Supervised Learning Benefits:</b> Pre-training on unlabeled motion capture data allows MEGA to capture rich human pose priors, significantly improving generalization and reducing the need for extensive paired image-mesh datasets.
            </div>
            <div class="lang-zh" style="display:none">
                <b>è‡ªç›‘ç£å­¦ä¹ ä¼˜åŠ¿ï¼š</b>åœ¨æœªæ ‡è®°è¿åŠ¨æ•æ‰æ•°æ®ä¸Šçš„é¢„è®­ç»ƒå…è®¸MEGAæ•è·ä¸°å¯Œçš„äººä½“å§¿åŠ¿å…ˆéªŒï¼Œæ˜¾è‘—æå‡æ³›åŒ–èƒ½åŠ›å¹¶å‡å°‘å¯¹å¹¿æ³›é…å¯¹å›¾åƒ-ç½‘æ ¼æ•°æ®é›†çš„éœ€æ±‚ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Flexible Generation Paradigm:</b> The dual-mode inference capability addresses the fundamental ambiguity of monocular HMR, allowing users to choose between speed and diversity based on specific application requirements.
            </div>
            <div class="lang-zh" style="display:none">
                <b>çµæ´»ç”ŸæˆèŒƒå¼ï¼š</b>åŒæ¨¡å¼æ¨ç†èƒ½åŠ›è§£å†³äº†å•ç›®HMRçš„åŸºæœ¬æ¨¡ç³Šæ€§ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®ç‰¹å®šåº”ç”¨éœ€æ±‚åœ¨é€Ÿåº¦å’Œå¤šæ ·æ€§ä¹‹é—´è¿›è¡Œé€‰æ‹©ã€‚
            </div>
          </li>
        </ul>

        <div style="margin-top:16px; padding-top:12px; border-top:1px dashed rgba(255,255,255,.15);">
             <h3 style="margin:0 0 6px; font-size:14px; color:#8bffcf;">
               <span class="lang-en">High-Level Insights: Why it Works?</span>
               <span class="lang-zh" style="display:none">é«˜å±‚æ´å¯Ÿï¼šä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ</span>
             </h3>
             <div class="lang-en" style="color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                It works because MEGA bridges the gap between discrete sequence modeling and continuous geometric reconstruction by tokenizing human meshes, enabling powerful generative capabilities while maintaining anthropomorphic constraints. The self-supervised pre-training on motion capture data provides rich priors that guide accurate predictions even from ambiguous 2D observations.
             </div>
             <div class="lang-zh" style="display:none; color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºMEGAé€šè¿‡tokenåŒ–äººä½“ç½‘æ ¼å¼¥åˆäº†ç¦»æ•£åºåˆ—å»ºæ¨¡ä¸è¿ç»­å‡ ä½•é‡å»ºä¹‹é—´çš„å·®è·ï¼Œå®ç°å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›åŒæ—¶ä¿æŒæ‹Ÿäººçº¦æŸã€‚è‡ªç›‘ç£é¢„è®­ç»ƒåœ¨è¿åŠ¨æ•æ‰æ•°æ®ä¸Šæä¾›äº†ä¸°å¯Œçš„å…ˆéªŒï¼Œå³ä½¿ä»æ¨¡ç³Šçš„2Dè§‚æµ‹ä¸­ä¹Ÿèƒ½æŒ‡å¯¼å‡†ç¡®é¢„æµ‹ã€‚
             </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            This paper introduces MEGA, a novel masked generative autoencoder that addresses the fundamental ambiguity of human mesh recovery from single images through dual inference modes. By tokenizing human meshes and leveraging self-supervised learning on motion capture data, MEGA achieves state-of-the-art performance in both deterministic and stochastic settings. The framework's ability to generate multiple plausible interpretations while maintaining high accuracy opens new possibilities for applications requiring diverse human pose predictions. Experiments on in-the-wild benchmarks demonstrate superior performance, with MEGA significantly outperforming previous methods in multi-output scenarios while remaining competitive in single-output mode.
          </div>
          <div class="lang-zh" style="display:none">
            æœ¬æ–‡ä»‹ç»äº†MEGAï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ©ç ç”Ÿæˆè‡ªç¼–ç å™¨ï¼Œé€šè¿‡åŒé‡æ¨ç†æ¨¡å¼è§£å†³äº†ä»å•å›¾åƒè¿›è¡Œäººç±»ç½‘æ ¼æ¢å¤çš„åŸºæœ¬æ¨¡ç³Šæ€§ã€‚é€šè¿‡tokenåŒ–äººä½“ç½‘æ ¼å¹¶åˆ©ç”¨è¿åŠ¨æ•æ‰æ•°æ®ä¸Šçš„è‡ªç›‘ç£å­¦ä¹ ï¼ŒMEGAåœ¨ç¡®å®šæ€§å’Œéšæœºè®¾ç½®ä¸­éƒ½å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶åœ¨ä¿æŒé«˜å‡†ç¡®æ€§çš„åŒæ—¶ç”Ÿæˆå¤šä¸ªåˆç†è§£é‡Šçš„èƒ½åŠ›ä¸ºéœ€è¦å¤šæ ·åŒ–äººä½“å§¿åŠ¿é¢„æµ‹çš„åº”ç”¨å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚åœ¨é‡å¤–åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒå±•ç¤ºäº†å“è¶Šæ€§èƒ½ï¼ŒMEGAåœ¨å¤šè¾“å‡ºåœºæ™¯ä¸­æ˜¾è‘—è¶…è¶Šäº†ä»¥å‰çš„æ–¹æ³•ï¼ŒåŒæ—¶åœ¨å•è¾“å‡ºæ¨¡å¼ä¸­ä¿æŒç«äº‰åŠ›ã€‚
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Links:</h2>
        <a href="https://github.com/g-fiche/MEGA" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          Project Page
        </a>
      </div>
    </div>
</section>
</body>
</html>
