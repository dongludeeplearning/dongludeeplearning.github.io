<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius: 16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  // ç›´æ¥æ‰“å¼€PDFæ–‡ä»¶
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ NeurIPS 2022
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">HUMANISE: Language-conditioned Human Motion Generation in 3D Scenes</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Zan Wang, Yixin Chen, Tengyu Liu, Yixin Zhu, Wei Liang, Siyuan Huang<br>
        <span style="opacity:0.8">Beijing Institute of Technology, BIGAI, Peking University</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to generate diverse, scene-aware, and goal-oriented human motions in 3D scenes conditioned on natural language descriptions?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•åŸºäºè‡ªç„¶è¯­è¨€æè¿°åœ¨3Dåœºæ™¯ä¸­ç”Ÿæˆå¤šæ ·åŒ–ã€åœºæ™¯æ„ŸçŸ¥å’Œç›®æ ‡å¯¼å‘çš„äººç±»è¿åŠ¨ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>HUMANISE Dataset Creation:</b> Large-scale synthetic HSI dataset containing 19.6k motion sequences in 643 indoor scenes, created by aligning high-quality AMASS motions with ScanNet scenes using collision and contact constraints.</div>
            <div class="lang-zh" style="display:none"><b>HUMANISEæ•°æ®é›†åˆ›å»ºï¼š</b>å¤§è§„æ¨¡åˆæˆHSIæ•°æ®é›†ï¼ŒåŒ…å«643ä¸ªå®¤å†…åœºæ™¯ä¸­çš„19.6kè¿åŠ¨åºåˆ—ï¼Œé€šè¿‡ä½¿ç”¨ç¢°æ’å’Œæ¥è§¦çº¦æŸå°†é«˜è´¨é‡AMASSè¿åŠ¨ä¸ScanNetåœºæ™¯å¯¹é½åˆ›å»ºã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Automatic Language Annotation:</b> Template-based automatic generation of language descriptions depicting action types and interacting objects, enabling semantic understanding of human-scene interactions.</div>
            <div class="lang-zh" style="display:none"><b>è‡ªåŠ¨è¯­è¨€æ ‡æ³¨ï¼š</b>åŸºäºæ¨¡æ¿çš„è‡ªåŠ¨ç”Ÿæˆæè¿°åŠ¨ä½œç±»å‹å’Œäº¤äº’å¯¹è±¡çš„è¯­è¨€æè¿°ï¼Œå®ç°å¯¹äººç±»-åœºæ™¯äº¤äº’çš„è¯­ä¹‰ç†è§£ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Language-Conditioned Motion Generation Task:</b> Novel task requiring joint modeling of 3D scenes, human motions, and natural language, with challenges in multi-modal understanding and physical plausibility.</div>
            <div class="lang-zh" style="display:none"><b>è¯­è¨€æ¡ä»¶è¿åŠ¨ç”Ÿæˆä»»åŠ¡ï¼š</b>æ–°é¢–ä»»åŠ¡éœ€è¦è”åˆå»ºæ¨¡3Dåœºæ™¯ã€äººç±»è¿åŠ¨å’Œè‡ªç„¶è¯­è¨€ï¼Œé¢ä¸´å¤šæ¨¡æ€ç†è§£å’Œç‰©ç†åˆç†æ€§çš„æŒ‘æˆ˜ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Scene-and-Language Conditioned Model:</b> cVAE-based generative model with condition module for joint embedding of scenes and language, motion encoder/decoder for sequence generation, and auxiliary tasks for object grounding and action recognition.</div>
            <div class="lang-zh" style="display:none"><b>åœºæ™¯å’Œè¯­è¨€æ¡ä»¶æ¨¡å‹ï¼š</b>åŸºäºcVAEçš„ç”Ÿæˆæ¨¡å‹ï¼Œå…·æœ‰ç”¨äºåœºæ™¯å’Œè¯­è¨€è”åˆåµŒå…¥çš„æ¡ä»¶æ¨¡å—ã€ç”¨äºåºåˆ—ç”Ÿæˆçš„è¿åŠ¨ç¼–ç å™¨/è§£ç å™¨ï¼Œä»¥åŠç”¨äºå¯¹è±¡å®šä½å’ŒåŠ¨ä½œè¯†åˆ«çš„è¾…åŠ©ä»»åŠ¡ã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Diverse Affordance Modeling:</b> Framework that handles diverse human-object interactions including unconventional cases (e.g., lying on office tables, sitting on toilets), encoding meaningful scene affordances for realistic HSI generation.</div>
            <div class="lang-zh" style="display:none"><b>å¤šæ ·åŒ–å¯åŠæ€§å»ºæ¨¡ï¼š</b>å¤„ç†å¤šæ ·åŒ–äººç±»-ç‰©ä½“äº¤äº’çš„æ¡†æ¶ï¼ŒåŒ…æ‹¬éå¸¸è§„æƒ…å†µï¼ˆä¾‹å¦‚èººåœ¨åŠå…¬æ¡Œä¸Šã€ååœ¨é©¬æ¡¶ä¸Šï¼‰ï¼Œä¸ºçœŸå®HSIç”Ÿæˆç¼–ç æœ‰æ„ä¹‰çš„åœºæ™¯å¯åŠæ€§ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆç¤ºä¾‹ï¼‰</h2>
        <div style="border-radius:14px; overflow:hidden;">
             <img src="Figures/humanise_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Limited Scale and Quality of HSI Datasets:</b> Existing datasets like PROX and GTA-IM have small scale, low quality, and lack semantic annotations for instruction-aware motion generation.</div>
            <div class="lang-zh" style="display:none"><b>HSIæ•°æ®é›†çš„è§„æ¨¡å’Œè´¨é‡æœ‰é™ï¼š</b>ç°æœ‰æ•°æ®é›†å¦‚PROXå’ŒGTA-IMè§„æ¨¡å°ã€è´¨é‡ä½ï¼Œå¹¶ä¸”ç¼ºä¹ç”¨äºæŒ‡ä»¤æ„ŸçŸ¥è¿åŠ¨ç”Ÿæˆçš„è¯­ä¹‰æ ‡æ³¨ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multi-Modal Joint Modeling:</b> Difficulty in simultaneously understanding and integrating 3D scene geometry, human motion dynamics, and natural language semantics for coherent generation.</div>
            <div class="lang-zh" style="display:none"><b>å¤šæ¨¡æ€è”åˆå»ºæ¨¡ï¼š</b>éš¾ä»¥åŒæ—¶ç†è§£å’Œæ•´åˆ3Dåœºæ™¯å‡ ä½•ã€äººä½“è¿åŠ¨åŠ¨åŠ›å­¦å’Œè‡ªç„¶è¯­è¨€è¯­ä¹‰ä»¥å®ç°è¿è´¯ç”Ÿæˆã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Language Grounding in 3D Scenes:</b> Challenge of precisely locating and grounding target objects in complex 3D environments based on referential language descriptions with spatial relations.</div>
            <div class="lang-zh" style="display:none"><b>3Dåœºæ™¯ä¸­çš„è¯­è¨€å®šä½ï¼š</b>åŸºäºå…·æœ‰ç©ºé—´å…³ç³»çš„æŒ‡ç§°æ€§è¯­è¨€æè¿°ï¼Œåœ¨å¤æ‚3Dç¯å¢ƒä¸­ç²¾ç¡®å®šä½å’Œå®šä½ç›®æ ‡å¯¹è±¡çš„æŒ‘æˆ˜ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Physical Plausibility with Semantic Consistency:</b> Ensuring generated motions are both physically realistic within 3D scenes and semantically faithful to specified actions and object interactions.</div>
            <div class="lang-zh" style="display:none"><b>è¯­ä¹‰ä¸€è‡´æ€§çš„ç‰©ç†åˆç†æ€§ï¼š</b>ç¡®ä¿ç”Ÿæˆçš„è¿åŠ¨åœ¨3Dåœºæ™¯ä¸­ç‰©ç†ä¸ŠçœŸå®ï¼ŒåŒæ—¶å¯¹æŒ‡å®šçš„åŠ¨ä½œå’Œç‰©ä½“äº¤äº’è¯­ä¹‰ä¸Šå¿ å®ã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Diverse Affordance Handling:</b> Modeling unconventional human-object interactions that go beyond typical daily activities, requiring understanding of object affordances and interaction possibilities.</div>
            <div class="lang-zh" style="display:none"><b>å¤šæ ·åŒ–å¯åŠæ€§å¤„ç†ï¼š</b>å»ºæ¨¡è¶…è¶Šå…¸å‹æ—¥å¸¸æ´»åŠ¨çš„éå¸¸è§„äººç±»-ç‰©ä½“äº¤äº’ï¼Œéœ€è¦ç†è§£ç‰©ä½“å¯åŠæ€§å’Œäº¤äº’å¯èƒ½æ€§ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Motion-Scene Alignment Pipeline:</b> Automatic synthesis of HSI by sampling interacting objects, positions, and valid transformations using collision constraints (k-d tree distance checking) and action-specific contact constraints for realistic interactions.</div>
            <div class="lang-zh" style="display:none"><b>è¿åŠ¨-åœºæ™¯å¯¹é½æµæ°´çº¿ï¼š</b>é€šè¿‡é‡‡æ ·äº¤äº’å¯¹è±¡ã€ä½ç½®å’Œæœ‰æ•ˆå˜æ¢ï¼Œä½¿ç”¨ç¢°æ’çº¦æŸï¼ˆk-dæ ‘è·ç¦»æ£€æŸ¥ï¼‰å’ŒåŠ¨ä½œç‰¹å®šæ¥è§¦çº¦æŸè‡ªåŠ¨åˆæˆHSIï¼Œå®ç°çœŸå®äº¤äº’ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Template-Based Language Generation:</b> Compositional templates following Sr3D format to generate language descriptions with action, target object, and optional spatial relations to uniquely refer to interacting objects in scenes.</div>
            <div class="lang-zh" style="display:none"><b>åŸºäºæ¨¡æ¿çš„è¯­è¨€ç”Ÿæˆï¼š</b>éµå¾ªSr3Dæ ¼å¼çš„ç»„åˆæ¨¡æ¿ï¼Œç”ŸæˆåŒ…å«åŠ¨ä½œã€ç›®æ ‡å¯¹è±¡å’Œå¯é€‰ç©ºé—´å…³ç³»çš„è¯­è¨€æè¿°ï¼Œä»¥å”¯ä¸€æŒ‡ä»£åœºæ™¯ä¸­çš„äº¤äº’å¯¹è±¡ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>cVAE Framework with Condition Module:</b> Conditional VAE architecture with joint embedding of 3D scenes (Point Transformer) and language (BERT) through self-attention fusion for multi-modal conditional generation.</div>
            <div class="lang-zh" style="display:none"><b>å¸¦æ¡ä»¶æ¨¡å—çš„cVAEæ¡†æ¶ï¼š</b>æ¡ä»¶VAEæ¶æ„ï¼Œé€šè¿‡è‡ªæ³¨æ„åŠ›èåˆå°†3Dåœºæ™¯ï¼ˆPoint Transformerï¼‰å’Œè¯­è¨€ï¼ˆBERTï¼‰è”åˆåµŒå…¥ï¼Œç”¨äºå¤šæ¨¡æ€æ¡ä»¶ç”Ÿæˆã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Motion Encoder-Decoder with SMPL-X:</b> Bidirectional GRU encoder for sequence features and transformer decoder for generating SMPL-X parameters (translation, rotation, joint rotations) conditioned on latent and conditional embeddings.</div>
            <div class="lang-zh" style="display:none"><b>å¸¦SMPL-Xçš„è¿åŠ¨ç¼–ç å™¨-è§£ç å™¨ï¼š</b>åŒå‘GRUç¼–ç å™¨ç”¨äºåºåˆ—ç‰¹å¾ï¼Œtransformerè§£ç å™¨ç”¨äºåŸºäºæ½œåœ¨åµŒå…¥å’Œæ¡ä»¶åµŒå…¥ç”ŸæˆSMPL-Xå‚æ•°ï¼ˆå¹³ç§»ã€æ—‹è½¬ã€å…³èŠ‚æ—‹è½¬ï¼‰ã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Auxiliary Tasks for Grounding:</b> Additional losses for 3D object location grounding (predicting target object positions) and action recognition (classifying action types) to enhance semantic consistency and spatial understanding.</div>
            <div class="lang-zh" style="display:none"><b>å®šä½è¾…åŠ©ä»»åŠ¡ï¼š</b>ç”¨äº3Då¯¹è±¡ä½ç½®å®šä½ï¼ˆé¢„æµ‹ç›®æ ‡å¯¹è±¡ä½ç½®ï¼‰å’ŒåŠ¨ä½œè¯†åˆ«ï¼ˆåˆ†ç±»åŠ¨ä½œç±»å‹ï¼‰çš„é¢å¤–æŸå¤±ï¼Œä»¥å¢å¼ºè¯­ä¹‰ä¸€è‡´æ€§å’Œç©ºé—´ç†è§£ã€‚</div>
          </li>
        </ol>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/humanise_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('2210.09729.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('2210.09729.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Dataset Quality vs. Synthetic Generation:</b> HUMANISE bridges the gap between data quality and scale by leveraging high-fidelity MoCap data and realistic scanned scenes, providing a cost-effective alternative to expensive real-world capture while maintaining semantic richness.
            </div>
            <div class="lang-zh" style="display:none">
                <b>æ•°æ®é›†è´¨é‡ä¸åˆæˆç”Ÿæˆï¼š</b>HUMANISEé€šè¿‡åˆ©ç”¨é«˜ä¿çœŸMoCapæ•°æ®å’ŒçœŸå®æ‰«æåœºæ™¯ï¼Œå¼¥åˆæ•°æ®è´¨é‡å’Œè§„æ¨¡ä¹‹é—´çš„å·®è·ï¼Œä¸ºæ˜‚è´µçš„çœŸå®ä¸–ç•Œæ•è·æä¾›å…·æœ‰æˆæœ¬æ•ˆç›Šçš„æ›¿ä»£æ–¹æ¡ˆï¼ŒåŒæ—¶ä¿æŒè¯­ä¹‰ä¸°å¯Œæ€§ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Language as Structured Interface:</b> Template-based language generation provides structured yet flexible descriptions that enable precise grounding of actions and objects, facilitating learning of semantic-scene-motion relationships.
            </div>
            <div class="lang-zh" style="display:none">
                <b>è¯­è¨€ä½œä¸ºç»“æ„åŒ–æ¥å£ï¼š</b>åŸºäºæ¨¡æ¿çš„è¯­è¨€ç”Ÿæˆæä¾›ç»“æ„åŒ–ä½†çµæ´»çš„æè¿°ï¼Œèƒ½å¤Ÿç²¾ç¡®å®šä½åŠ¨ä½œå’Œå¯¹è±¡ï¼Œä¿ƒè¿›è¯­ä¹‰-åœºæ™¯-è¿åŠ¨å…³ç³»çš„å­¦ä¹ ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>cVAE for Conditional Generation:</b> The conditional VAE framework effectively handles multi-modal conditioning by learning joint embeddings, enabling coherent generation across scene geometry, motion dynamics, and linguistic semantics.
            </div>
            <div class="lang-zh" style="display:none">
                <b>cVAEç”¨äºæ¡ä»¶ç”Ÿæˆï¼š</b>æ¡ä»¶VAEæ¡†æ¶é€šè¿‡å­¦ä¹ è”åˆåµŒå…¥æœ‰æ•ˆåœ°å¤„ç†å¤šæ¨¡æ€æ¡ä»¶ï¼Œå®ç°è·¨åœºæ™¯å‡ ä½•ã€è¿åŠ¨åŠ¨åŠ›å­¦å’Œè¯­è¨€è¯­ä¹‰çš„è¿è´¯ç”Ÿæˆã€‚
            </div>
          </li>
        </ul>

        <div style="margin-top:16px; padding-top:12px; border-top:1px dashed rgba(255,255,255,.15);">
             <h3 style="margin:0 0 6px; font-size:14px; color:#8bffcf;">
               <span class="lang-en">High-Level Insights: Why it Works?</span>
               <span class="lang-zh" style="display:none">é«˜å±‚æ´å¯Ÿï¼šä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ</span>
             </h3>
             <div class="lang-en" style="color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                It works because HUMANISE addresses the fundamental data limitation in HSI research by creating a synthetic dataset that combines the best of both worlds: high-quality motion capture data with diverse real-world scenes. The key insight is that language provides a natural interface for specifying complex human-scene interactions, and by jointly modeling scenes, motions, and language in a conditional generative framework, the model learns to generate physically plausible and semantically meaningful behaviors. The auxiliary grounding tasks ensure the model doesn't just memorize patterns but truly understands the relationships between linguistic descriptions, 3D geometry, and human motion.
             </div>
             <div class="lang-zh" style="display:none; color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºHUMANISEé€šè¿‡åˆ›å»ºä¸€ä¸ªç»“åˆä¸¤å…¨å…¶ç¾çš„åˆæˆæ•°æ®é›†æ¥è§£å†³HSIç ”ç©¶ä¸­çš„åŸºæœ¬æ•°æ®é™åˆ¶ï¼šé«˜è´¨é‡è¿åŠ¨æ•è·æ•°æ®ä¸å¤šæ ·åŒ–çœŸå®ä¸–ç•Œåœºæ™¯ã€‚å…³é”®æ´å¯Ÿæ˜¯è¯­è¨€ä¸ºæŒ‡å®šå¤æ‚äººç±»-åœºæ™¯äº¤äº’æä¾›äº†è‡ªç„¶æ¥å£ï¼Œé€šè¿‡åœ¨æ¡ä»¶ç”Ÿæˆæ¡†æ¶ä¸­è”åˆå»ºæ¨¡åœºæ™¯ã€è¿åŠ¨å’Œè¯­è¨€ï¼Œæ¨¡å‹å­¦ä¼šç”Ÿæˆç‰©ç†ä¸Šåˆç†ä¸”è¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„è¡Œä¸ºã€‚è¾…åŠ©å®šä½ä»»åŠ¡ç¡®ä¿æ¨¡å‹ä¸ä»…ä»…è®°å¿†æ¨¡å¼ï¼Œè€Œæ˜¯çœŸæ­£ç†è§£è¯­è¨€æè¿°ã€3Då‡ ä½•å’Œäººç±»è¿åŠ¨ä¹‹é—´çš„å…³ç³»ã€‚
             </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            This work introduces HUMANISE, a comprehensive framework for language-conditioned human motion generation in 3D scenes. By addressing the critical limitations of existing HSI datasets through large-scale synthetic data generation, the work enables a new generation task that requires joint understanding of scenes, motions, and language. The proposed cVAE-based model with auxiliary grounding tasks demonstrates superior performance in generating diverse, physically plausible, and semantically consistent human motions. Through extensive experiments and ablation studies, the framework shows significant improvements over baselines and proves the value of multi-modal conditional generation for HSI tasks. The HUMANISE dataset and model establish a new benchmark for language-guided human-scene interaction research, paving the way for more natural and intuitive human-AI interaction in virtual environments. Future work could extend this framework to handle more complex multi-agent scenarios and temporal language understanding.
          </div>
          <div class="lang-zh" style="display:none">
            æœ¬å·¥ä½œä»‹ç»äº†HUMANISEï¼Œä¸€ä¸ªç”¨äº3Dåœºæ™¯ä¸­è¯­è¨€æ¡ä»¶äººç±»è¿åŠ¨ç”Ÿæˆçš„ç»¼åˆæ¡†æ¶ã€‚é€šè¿‡å¤§è§„æ¨¡åˆæˆæ•°æ®ç”Ÿæˆè§£å†³ç°æœ‰HSIæ•°æ®é›†çš„å…³é”®é™åˆ¶ï¼Œè¯¥å·¥ä½œå®ç°äº†ä¸€ä¸ªéœ€è¦è”åˆç†è§£åœºæ™¯ã€è¿åŠ¨å’Œè¯­è¨€çš„æ–°ç”Ÿæˆä»»åŠ¡ã€‚æå‡ºçš„åŸºäºcVAEçš„æ¨¡å‹ä¸è¾…åŠ©å®šä½ä»»åŠ¡å±•ç¤ºäº†åœ¨ç”Ÿæˆå¤šæ ·åŒ–ã€ç‰©ç†ä¸Šåˆç†å’Œè¯­ä¹‰ä¸Šä¸€è‡´çš„äººç±»è¿åŠ¨æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒå’Œæ¶ˆèç ”ç©¶ï¼Œè¯¥æ¡†æ¶æ˜¾ç¤ºå‡ºå¯¹åŸºçº¿çš„æ˜¾è‘—æ”¹è¿›ï¼Œå¹¶è¯æ˜äº†å¤šæ¨¡æ€æ¡ä»¶ç”Ÿæˆå¯¹HSIä»»åŠ¡çš„ä»·å€¼ã€‚HUMANISEæ•°æ®é›†å’Œæ¨¡å‹ä¸ºè¯­è¨€å¼•å¯¼çš„äººç±»-åœºæ™¯äº¤äº’ç ”ç©¶å»ºç«‹äº†æ–°çš„åŸºå‡†ï¼Œä¸ºè™šæ‹Ÿç¯å¢ƒä¸­æ›´è‡ªç„¶å’Œç›´è§‚çš„äººæœºäº¤äº’é“ºå¹³äº†é“è·¯ã€‚æœªæ¥å·¥ä½œå¯ä»¥æ‰©å±•æ­¤æ¡†æ¶ä»¥å¤„ç†æ›´å¤æ‚çš„å¤šæ™ºèƒ½ä½“åœºæ™¯å’Œæ—¶é—´è¯­è¨€ç†è§£ã€‚
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Code:</h2>
        <a href="https://github.com/silverster98/HUMANISE" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          GitHub Repo
        </a>
        <a href="https://silverster98.github.io/HUMANISE/" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          Project Page
        </a>
      </div>
    </div>
</section>
</body>
</html>
