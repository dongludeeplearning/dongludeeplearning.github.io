<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius: 16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  // ç›´æ¥æ‰“å¼€PDFæ–‡ä»¶
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ CVPR 2025
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Jinlu Zhang, Yixin Chen, Zan Wang, Jie Yang, Yizhou Wang, Siyuan Huang<br>
        <span style="opacity:0.8">Peking University, BIGAI, Beijing Institute of Technology, CUHK-Shenzhen</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to generate novel 3D human-object interactions from text descriptions for open-set objects without task-specific training?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•ä»æ–‡æœ¬æè¿°ä¸­ä¸ºå¼€æ”¾é›†å¯¹è±¡ç”Ÿæˆæ–°é¢–çš„3Däººç±»-ç‰©ä½“äº¤äº’ï¼Œè€Œæ— éœ€ç‰¹å®šä»»åŠ¡è®­ç»ƒï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>InteractAnything Framework:</b> Zero-shot 3D HOI generation framework that synthesizes diverse, detailed, and novel interactions from text and object meshes without training on specific datasets, leveraging large-scale pre-trained models.</div>
            <div class="lang-zh" style="display:none"><b>InteractAnythingæ¡†æ¶ï¼š</b>é›¶æ ·æœ¬3D HOIç”Ÿæˆæ¡†æ¶ï¼Œä»æ–‡æœ¬å’Œç‰©ä½“ç½‘æ ¼åˆæˆå¤šæ ·åŒ–ã€è¯¦ç»†å’Œæ–°é¢–çš„äº¤äº’ï¼Œæ— éœ€åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œåˆ©ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>LLM-Guided Initialization:</b> Human-level feedback distillation from LLMs to infer precise human-object relations, initializing object properties and guiding optimization with structured reasoning from pre-defined options.</div>
            <div class="lang-zh" style="display:none"><b>LLMå¼•å¯¼åˆå§‹åŒ–ï¼š</b>ä»LLMä¸­è’¸é¦äººç±»æ°´å¹³åé¦ˆï¼Œä»¥æ¨ç†ç²¾ç¡®çš„äººç±»-ç‰©ä½“å…³ç³»ï¼Œä½¿ç”¨é¢„å®šä¹‰é€‰é¡¹çš„ç»“æ„åŒ–æ¨ç†åˆå§‹åŒ–å¯¹è±¡å±æ€§å¹¶å¼•å¯¼ä¼˜åŒ–ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Open-Set Object Affordance Parsing:</b> Novel approach using pre-trained 2D diffusion models with adaptive inpainting masks to extract contact probabilities and define weighted dynamic contact regions for unseen objects.</div>
            <div class="lang-zh" style="display:none"><b>å¼€æ”¾é›†ç‰©ä½“å¯åŠæ€§è§£æï¼š</b>æ–°é¢–æ–¹æ³•ï¼Œä½¿ç”¨å¸¦æœ‰è‡ªé€‚åº”inpaintingæ©ç çš„é¢„è®­ç»ƒ2Dæ‰©æ•£æ¨¡å‹æ¥æå–æ¥è§¦æ¦‚ç‡å¹¶ä¸ºæœªè§å¯¹è±¡å®šä¹‰åŠ æƒåŠ¨æ€æ¥è§¦åŒºåŸŸã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multi-View SDS with Spatial Constraints:</b> Text and geometry-driven human pose synthesis through multi-hypothesis sampling with multi-view SDS loss, ensuring semantic alignment and spatial plausibility.</div>
            <div class="lang-zh" style="display:none"><b>å¸¦ç©ºé—´çº¦æŸçš„å¤šè§†è§’SDSï¼š</b>é€šè¿‡å¤šå‡è®¾é‡‡æ ·ä¸å¤šè§†è§’SDSæŸå¤±çš„æ–‡æœ¬å’Œå‡ ä½•é©±åŠ¨äººç±»å§¿æ€åˆæˆï¼Œç¡®ä¿è¯­ä¹‰å¯¹é½å’Œç©ºé—´åˆç†æ€§ã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Coarse-to-Fine HOI Optimization:</b> Force-closure based optimization pipeline for fine-grained, precise, and natural interactions, enforcing realistic 3D contact between human body parts and objects including grasping hands.</div>
            <div class="lang-zh" style="display:none"><b>ç²—åˆ°ç²¾HOIä¼˜åŒ–ï¼š</b>åŸºäºåŠ›é—­åˆçš„ä¼˜åŒ–æµæ°´çº¿ï¼Œç”¨äºç²¾ç»†ã€ç²¾ç¡®å’Œè‡ªç„¶çš„äº¤äº’ï¼Œå¼ºåˆ¶äººç±»èº«ä½“éƒ¨ä½ä¸ç‰©ä½“ï¼ˆåŒ…æ‹¬æŠ“æ¡æ‰‹ï¼‰ä¹‹é—´çš„çœŸå®3Dæ¥è§¦ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆç¤ºä¾‹ï¼‰</h2>
        <div style="border-radius:14px; overflow:hidden;">
             <img src="Figures/interactanything_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Precise Human-Object Relation Reasoning:</b> Inferring complex semantic relationships including relative positions, orientations, and interaction dynamics from simple text descriptions for accurate initialization.</div>
            <div class="lang-zh" style="display:none"><b>ç²¾ç¡®äººç±»-ç‰©ä½“å…³ç³»æ¨ç†ï¼š</b>ä»ç®€å•æ–‡æœ¬æè¿°ä¸­æ¨ç†å¤æ‚çš„è¯­ä¹‰å…³ç³»ï¼ŒåŒ…æ‹¬ç›¸å¯¹ä½ç½®ã€æ–¹å‘å’Œäº¤äº’åŠ¨åŠ›å­¦ä»¥å®ç°å‡†ç¡®åˆå§‹åŒ–ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Open-Set Object Affordance Parsing:</b> Extracting contact information and interaction possibilities from arbitrary 3D objects without prior knowledge or category-specific training data.</div>
            <div class="lang-zh" style="display:none"><b>å¼€æ”¾é›†ç‰©ä½“å¯åŠæ€§è§£æï¼š</b>ä»æœªç»è®­ç»ƒçš„ä»»æ„3Då¯¹è±¡ä¸­æå–æ¥è§¦ä¿¡æ¯å’Œäº¤äº’å¯èƒ½æ€§ï¼Œè€Œæ— éœ€å…ˆéªŒçŸ¥è¯†æˆ–ç±»åˆ«ç‰¹å®šè®­ç»ƒæ•°æ®ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Text-Geometry Aligned Pose Synthesis:</b> Generating human poses that simultaneously respect textual descriptions, object geometry constraints, and maintain physical plausibility across diverse interaction scenarios.</div>
            <div class="lang-zh" style="display:none"><b>æ–‡æœ¬-å‡ ä½•å¯¹é½å§¿æ€åˆæˆï¼š</b>ç”ŸæˆåŒæ—¶å°Šé‡æ–‡æœ¬æè¿°ã€ç‰©ä½“å‡ ä½•çº¦æŸå¹¶åœ¨å¤šæ ·åŒ–äº¤äº’åœºæ™¯ä¸­ä¿æŒç‰©ç†åˆç†æ€§çš„äººç±»å§¿æ€ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Fine-Grained Contact Modeling:</b> Achieving precise 3D contact between human body parts (especially hands) and objects while ensuring natural, expressive, and diverse interaction outcomes.</div>
            <div class="lang-zh" style="display:none"><b>ç»†ç²’åº¦æ¥è§¦å»ºæ¨¡ï¼š</b>å®ç°äººç±»èº«ä½“éƒ¨ä½ï¼ˆå°¤å…¶æ˜¯æ‰‹ï¼‰ä¸ç‰©ä½“ä¹‹é—´çš„ç²¾ç¡®3Dæ¥è§¦ï¼ŒåŒæ—¶ç¡®ä¿è‡ªç„¶ã€å¯Œæœ‰è¡¨ç°åŠ›å’Œå¤šæ ·åŒ–çš„äº¤äº’ç»“æœã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Zero-Shot Generalization:</b> Developing a framework that works across arbitrary object categories and interaction types without task-specific fine-tuning or dataset curation.</div>
            <div class="lang-zh" style="display:none"><b>é›¶æ ·æœ¬æ³›åŒ–ï¼š</b>å¼€å‘ä¸€ä¸ªé€‚ç”¨äºä»»æ„å¯¹è±¡ç±»åˆ«å’Œäº¤äº’ç±»å‹çš„æ¡†æ¶ï¼Œæ— éœ€ç‰¹å®šä»»åŠ¡å¾®è°ƒæˆ–æ•°æ®é›†æ•´ç†ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>LLM-Guided Initialization Pipeline:</b> Step-by-step reasoning with LLMs to select from pre-defined options for object properties (rotation, translation, scale, state) and human body parts, mapping semantic feedback to geometric parameters.</div>
            <div class="lang-zh" style="display:none"><b>LLMå¼•å¯¼åˆå§‹åŒ–æµæ°´çº¿ï¼š</b>ä¸LLMé€æ­¥æ¨ç†ï¼Œä»é¢„å®šä¹‰é€‰é¡¹ä¸­é€‰æ‹©å¯¹è±¡å±æ€§ï¼ˆæ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ã€çŠ¶æ€ï¼‰å’Œäººç±»èº«ä½“éƒ¨ä½ï¼Œå°†è¯­ä¹‰åé¦ˆæ˜ å°„åˆ°å‡ ä½•å‚æ•°ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Adaptive Inpainting for Affordance:</b> LLM-guided generation of full-body and body-part inpainting masks, using pre-trained 2D diffusion models to extract contact probabilities and segment weighted dynamic contact regions on 3D meshes.</div>
            <div class="lang-zh" style="display:none"><b>è‡ªé€‚åº”inpaintingç”¨äºå¯åŠæ€§ï¼š</b>LLMå¼•å¯¼ç”Ÿæˆå…¨èº«å’Œèº«ä½“éƒ¨ä½inpaintingæ©ç ï¼Œä½¿ç”¨é¢„è®­ç»ƒ2Dæ‰©æ•£æ¨¡å‹æå–æ¥è§¦æ¦‚ç‡å¹¶åœ¨3Dç½‘æ ¼ä¸Šåˆ†å‰²åŠ æƒåŠ¨æ€æ¥è§¦åŒºåŸŸã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Multi-Hypothesis Pose Sampling:</b> Initial human pose generation through multi-view SDS with spatial constraints, sampling diverse hypotheses that align with text descriptions and object geometry before refinement.</div>
            <div class="lang-zh" style="display:none"><b>å¤šå‡è®¾å§¿æ€é‡‡æ ·ï¼š</b>é€šè¿‡å¸¦ç©ºé—´çº¦æŸçš„å¤šè§†è§’SDSç”Ÿæˆåˆå§‹äººç±»å§¿æ€ï¼Œåœ¨ç»†åŒ–ä¹‹å‰é‡‡æ ·ä¸æ–‡æœ¬æè¿°å’Œç‰©ä½“å‡ ä½•å¯¹é½çš„å¤šæ ·åŒ–å‡è®¾ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Coarse-to-Fine HOI Optimization:</b> Three-stage optimization including global HOI optimization for coarse alignment, finer HOI optimization for detailed contact, and expressive HOI optimization for natural and diverse interactions.</div>
            <div class="lang-zh" style="display:none"><b>ç²—åˆ°ç²¾HOIä¼˜åŒ–ï¼š</b>ä¸‰é˜¶æ®µä¼˜åŒ–ï¼ŒåŒ…æ‹¬ç”¨äºç²—ç•¥å¯¹é½çš„å…¨å±€HOIä¼˜åŒ–ã€ç”¨äºè¯¦ç»†æ¥è§¦çš„æ›´ç²¾ç»†HOIä¼˜åŒ–ï¼Œä»¥åŠç”¨äºè‡ªç„¶å’Œå¤šæ ·åŒ–äº¤äº’çš„å¯Œæœ‰è¡¨ç°åŠ›HOIä¼˜åŒ–ã€‚</div>
          </li>
          <li>
            <div class="lang-en"><b>Force Closure Integration:</b> Physics-based contact modeling ensuring stable grasps and interactions, with multi-objective optimization balancing contact accuracy, pose naturalness, and semantic fidelity.</div>
            <div class="lang-zh" style="display:none"><b>åŠ›é—­åˆé›†æˆï¼š</b>åŸºäºç‰©ç†çš„æ¥è§¦å»ºæ¨¡ç¡®ä¿ç¨³å®šçš„æŠ“æ¡å’Œäº¤äº’ï¼Œé€šè¿‡å¤šç›®æ ‡ä¼˜åŒ–å¹³è¡¡æ¥è§¦å‡†ç¡®æ€§ã€å§¿æ€è‡ªç„¶æ€§å’Œè¯­ä¹‰ä¿çœŸåº¦ã€‚</div>
          </li>
        </ol>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/interactanything_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('2505.24315.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('2505.24315.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Zero-Shot HOI as Compositional Generation:</b> InteractAnything demonstrates that zero-shot HOI generation is fundamentally a compositional problem, requiring joint optimization of human poses, object states, and semantic constraints without paired training data.
            </div>
            <div class="lang-zh" style="display:none">
                <b>é›¶æ ·æœ¬HOIä½œä¸ºç»„åˆç”Ÿæˆï¼š</b>InteractAnythingè¯æ˜é›¶æ ·æœ¬HOIç”Ÿæˆä»æ ¹æœ¬ä¸Šæ˜¯ä¸€ä¸ªç»„åˆé—®é¢˜ï¼Œéœ€è¦åœ¨æ²¡æœ‰é…å¯¹è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹è”åˆä¼˜åŒ–äººç±»å§¿æ€ã€ç‰©ä½“çŠ¶æ€å’Œè¯­ä¹‰çº¦æŸã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>LLM as Structured Reasoner:</b> Large language models excel at providing structured feedback for geometric reasoning, enabling precise initialization of interaction parameters that traditional approaches struggle to achieve.
            </div>
            <div class="lang-zh" style="display:none">
                <b>LLMä½œä¸ºç»“æ„åŒ–æ¨ç†å™¨ï¼š</b>å¤§è¯­è¨€æ¨¡å‹æ“…é•¿ä¸ºå‡ ä½•æ¨ç†æä¾›ç»“æ„åŒ–åé¦ˆï¼Œèƒ½å¤Ÿå®ç°ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥è¾¾åˆ°çš„äº¤äº’å‚æ•°ç²¾ç¡®åˆå§‹åŒ–ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Diffusion Models for Affordance:</b> Pre-trained 2D diffusion models contain rich interaction priors that can be distilled through inpainting to understand object affordances, bridging 2D image understanding with 3D geometric reasoning.
            </div>
            <div class="lang-zh" style="display:none">
                <b>æ‰©æ•£æ¨¡å‹ç”¨äºå¯åŠæ€§ï¼š</b>é¢„è®­ç»ƒçš„2Dæ‰©æ•£æ¨¡å‹åŒ…å«ä¸°å¯Œçš„äº¤äº’å…ˆéªŒï¼Œå¯ä»¥é€šè¿‡inpaintingè’¸é¦æ¥ç†è§£ç‰©ä½“å¯åŠæ€§ï¼Œå°†2Då›¾åƒç†è§£ä¸3Då‡ ä½•æ¨ç†è¿æ¥èµ·æ¥ã€‚
            </div>
          </li>
        </ul>

        <div style="margin-top:16px; padding-top:12px; border-top:1px dashed rgba(255,255,255,.15);">
             <h3 style="margin:0 0 6px; font-size:14px; color:#8bffcf;">
               <span class="lang-en">High-Level Insights: Why it Works?</span>
               <span class="lang-zh" style="display:none">é«˜å±‚æ´å¯Ÿï¼šä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ</span>
             </h3>
             <div class="lang-en" style="color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                It works because InteractAnything decomposes the complex zero-shot HOI task into manageable components, leveraging complementary strengths of different AI models. LLMs provide semantic reasoning for initialization, diffusion models offer visual priors for affordance parsing, and physics-based optimization ensures geometric accuracy. This multi-modal approach creates a robust pipeline that can handle the combinatorial complexity of human-object interactions without requiring exhaustive training data, demonstrating that zero-shot HOI generation is achievable through strategic knowledge distillation from pre-trained models.
             </div>
             <div class="lang-zh" style="display:none; color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºInteractAnythingå°†å¤æ‚çš„é›¶æ ·æœ¬HOIä»»åŠ¡åˆ†è§£ä¸ºå¯ç®¡ç†çš„ç»„ä»¶ï¼Œåˆ©ç”¨ä¸åŒAIæ¨¡å‹çš„äº’è¡¥ä¼˜åŠ¿ã€‚LLMæä¾›è¯­ä¹‰æ¨ç†ç”¨äºåˆå§‹åŒ–ï¼Œæ‰©æ•£æ¨¡å‹æä¾›è§†è§‰å…ˆéªŒç”¨äºå¯åŠæ€§è§£æï¼ŒåŸºäºç‰©ç†çš„ä¼˜åŒ–ç¡®ä¿å‡ ä½•å‡†ç¡®æ€§ã€‚è¿™ç§å¤šæ¨¡æ€æ–¹æ³•åˆ›å»ºäº†ä¸€ä¸ªé²æ£’çš„æµæ°´çº¿ï¼Œèƒ½å¤Ÿå¤„ç†äººç±»-ç‰©ä½“äº¤äº’çš„ç»„åˆå¤æ‚æ€§ï¼Œè€Œæ— éœ€è¯¦å°½çš„è®­ç»ƒæ•°æ®ï¼Œè¯æ˜é€šè¿‡ä»é¢„è®­ç»ƒæ¨¡å‹ä¸­è¿›è¡Œæˆ˜ç•¥çŸ¥è¯†è’¸é¦ï¼Œé›¶æ ·æœ¬HOIç”Ÿæˆæ˜¯å¯å®ç°çš„ã€‚
             </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            This work presents InteractAnything, a comprehensive zero-shot framework for 3D human-object interaction synthesis from text descriptions. By addressing the core challenges of relation reasoning, affordance parsing, and pose synthesis, the framework achieves high-quality, geometrically precise, and semantically consistent HOI generation for open-set objects. The multi-stage approach leverages LLMs for structured initialization, diffusion models for affordance understanding, and physics-based optimization for contact accuracy. Extensive experiments demonstrate superior performance over existing methods, particularly in handling diverse and novel interactions. This work establishes a new paradigm for text-driven HOI synthesis, enabling applications in AR/VR, animation, and robotics without the need for object-specific training data.
          </div>
          <div class="lang-zh" style="display:none">
            æœ¬å·¥ä½œæå‡ºäº†InteractAnythingï¼Œä¸€ä¸ªä»æ–‡æœ¬æè¿°è¿›è¡Œ3Däººç±»-ç‰©ä½“äº¤äº’åˆæˆçš„å…¨é¢é›¶æ ·æœ¬æ¡†æ¶ã€‚é€šè¿‡è§£å†³å…³ç³»æ¨ç†ã€å¯åŠæ€§è§£æå’Œå§¿æ€åˆæˆçš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶å®ç°äº†é’ˆå¯¹å¼€æ”¾é›†å¯¹è±¡çš„ä¼˜è´¨ã€å‡ ä½•ç²¾ç¡®å’Œè¯­ä¹‰ä¸€è‡´çš„HOIç”Ÿæˆã€‚å¤šé˜¶æ®µæ–¹æ³•åˆ©ç”¨LLMè¿›è¡Œç»“æ„åŒ–åˆå§‹åŒ–ã€æ‰©æ•£æ¨¡å‹è¿›è¡Œå¯åŠæ€§ç†è§£ï¼Œä»¥åŠåŸºäºç‰©ç†çš„ä¼˜åŒ–è¿›è¡Œæ¥è§¦å‡†ç¡®æ€§ã€‚å¹¿æ³›å®éªŒè¯æ˜äº†ä¼˜äºç°æœ‰æ–¹æ³•çš„å“è¶Šæ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤„ç†å¤šæ ·åŒ–å’Œæ–°é¢–äº¤äº’æ–¹é¢ã€‚æœ¬å·¥ä½œä¸ºæ–‡æœ¬é©±åŠ¨HOIåˆæˆå»ºç«‹äº†æ–°èŒƒå¼ï¼Œä½¿AR/VRã€åŠ¨ç”»å’Œæœºå™¨äººåº”ç”¨èƒ½å¤Ÿåœ¨æ— éœ€å¯¹è±¡ç‰¹å®šè®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å®ç°ã€‚
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Code:</h2>
        <a href="https://jinluzhang.site/projects/interactanything" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          Project Page
        </a>
        <a href="https://github.com/jinluzhang/InteractAnything" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          GitHub Repo
        </a>
      </div>
    </div>
</section>
</body>
</html>
