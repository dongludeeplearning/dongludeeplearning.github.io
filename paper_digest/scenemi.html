<!doctype html>
<html>
<head>
<meta charset="utf-8">
<style>
  :root{
      --bg:#0b1020;
      --panel:#0f1733;
      --panel2:#0c1430;
      --text:#e8ecff;
      --muted:#aeb7e6;
      --border:rgba(255,255,255,.10);
      --accent:#7aa2ff;
      --accent2:#8bffcf;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
  }
  body {
    background: transparent;
    background-color: var(--bg);
    color: var(--text);
    font-family: var(--sans);
    margin: 0;
    padding: 16px;
    box-sizing: border-box;
  }
  ::-webkit-scrollbar { width: 8px; height: 8px; }
  ::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
  ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.15); border-radius: 4px; }
  ::-webkit-scrollbar-thumb:hover { background: rgba(255,255,255,0.25); }
</style>
<script>
function toggleLang(btn) {
  const container = btn.closest('div');
  const enElements = container.querySelectorAll('.lang-en');
  const zhElements = container.querySelectorAll('.lang-zh');

  enElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });

  zhElements.forEach(el => {
    el.style.display = (el.style.display === 'none') ? 'block' : 'none';
  });
}
function openLocalPdf(filename) {
  // ç›´æ¥æ‰“å¼€PDFæ–‡ä»¶
  window.open('pdfs/' + filename, '_blank');
}
function delLocalPdf(filename) {
  if (confirm('Delete local PDF file: ' + filename + '? Note: This requires server environment to actually delete files.')) {
    alert('Delete function needs to be implemented on the server side.');
  }
}
</script>
</head>
<body>
<section style="max-width:980px;margin:0 auto;">
    <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
      <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
      <div style="font-family:ui-monospace,Menlo,Consolas,monospace;color:rgba(232,236,255,.7);font-size:12px;">
        Paper Digest â€¢ ICCV 2025
      </div>
      <h1 style="margin:6px 0 0;font-size:22px;line-height:1.25;">SceneMI: Motion In-betweening for Modeling Human-Scene Interactions</h1>
      <div style="margin-top:6px;color:rgba(232,236,255,.6);font-size:12px;line-height:1.5;">
        Inwoo Hwang, Bing Zhou, Young Min Kim, Jian Wang, Chuan Guo<br>
        <span style="opacity:0.8">Seoul National University, Snap Inc.</span>
      </div>
      <div style="margin-top:12px;padding-top:12px;border-top:1px solid rgba(255,255,255,.08);color:rgba(232,236,255,.75);font-size:13px;line-height:1.6;">
        <div class="lang-en">
            <b>One-Sentence Problem:</b> How to reformulate human-scene interaction modeling as a more tractable scene-aware motion in-betweening task to achieve better controllability and flexibility for real-world applications?
        </div>
        <div class="lang-zh" style="display:none">
            <b>ä¸€å¥è¯é—®é¢˜ï¼š</b>å¦‚ä½•å°†äººç±»-åœºæ™¯äº¤äº’å»ºæ¨¡é‡æ–°å®šä¹‰ä¸ºæ›´æ˜“å¤„ç†çš„åœºæ™¯æ„ŸçŸ¥è¿åŠ¨æ’å€¼ä»»åŠ¡ï¼Œä»¥å®ç°æ›´å¥½çš„å¯æ§æ€§å’ŒçœŸå®ä¸–ç•Œåº”ç”¨çš„çµæ´»æ€§ï¼Ÿ
        </div>
      </div>
    </div>

    <div style="display:grid;grid-template-columns:1fr;gap:14px;margin-top:14px;">
      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Contributionsï¼ˆè´¡çŒ®ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>SceneMI Framework:</b> Pioneering reformulation of HSI modeling as scene-aware motion in-betweening, enabling controllable and flexible synthesis of human motions in 3D scenes while respecting environmental constraints.</div>
            <div class="lang-zh" style="display:none"><b>SceneMIæ¡†æ¶ï¼š</b>å¼€åˆ›æ€§åœ°å°†HSIå»ºæ¨¡é‡æ–°å®šä¹‰ä¸ºåœºæ™¯æ„ŸçŸ¥è¿åŠ¨æ’å€¼ï¼Œå®ç°å¯æ§å’Œçµæ´»çš„3Dåœºæ™¯ä¸­äººç±»è¿åŠ¨åˆæˆï¼ŒåŒæ—¶å°Šé‡ç¯å¢ƒçº¦æŸã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Dual Scene Descriptors:</b> Novel hierarchical scene encoding with global occupancy voxel grids and local Basis Point Set (BPS) features, providing comprehensive environmental context for motion synthesis at multiple scales.</div>
            <div class="lang-zh" style="display:none"><b>åŒåœºæ™¯æè¿°ç¬¦ï¼š</b>æ–°é¢–çš„åˆ†å±‚åœºæ™¯ç¼–ç ï¼Œä½¿ç”¨å…¨å±€å ç”¨ä½“ç´ ç½‘æ ¼å’Œå±€éƒ¨åŸºç¡€ç‚¹é›†ï¼ˆBPSï¼‰ç‰¹å¾ï¼Œä¸ºå¤šå°ºåº¦è¿åŠ¨åˆæˆæä¾›å…¨é¢çš„ç¯å¢ƒä¸Šä¸‹æ–‡ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Noisy Keyframe Handling:</b> Specialized denoising procedure leveraging diffusion models' inherent noise removal capabilities to robustly handle imperfect keyframes from noisy sensors or video extraction.</div>
            <div class="lang-zh" style="display:none"><b>å™ªå£°å…³é”®å¸§å¤„ç†ï¼š</b>ä¸“é—¨çš„å»å™ªè¿‡ç¨‹ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹å›ºæœ‰çš„å™ªå£°å»é™¤èƒ½åŠ›ï¼Œé²æ£’åœ°å¤„ç†æ¥è‡ªå™ªå£°ä¼ æ„Ÿå™¨æˆ–è§†é¢‘æå–çš„ä¸å®Œç¾å…³é”®å¸§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Comprehensive Evaluation:</b> Extensive validation on multiple datasets including TRUMANS, GIMO, and PROX, demonstrating generalization to real-world noisy data and applications in monocular video HSI reconstruction.</div>
            <div class="lang-zh" style="display:none"><b>å…¨é¢è¯„ä¼°ï¼š</b>åœ¨å¤šä¸ªæ•°æ®é›†ï¼ˆåŒ…æ‹¬TRUMANSã€GIMOå’ŒPROXï¼‰ä¸Šçš„å¹¿æ³›éªŒè¯ï¼Œå±•ç¤ºäº†å‘çœŸå®ä¸–ç•Œå™ªå£°æ•°æ®çš„æ³›åŒ–å’Œå•ç›®è§†é¢‘HSIé‡å»ºåº”ç”¨ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Practical Applications:</b> Framework supporting keyframe-guided character animation, artifact reduction in noisy HSI data (37.5% foot skating reduction, 56.5% jittering reduction), and enhanced HSI reconstruction from monocular videos.</div>
            <div class="lang-zh" style="display:none"><b>å®é™…åº”ç”¨ï¼š</b>æ¡†æ¶æ”¯æŒå…³é”®å¸§å¼•å¯¼çš„è§’è‰²åŠ¨ç”»ã€å™ªå£°HSIæ•°æ®ä¸­çš„ç‘•ç–µå‡å°‘ï¼ˆè„šæ»‘åŠ¨å‡å°‘37.5%ã€æŠ–åŠ¨å‡å°‘56.5%ï¼‰ï¼Œä»¥åŠå¢å¼ºçš„å•ç›®è§†é¢‘HSIé‡å»ºã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Intro Figureï¼ˆå¼•è¨€ç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/scenemi_intro.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Intro Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('2503.16289.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('2503.16289.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10)">
        <h2 style="margin:0 0 8px;font-size:16px;">Overview Figureï¼ˆç¤ºæ„å›¾ï¼‰</h2>
        <div style="border:1px dashed rgba(255,255,255,.18);border-radius:14px;padding:16px;color:rgba(232,236,255,.65);line-height:1.6;">
            <img src="Figures/scenemi_overview.png" style="width:100%; height:auto; display:block; border-radius:8px;" alt="Overview Figure" />

            <div style="margin-top:12px; display:flex; gap:10px; justify-content:flex-end;">
                 <button onclick="openLocalPdf('2503.16289.pdf')" style="background:rgba(139,255,207,0.1); border:1px solid rgba(139,255,207,0.3); color:#8bffcf; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ“‚ Open Local PDF</button>
                 <button onclick="delLocalPdf('2503.16289.pdf')" style="background:rgba(255,100,100,0.1); border:1px solid rgba(255,100,100,0.3); color:#ff6464; padding:6px 12px; border-radius:8px; cursor:pointer; font-size:12px;">ğŸ—‘ï¸ Del Local PDF</button>
            </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Challengesï¼ˆæŒ‘æˆ˜ï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Limited Controllability:</b> Existing generative HSI approaches lack precise control over motion trajectories and timing, making them unsuitable for animation and interactive applications requiring specific keyframe constraints.</div>
            <div class="lang-zh" style="display:none"><b>æœ‰é™çš„å¯æ§æ€§ï¼š</b>ç°æœ‰çš„ç”Ÿæˆå¼HSIæ–¹æ³•ç¼ºä¹å¯¹è¿åŠ¨è½¨è¿¹å’Œæ—¶åºçš„ç²¾ç¡®æ§åˆ¶ï¼Œä½¿å…¶ä¸é€‚åˆéœ€è¦ç‰¹å®šå…³é”®å¸§çº¦æŸçš„åŠ¨ç”»å’Œäº¤äº’åº”ç”¨ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Environmental Constraints:</b> Naive application of isolated human motion in-betweening to scenes leads to undesirable body-scene penetrations and physically implausible interactions with environmental obstacles.</div>
            <div class="lang-zh" style="display:none"><b>ç¯å¢ƒçº¦æŸï¼š</b>å°†å­¤ç«‹çš„ä¸ªäººè¿åŠ¨æ’å€¼ç®€å•åœ°åº”ç”¨äºåœºæ™¯ä¼šå¯¼è‡´ä¸å¸Œæœ›çš„èº«ä½“-åœºæ™¯ç©¿é€å’Œä¸ç¯å¢ƒéšœç¢ç‰©çš„ç‰©ç†ä¸åˆç†äº¤äº’ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Noisy Real-World Data:</b> Practical applications require handling imperfect keyframes from noisy motion capture sensors, inaccurate IMU devices, or extracted from monocular videos.</div>
            <div class="lang-zh" style="display:none"><b>å™ªå£°çœŸå®ä¸–ç•Œæ•°æ®ï¼š</b>å®é™…åº”ç”¨éœ€è¦å¤„ç†æ¥è‡ªå™ªå£°è¿åŠ¨æ•æ‰ä¼ æ„Ÿå™¨ã€ä¸å‡†ç¡®IMUè®¾å¤‡æˆ–ä»å•ç›®è§†é¢‘æå–çš„ä¸å®Œç¾å…³é”®å¸§ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Scene Representation:</b> Need comprehensive yet efficient scene encoding that captures both global layout for trajectory planning and local geometry for fine-grained interaction constraints.</div>
            <div class="lang-zh" style="display:none"><b>åœºæ™¯è¡¨ç¤ºï¼š</b>éœ€è¦å…¨é¢è€Œé«˜æ•ˆçš„åœºæ™¯ç¼–ç ï¼Œæ—¢èƒ½æ•æ‰å…¨å±€å¸ƒå±€ç”¨äºè½¨è¿¹è§„åˆ’ï¼Œåˆèƒ½æ•æ‰å±€éƒ¨å‡ ä½•ç”¨äºç»†ç²’åº¦äº¤äº’çº¦æŸã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Cross-Domain Generalization:</b> Models trained on hand-crafted scenes must generalize to real-world environments scanned by smartphones or other consumer devices with varying quality and resolution.</div>
            <div class="lang-zh" style="display:none"><b>è·¨åŸŸæ³›åŒ–ï¼š</b>åœ¨æ‰‹å·¥åˆ¶ä½œåœºæ™¯ä¸Šè®­ç»ƒçš„æ¨¡å‹å¿…é¡»æ³›åŒ–åˆ°ç”±æ™ºèƒ½æ‰‹æœºæˆ–å…¶ä»–æ¶ˆè´¹è®¾å¤‡æ‰«æçš„çœŸå®ä¸–ç•Œç¯å¢ƒï¼Œè¿™äº›ç¯å¢ƒå…·æœ‰ä¸åŒè´¨é‡å’Œåˆ†è¾¨ç‡ã€‚</div>
          </li>
        </ul>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Methodï¼ˆæ–¹æ³•ï¼‰</h2>
        <ol style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Task Reformulation:</b> Reformulate HSI modeling as scene-aware motion in-betweening - synthesizing natural transitions between keyframes while adapting to environmental constraints, reducing task complexity while enabling practical applications.</div>
            <div class="lang-zh" style="display:none"><b>ä»»åŠ¡é‡æ–°å®šä¹‰ï¼š</b>å°†HSIå»ºæ¨¡é‡æ–°å®šä¹‰ä¸ºåœºæ™¯æ„ŸçŸ¥è¿åŠ¨æ’å€¼ - åœ¨é€‚åº”ç¯å¢ƒçº¦æŸçš„åŒæ—¶åˆæˆå…³é”®å¸§ä¹‹é—´çš„è‡ªç„¶è¿‡æ¸¡ï¼Œé™ä½ä»»åŠ¡å¤æ‚åº¦åŒæ—¶å¯ç”¨å®é™…åº”ç”¨ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Dual Scene Encoding:</b> Hierarchical scene representation with global occupancy voxel grids (48Ã—24Ã—48, 0.1m resolution) for overall layout and local BPS features (64 anchor points) for keyframe-centered interactions, jointly trained with motion diffusion.</div>
            <div class="lang-zh" style="display:none"><b>åŒåœºæ™¯ç¼–ç ï¼š</b>åˆ†å±‚åœºæ™¯è¡¨ç¤ºï¼Œä½¿ç”¨å…¨å±€å ç”¨ä½“ç´ ç½‘æ ¼ï¼ˆ48Ã—24Ã—48ï¼Œ0.1måˆ†è¾¨ç‡ï¼‰ç”¨äºæ•´ä½“å¸ƒå±€å’Œå±€éƒ¨BPSç‰¹å¾ï¼ˆ64é”šç‚¹ï¼‰ç”¨äºå…³é”®å¸§ä¸­å¿ƒäº¤äº’ï¼Œä¸è¿åŠ¨æ‰©æ•£è”åˆè®­ç»ƒã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Conditional Diffusion Model:</b> U-Net based architecture with Adaptive Group Normalization and 1D convolutions, conditioned on scene features, body shape, and diffusion timestep, trained with reconstruction, joint position, and velocity losses.</div>
            <div class="lang-zh" style="display:none"><b>æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼š</b>åŸºäºU-Netçš„æ¶æ„ï¼Œå…·æœ‰è‡ªé€‚åº”ç»„å½’ä¸€åŒ–å’Œ1Då·ç§¯ï¼Œä»¥åœºæ™¯ç‰¹å¾ã€èº«ä½“å½¢çŠ¶å’Œæ‰©æ•£æ—¶é—´æ­¥ä¸ºæ¡ä»¶ï¼Œä½¿ç”¨é‡å»ºã€å…³èŠ‚ä½ç½®å’Œé€Ÿåº¦æŸå¤±è¿›è¡Œè®­ç»ƒã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Keyframe Imputation:</b> Training procedure with random keyframe masking and imputation, enabling the model to focus on synthesizing transitions while maintaining keyframe fidelity, with classifier-free guidance during inference.</div>
            <div class="lang-zh" style="display:none"><b>å…³é”®å¸§æ’è¡¥ï¼š</b>è®­ç»ƒè¿‡ç¨‹ä½¿ç”¨éšæœºå…³é”®å¸§æ©ç å’Œæ’è¡¥ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä¸“æ³¨äºåˆæˆè¿‡æ¸¡åŒæ—¶ä¿æŒå…³é”®å¸§ä¿çœŸåº¦ï¼Œåœ¨æ¨ç†æœŸé—´ä½¿ç”¨æ— åˆ†ç±»å™¨å¼•å¯¼ã€‚</div>
          </li>
          <li style="margin-bottom:8px;">
            <div class="lang-en"><b>Noisy Keyframe Handling:</b> Specialized denoising schedule dividing diffusion steps into two phases: early steps guided by noisy keyframes for alignment, later steps denoising both keyframes and transitions, leveraging diffusion models' inherent noise removal capabilities.</div>
            <div class="lang-zh" style="display:none"><b>å™ªå£°å…³é”®å¸§å¤„ç†ï¼š</b>ä¸“é—¨çš„å»å™ªè°ƒåº¦å°†æ‰©æ•£æ­¥éª¤åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šæ—©æœŸæ­¥éª¤ç”±å™ªå£°å…³é”®å¸§å¼•å¯¼è¿›è¡Œå¯¹é½ï¼ŒåæœŸæ­¥éª¤å¯¹å…³é”®å¸§å’Œè¿‡æ¸¡è¿›è¡Œå»å™ªï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹å›ºæœ‰çš„å™ªå£°å»é™¤èƒ½åŠ›ã€‚</div>
          </li>
        </ol>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Discussionï¼ˆè®¨è®ºï¼‰</h2>
        <ul style="margin:0;padding-left:18px;color:rgba(232,236,255,.80);line-height:1.65;">
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Task Reformulation Benefits:</b> By reducing complex HSI generation to controlled motion in-betweening, SceneMI achieves better controllability and practical applicability while maintaining physical plausibility through scene awareness.
            </div>
            <div class="lang-zh" style="display:none">
                <b>ä»»åŠ¡é‡æ–°å®šä¹‰çš„å¥½å¤„ï¼š</b>é€šè¿‡å°†å¤æ‚çš„HSIç”Ÿæˆç®€åŒ–ä¸ºå—æ§è¿åŠ¨æ’å€¼ï¼ŒSceneMIå®ç°äº†æ›´å¥½çš„å¯æ§æ€§å’Œå®é™…é€‚ç”¨æ€§ï¼ŒåŒæ—¶é€šè¿‡åœºæ™¯æ„ŸçŸ¥ä¿æŒç‰©ç†åˆç†æ€§ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Hierarchical Scene Encoding:</b> The dual representation of global and local scene features enables efficient processing of environmental constraints at multiple scales, providing robust generalization to diverse scene sources.
            </div>
            <div class="lang-zh" style="display:none">
                <b>åˆ†å±‚åœºæ™¯ç¼–ç ï¼š</b>å…¨å±€å’Œå±€éƒ¨åœºæ™¯ç‰¹å¾çš„åŒé‡è¡¨ç¤ºèƒ½å¤Ÿåœ¨å¤šä¸ªå°ºåº¦ä¸Šé«˜æ•ˆå¤„ç†ç¯å¢ƒçº¦æŸï¼Œä¸ºä¸åŒçš„åœºæ™¯æºæä¾›é²æ£’çš„æ³›åŒ–ã€‚
            </div>
          </li>
          <li style="margin-bottom:12px;">
            <div class="lang-en">
                <b>Diffusion Model Advantages:</b> Leveraging the inherent denoising properties of diffusion models enables graceful handling of noisy real-world data, bridging the gap between synthetic training data and practical applications.
            </div>
            <div class="lang-zh" style="display:none">
                <b>æ‰©æ•£æ¨¡å‹ä¼˜åŠ¿ï¼š</b>åˆ©ç”¨æ‰©æ•£æ¨¡å‹å›ºæœ‰çš„å»å™ªç‰¹æ€§èƒ½å¤Ÿä¼˜é›…åœ°å¤„ç†å™ªå£°çš„çœŸå®ä¸–ç•Œæ•°æ®ï¼Œå¼¥åˆåˆæˆè®­ç»ƒæ•°æ®å’Œå®é™…åº”ç”¨ä¹‹é—´çš„å·®è·ã€‚
            </div>
          </li>
        </ul>

        <div style="margin-top:16px; padding-top:12px; border-top:1px dashed rgba(255,255,255,.15);">
             <h3 style="margin:0 0 6px; font-size:14px; color:#8bffcf;">
               <span class="lang-en">High-Level Insights: Why it Works?</span>
               <span class="lang-zh" style="display:none">é«˜å±‚æ´å¯Ÿï¼šä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ</span>
             </h3>
             <div class="lang-en" style="color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                It works because SceneMI transforms the challenging problem of unconstrained HSI generation into a more manageable controlled synthesis task. By focusing on motion transitions between keyframes while incorporating comprehensive scene awareness, the framework achieves both precise control and environmental plausibility. The hierarchical scene encoding and diffusion-based denoising provide the necessary robustness to handle real-world imperfections, making the approach practically viable for animation, data enhancement, and video reconstruction applications.
             </div>
             <div class="lang-zh" style="display:none; color:rgba(232,236,255,.80); font-size:13px; line-height:1.6;">
                ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºSceneMIå°†æ— çº¦æŸHSIç”Ÿæˆè¿™ä¸€å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜è½¬æ¢ä¸ºæ›´æ˜“ç®¡ç†çš„å—æ§åˆæˆä»»åŠ¡ã€‚é€šè¿‡ä¸“æ³¨äºå…³é”®å¸§ä¹‹é—´çš„è¿åŠ¨è¿‡æ¸¡åŒæ—¶èå…¥å…¨é¢çš„åœºæ™¯æ„ŸçŸ¥ï¼Œè¯¥æ¡†æ¶å®ç°äº†ç²¾ç¡®æ§åˆ¶å’Œç¯å¢ƒåˆç†æ€§ã€‚åˆ†å±‚åœºæ™¯ç¼–ç å’ŒåŸºäºæ‰©æ•£çš„å»å™ªæä¾›äº†å¤„ç†çœŸå®ä¸–ç•Œä¸å®Œç¾æ€§çš„å¿…è¦é²æ£’æ€§ï¼Œä½¿è¯¥æ–¹æ³•åœ¨åŠ¨ç”»ã€æ•°æ®å¢å¼ºå’Œè§†é¢‘é‡å»ºåº”ç”¨ä¸­å…·æœ‰å®é™…å¯è¡Œæ€§ã€‚
             </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); position: relative;">
        <button onclick="toggleLang(this)" style="position: absolute; top: 16px; right: 16px; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.2); color: #aeb7e6; padding: 4px 10px; border-radius: 8px; cursor: pointer; font-size: 12px;">ä¸­ / En</button>
        <h2 style="margin:0 0 8px;font-size:16px;">Conclusionï¼ˆç»“è®ºï¼‰</h2>
        <div style="color:rgba(232,236,255,.80);line-height:1.65;">
          <div class="lang-en">
            This paper introduces SceneMI, a novel framework that reformulates human-scene interaction modeling as scene-aware motion in-betweening. By leveraging dual scene descriptors and the denoising capabilities of diffusion models, SceneMI enables controllable synthesis of human motions in 3D scenes while handling noisy keyframes from real-world sources. Extensive experiments demonstrate superior performance in keyframe-guided animation, artifact reduction in noisy HSI data (37.5% reduction in foot skating and 56.5% in jittering), and enhanced HSI reconstruction from monocular videos. The framework shows robust generalization across different scene types and motion quality levels, establishing scene-aware motion in-betweening as a practical and tractable approach for HSI modeling with significant implications for animation, virtual reality, and human behavior understanding applications.
          </div>
          <div class="lang-zh" style="display:none">
            æœ¬æ–‡ä»‹ç»äº†SceneMIï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œå°†äººç±»-åœºæ™¯äº¤äº’å»ºæ¨¡é‡æ–°å®šä¹‰ä¸ºåœºæ™¯æ„ŸçŸ¥è¿åŠ¨æ’å€¼ã€‚é€šè¿‡åˆ©ç”¨åŒåœºæ™¯æè¿°ç¬¦å’Œæ‰©æ•£æ¨¡å‹çš„å»å™ªèƒ½åŠ›ï¼ŒSceneMIèƒ½å¤Ÿåœ¨å¤„ç†æ¥è‡ªçœŸå®ä¸–ç•Œæ¥æºçš„å™ªå£°å…³é”®å¸§çš„åŒæ—¶ï¼Œå®ç°3Dåœºæ™¯ä¸­äººç±»è¿åŠ¨çš„å¯æ§åˆæˆã€‚å¹¿æ³›çš„å®éªŒå±•ç¤ºäº†åœ¨å…³é”®å¸§å¼•å¯¼åŠ¨ç”»ã€å™ªå£°HSIæ•°æ®ç‘•ç–µå‡å°‘ï¼ˆè„šæ»‘åŠ¨å‡å°‘37.5%ã€æŠ–åŠ¨å‡å°‘56.5%ï¼‰å’Œå¢å¼ºå•ç›®è§†é¢‘HSIé‡å»ºæ–¹é¢çš„ä¼˜è¶Šæ€§èƒ½ã€‚è¯¥æ¡†æ¶åœ¨ä¸åŒåœºæ™¯ç±»å‹å’Œè¿åŠ¨è´¨é‡æ°´å¹³ä¸Šæ˜¾ç¤ºå‡ºé²æ£’çš„æ³›åŒ–ï¼Œå°†åœºæ™¯æ„ŸçŸ¥è¿åŠ¨æ’å€¼ç¡®ç«‹ä¸ºHSIå»ºæ¨¡çš„å®ç”¨å’Œæ˜“å¤„ç†æ–¹æ³•ï¼Œå¯¹åŠ¨ç”»ã€è™šæ‹Ÿç°å®å’Œäººç±»è¡Œä¸ºç†è§£åº”ç”¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚
          </div>
        </div>
      </div>

      <div style="padding:16px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(0,0,0,.10); display:flex; align-items:center; gap:12px;">
        <h2 style="margin:0;font-size:16px;">Official Code:</h2>
        <a href="http://inwoohwang.me/SceneMI" target="_blank" style="display:flex; align-items:center; gap:6px; color:#8bffcf; text-decoration:none; font-family:ui-monospace,monospace; font-size:13px; border:1px solid rgba(139,255,207,0.3); padding:6px 12px; border-radius:8px; background:rgba(139,255,207,0.05); transition: all 0.2s ease;">
          Project Page
        </a>
      </div>
    </div>
</section>
</body>
</html>
